<!DOCTYPE html><html class="theme-next muse use-motion" lang="zh-CN"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><script src="https://cdn.staticfile.org/pace/1.0.2/pace.min.js"></script><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="google-site-verification" content="Ojd_HrL_PelaXvKK5IkbhLbjZ_sHt6IxRzP-XPaaTw4"><meta name="msvalidate.01" content="473DA33F97AC4CCE578BDDE1F4B458E5"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png"><link rel="mask-icon" href="/images/logo.svg" color="#222"><script type="text/javascript" id="hexo.configurations">var NexT=window.NexT||{},CONFIG={root:"/",scheme:"Muse",version:"6.4.1",sidebar:{position:"left",display:"post",offset:12,b2t:!1,scrollpercent:!1,onmobile:!1},fancybox:!0,fastclick:!1,lazyload:!0,tabs:!0,motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},algolia:{applicationID:"",apiKey:"",indexName:"",hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}}}</script><meta name="description" content="最近公司项目需要使用GPU进行加速，没有人会CUDA编程，所以开始了这个学习。做深度学习，CUDA编程也算是必备技能了吧。"><meta name="keywords" content="Deep Learning,CUDA,PyCUDA,GPU"><meta property="og:type" content="article"><meta property="og:title" content="PyCUDA学习笔记"><meta property="og:url" content="http://muyaan.com/2019/02/01/PyCUDA学习笔记/index.html"><meta property="og:site_name" content="慕湮"><meta property="og:description" content="最近公司项目需要使用GPU进行加速，没有人会CUDA编程，所以开始了这个学习。做深度学习，CUDA编程也算是必备技能了吧。"><meta property="og:locale" content="zh-CN"><meta property="og:updated_time" content="2019-02-01T02:25:30.289Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="PyCUDA学习笔记"><meta name="twitter:description" content="最近公司项目需要使用GPU进行加速，没有人会CUDA编程，所以开始了这个学习。做深度学习，CUDA编程也算是必备技能了吧。"><link rel="canonical" href="http://muyaan.com/2019/02/01/PyCUDA学习笔记/"><script type="text/javascript" id="page.configurations">CONFIG.page={sidebar:""}</script><title>PyCUDA学习笔记 | 慕湮</title><script type="text/javascript">var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?ca5844321cfb80fdf6f12b4dcc326991";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><style>html{font-family:sans-serif;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}body{margin:0}article,aside,details,figcaption,figure,footer,header,hgroup,main,menu,nav,section,summary{display:block}audio,canvas,progress,video{display:inline-block;vertical-align:baseline}audio:not([controls]){display:none;height:0}[hidden],template{display:none}a{background-color:transparent}a:active,a:hover{outline:0}abbr[title]{border-bottom:1px dotted}b,strong{font-weight:700}dfn{font-style:italic}h1{font-size:2em;margin:.67em 0}mark{background:#ff0;color:#000}small{font-size:80%}sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}sup{top:-.5em}sub{bottom:-.25em}img{border:0}svg:not(:root){overflow:hidden}figure{margin:1em 40px}hr{-moz-box-sizing:content-box;box-sizing:content-box;height:0}pre{overflow:auto}code,kbd,pre,samp{font-family:monospace,monospace;font-size:1em}button,input,optgroup,select,textarea{color:inherit;font:inherit;margin:0}button{overflow:visible}button,select{text-transform:none}button,html input[type=button],input[type=reset],input[type=submit]{-webkit-appearance:button;cursor:pointer}button[disabled],html input[disabled]{cursor:default}button::-moz-focus-inner,input::-moz-focus-inner{border:0;padding:0}input{line-height:normal}input[type=checkbox],input[type=radio]{box-sizing:border-box;padding:0}input[type=number]::-webkit-inner-spin-button,input[type=number]::-webkit-outer-spin-button{height:auto}input[type=search]{-webkit-appearance:textfield;-moz-box-sizing:content-box;-webkit-box-sizing:content-box;box-sizing:content-box}input[type=search]::-webkit-search-cancel-button,input[type=search]::-webkit-search-decoration{-webkit-appearance:none}fieldset{border:1px solid silver;margin:0 2px;padding:.35em .625em .75em}legend{border:0;padding:0}textarea{overflow:auto}optgroup{font-weight:700}table{border-collapse:collapse;border-spacing:0}td,th{padding:0}::selection{background:#262a30;color:#fff}body{position:relative;font-family:Lato,"PingFang SC","Microsoft YaHei",sans-serif;font-size:14px;line-height:2;color:#555;background:#fff}@media (max-width:767px){body{padding-right:0!important}}@media (min-width:768px) and (max-width:991px){body{padding-right:0!important}}@media (min-width:1200px){body{font-size:16px}}h1,h2,h3,h4,h5,h6{margin:0;padding:0;font-weight:700;line-height:1.5;font-family:'Roboto Slab',Lato,"PingFang SC","Microsoft YaHei",sans-serif}h1,h2,h3,h4,h5,h6{margin:20px 0 15px}h1{font-size:22px}@media (max-width:767px){h1{font-size:18px}}h2{font-size:20px}@media (max-width:767px){h2{font-size:16px}}h3{font-size:18px}@media (max-width:767px){h3{font-size:14px}}h4{font-size:16px}@media (max-width:767px){h4{font-size:12px}}h5{font-size:14px}@media (max-width:767px){h5{font-size:10px}}h6{font-size:12px}@media (max-width:767px){h6{font-size:8px}}p{margin:0 0 20px 0}a{color:#555;text-decoration:none;outline:0;border-bottom:1px solid #999;word-wrap:break-word}a:hover{color:#222;border-bottom-color:#222}blockquote{margin:0;padding:0}img{display:block;margin:auto;max-width:100%;height:auto}hr{margin:40px 0;height:3px;border:none;background-color:#ddd;background-image:repeating-linear-gradient(-45deg,#fff,#fff 4px,transparent 4px,transparent 8px)}blockquote{padding:0 15px;color:#666;border-left:4px solid #ddd}blockquote cite::before{content:"-";padding:0 5px}dt{font-weight:700}dd{margin:0;padding:0}kbd{border:1px solid #ccc;border-radius:.2em;box-shadow:.1em .1em .2em rgba(0,0,0,.1);background-color:#f9f9f9;font-family:inherit;background-image:-webkit-linear-gradient(top,#eee,#fff,#eee);padding:.1em .3em;white-space:nowrap}.text-left{text-align:left}.text-center{text-align:center}.text-right{text-align:right}.text-justify{text-align:justify}.text-nowrap{white-space:nowrap}.text-lowercase{text-transform:lowercase}.text-uppercase{text-transform:uppercase}.text-capitalize{text-transform:capitalize}.center-block{display:block;margin-left:auto;margin-right:auto}.clearfix:after,.clearfix:before{content:" ";display:table}.clearfix:after{clear:both}.pullquote{width:45%}.pullquote.left{float:left;margin-left:5px;margin-right:10px}.pullquote.right{float:right;margin-left:10px;margin-right:5px}.affix.affix.affix{position:fixed}.translation{margin-top:-20px;font-size:14px;color:#999}.scrollbar-measure{width:100px;height:100px;overflow:scroll;position:absolute;top:-9999px}.use-motion .motion-element{opacity:0}table{margin:20px 0;width:100%;border-collapse:collapse;border-spacing:0;border:1px solid #ddd;font-size:14px;word-wrap:break-all}table>tbody>tr:nth-of-type(odd){background-color:#f9f9f9}table>tbody>tr:hover{background-color:#f5f5f5}caption,td,th{padding:8px;text-align:left;vertical-align:middle;font-weight:400}td,th{border-bottom:3px solid #ddd;border-right:1px solid #eee}th{padding-bottom:10px;font-weight:700}td{border-bottom-width:1px}body,html{height:100%}.container{position:relative;min-height:100%}.header-inner{margin:0 auto;padding:100px 0 70px;width:700px}@media (min-width:1200px){.container .header-inner{width:800px}}@media (min-width:1600px){.container .header-inner{width:900px}}.main{padding-bottom:150px}.main-inner{margin:0 auto;width:700px}@media (min-width:1200px){.container .main-inner{width:800px}}@media (min-width:1600px){.container .main-inner{width:900px}}.footer{position:absolute;left:0;bottom:0;width:100%;min-height:50px}.footer-inner{box-sizing:border-box;margin:20px auto;width:700px}@media (min-width:1200px){.container .footer-inner{width:800px}}@media (min-width:1600px){.container .footer-inner{width:900px}}.highlight,pre{overflow:auto;margin:20px 0;padding:0;font-size:14px;color:#4d4d4c;background:#f7f7f7;line-height:1.6}code,pre{font-family:consolas,Menlo,"PingFang SC","Microsoft YaHei",monospace}code{padding:2px 4px;word-wrap:break-word;color:#555;background:#eee;border-radius:3px;font-size:14px}pre{padding:10px}pre code{padding:0;color:#4d4d4c;background:0 0;text-shadow:none}.highlight{border-radius:1px}.highlight pre{border:none;margin:0;padding:10px 0}.highlight table{margin:0;width:auto;border:none}.highlight td{border:none;padding:0}.highlight figcaption{font-size:1em;color:#4d4d4c;line-height:1em;margin-bottom:1em;margin:0;padding:.5em;background:#eee;border-bottom:1px solid #e9e9e9}.highlight figcaption:after,.highlight figcaption:before{content:" ";display:table}.highlight figcaption:after{clear:both}.highlight figcaption a{float:right;color:#4d4d4c}.highlight figcaption a:hover{border-bottom-color:#4d4d4c}.highlight .gutter pre{padding-left:10px;padding-right:10px;color:#869194;text-align:right;background-color:#eff2f3}.highlight .code pre{width:100%;padding-left:10px;padding-right:10px;background-color:#f7f7f7}.highlight .line{height:20px}.gutter{-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.gist table{width:auto}.gist table td{border:none}pre .deletion{background:#fdd}pre .addition{background:#dfd}pre .meta{color:#8959a8}pre .comment{color:#8e908c}pre .attribute,pre .css .class,pre .css .id,pre .css .pseudo,pre .html .doctype,pre .regexp,pre .ruby .constant,pre .tag,pre .variable,pre .xml .doctype,pre .xml .pi,pre .xml .tag .title{color:#c82829}pre .built_in,pre .command,pre .constant,pre .literal,pre .number,pre .params,pre .preprocessor{color:#f5871f}pre .css .rules .attribute,pre .formula,pre .header,pre .inheritance,pre .number,pre .ruby .class .title,pre .ruby .symbol,pre .special,pre .string,pre .value,pre .xml .cdata{color:#718c00}pre .css .hexcolor,pre .title{color:#3e999f}pre .coffeescript .title,pre .function,pre .javascript .title,pre .perl .sub,pre .python .decorator,pre .python .title,pre .ruby .function .title,pre .ruby .title .keyword{color:#4271ae}pre .javascript .function,pre .keyword{color:#8959a8}.posts-expand .post-body img.full-image{border:none}.blockquote-center,.page-home .post-type-quote blockquote,.page-post-detail .post-type-quote blockquote{position:relative;margin:40px 0;padding:0;border-left:none;text-align:center}.blockquote-center::after,.blockquote-center::before,.page-home .post-type-quote blockquote::after,.page-home .post-type-quote blockquote::before,.page-post-detail .post-type-quote blockquote::after,.page-post-detail .post-type-quote blockquote::before{position:absolute;content:' ';display:block;width:100%;height:24px;opacity:.2;background-repeat:no-repeat;background-position:0 -6px;background-size:22px 22px}.blockquote-center::before,.page-home .post-type-quote blockquote::before,.page-post-detail .post-type-quote blockquote::before{top:-20px;background-image:url(../images/quote-l.svg);border-top:1px solid #ccc}.blockquote-center::after,.page-home .post-type-quote blockquote::after,.page-post-detail .post-type-quote blockquote::after{bottom:-20px;background-image:url(../images/quote-r.svg);border-bottom:1px solid #ccc;background-position:100% 8px}.blockquote-center div,.blockquote-center p,.page-home .post-type-quote blockquote div,.page-home .post-type-quote blockquote p,.page-post-detail .post-type-quote blockquote div,.page-post-detail .post-type-quote blockquote p{text-align:center}.post .post-body .group-picture img{box-sizing:border-box;padding:0 3px;border:none}.post .group-picture-row{overflow:hidden;margin-top:6px}.post .group-picture-row:first-child{margin-top:0}.post .group-picture-column{float:left}.page-post-detail .post-body .group-picture-column{float:none;margin-top:10px;width:auto!important}.page-post-detail .post-body .group-picture-column img{margin:0 auto}.page-archive .group-picture-container{overflow:hidden}.page-archive .group-picture-row{float:left}.page-archive .group-picture-row:first-child{margin-top:6px}.page-archive .group-picture-column{max-width:150px;max-height:150px}.post-body .note{position:relative;padding:15px;margin-bottom:20px;border:1px solid #eee;border-left-width:5px;border-radius:3px}.post-body .note h2,.post-body .note h3,.post-body .note h4,.post-body .note h5,.post-body .note h6{margin-top:0;margin-bottom:0;border-bottom:initial;padding-top:0!important}.post-body .note blockquote:first-child,.post-body .note ol:first-child,.post-body .note p:first-child,.post-body .note pre:first-child,.post-body .note table:first-child,.post-body .note ul:first-child{margin-top:0}.post-body .note blockquote:last-child,.post-body .note ol:last-child,.post-body .note p:last-child,.post-body .note pre:last-child,.post-body .note table:last-child,.post-body .note ul:last-child{margin-bottom:0}.post-body .note.default{border-left-color:#777}.post-body .note.default h2,.post-body .note.default h3,.post-body .note.default h4,.post-body .note.default h5,.post-body .note.default h6{color:#777}.post-body .note.primary{border-left-color:#6f42c1}.post-body .note.primary h2,.post-body .note.primary h3,.post-body .note.primary h4,.post-body .note.primary h5,.post-body .note.primary h6{color:#6f42c1}.post-body .note.info{border-left-color:#428bca}.post-body .note.info h2,.post-body .note.info h3,.post-body .note.info h4,.post-body .note.info h5,.post-body .note.info h6{color:#428bca}.post-body .note.success{border-left-color:#5cb85c}.post-body .note.success h2,.post-body .note.success h3,.post-body .note.success h4,.post-body .note.success h5,.post-body .note.success h6{color:#5cb85c}.post-body .note.warning{border-left-color:#f0ad4e}.post-body .note.warning h2,.post-body .note.warning h3,.post-body .note.warning h4,.post-body .note.warning h5,.post-body .note.warning h6{color:#f0ad4e}.post-body .note.danger{border-left-color:#d9534f}.post-body .note.danger h2,.post-body .note.danger h3,.post-body .note.danger h4,.post-body .note.danger h5,.post-body .note.danger h6{color:#d9534f}.post-body .label{display:inline;padding:0 2px;white-space:nowrap}.post-body .label.default{background-color:#f0f0f0}.post-body .label.primary{background-color:#efe6f7}.post-body .label.info{background-color:#e5f2f8}.post-body .label.success{background-color:#e7f4e9}.post-body .label.warning{background-color:#fcf6e1}.post-body .label.danger{background-color:#fae8eb}.post-body .tabs{position:relative;display:block;margin-bottom:20px;padding-top:10px}.post-body .tabs ul.nav-tabs{margin:0;padding:0;display:flex;margin-bottom:-1px}@media (max-width:413px){.post-body .tabs ul.nav-tabs{display:block;margin-bottom:5px}}.post-body .tabs ul.nav-tabs li.tab{list-style-type:none!important;margin:0 .25em 0 0;border-top:3px solid transparent;border-left:1px solid transparent;border-right:1px solid transparent}@media (max-width:413px){.post-body .tabs ul.nav-tabs li.tab{margin:initial;border-top:1px solid transparent;border-left:3px solid transparent;border-right:1px solid transparent;border-bottom:1px solid transparent}}.post-body .tabs ul.nav-tabs li.tab a{outline:0;border-bottom:initial;display:block;line-height:1.8em;padding:.25em .75em;transition-duration:.2s;transition-timing-function:ease-out;transition-delay:0s}.post-body .tabs ul.nav-tabs li.tab a i{width:1.285714285714286em}.post-body .tabs ul.nav-tabs li.tab.active{border-top:3px solid #fc6423;border-left:1px solid #ddd;border-right:1px solid #ddd;background-color:#fff}@media (max-width:413px){.post-body .tabs ul.nav-tabs li.tab.active{border-top:1px solid #ddd;border-left:3px solid #fc6423;border-right:1px solid #ddd;border-bottom:1px solid #ddd}}.post-body .tabs ul.nav-tabs li.tab.active a{cursor:default;color:#555}.post-body .tabs .tab-content{background-color:#fff}.post-body .tabs .tab-content .tab-pane{border:1px solid #ddd;padding:20px 20px 0 20px}.post-body .tabs .tab-content .tab-pane:not(.active){display:none!important}.post-body .tabs .tab-content .tab-pane.active{display:block!important}.btn{display:inline-block;padding:0 20px;font-size:14px;color:#fff;background:#222;border:2px solid #222;text-decoration:none;border-radius:0;transition-property:background-color;transition-duration:.2s;transition-timing-function:ease-in-out;transition-delay:0s;line-height:2}.btn:hover{border-color:#222;color:#222;background:#fff}.btn+.btn{margin:0 0 8px 8px}.btn .fa-fw{width:1.285714285714286em;text-align:left}.btn-bar{display:block;width:22px;height:2px;background:#555;border-radius:1px}.btn-bar+.btn-bar{margin-top:4px}.pagination{margin:120px 0 40px;text-align:center;border-top:1px solid #eee}.page-number-basic,.pagination .next,.pagination .page-number,.pagination .prev,.pagination .space{display:inline-block;position:relative;top:-1px;margin:0 10px;padding:0 11px}@media (max-width:767px){.page-number-basic,.pagination .next,.pagination .page-number,.pagination .prev,.pagination .space{margin:0 5px}}.pagination .next,.pagination .page-number,.pagination .prev{border-bottom:0;border-top:1px solid #eee;transition-property:border-color;transition-duration:.2s;transition-timing-function:ease-in-out;transition-delay:0s}.pagination .next:hover,.pagination .page-number:hover,.pagination .prev:hover{border-top-color:#222}.pagination .space{padding:0;margin:0}.pagination .prev{margin-left:0}.pagination .next{margin-right:0}.pagination .page-number.current{color:#fff;background:#ccc;border-top-color:#ccc}@media (max-width:767px){.pagination{border-top:none}.pagination .next,.pagination .page-number,.pagination .prev{margin-bottom:10px;border-top:0;border-bottom:1px solid #eee;padding:0 10px}.pagination .next:hover,.pagination .page-number:hover,.pagination .prev:hover{border-bottom-color:#222}}.comments{margin:60px 20px 0}.tag-cloud{text-align:center}.tag-cloud a{display:inline-block;margin:10px}.back-to-top{box-sizing:border-box;position:fixed;bottom:-100px;right:30px;z-index:1050;padding:0 6px;width:24px;background:#222;font-size:12px;opacity:1;color:#fff;cursor:pointer;text-align:center;-webkit-transform:translateZ(0);transition-property:bottom;transition-duration:.2s;transition-timing-function:ease-in-out;transition-delay:0s}@media (min-width:768px) and (max-width:991px){.back-to-top{display:none!important}}@media (max-width:767px){.back-to-top{display:none!important}}.back-to-top.back-to-top-on{bottom:19px}.header{background:0 0}.header-inner{position:relative}.headband{height:3px;background:#222}.site-meta{margin:0;text-align:center}@media (max-width:767px){.site-meta{text-align:center}}.brand{position:relative;display:inline-block;padding:0 40px;color:#fff;background:#222;border-bottom:none}.brand:hover{color:#fff}.logo{display:inline-block;margin-right:5px;line-height:36px;vertical-align:top}.site-title{display:inline-block;vertical-align:top;line-height:36px;font-size:20px;font-weight:400;font-family:Lato,"PingFang SC","Microsoft YaHei",sans-serif}.site-subtitle{margin-top:10px;font-size:13px;color:#999}.use-motion .brand{opacity:0}.use-motion .logo,.use-motion .site-subtitle,.use-motion .site-title{opacity:0;position:relative;top:-10px}.site-nav-toggle{display:none;position:absolute;top:10px;left:10px}@media (max-width:767px){.site-nav-toggle{display:block}}.site-nav-toggle button{margin-top:2px;padding:9px 10px;background:0 0;border:none}@media (max-width:767px){.site-nav{display:none;margin:0 -10px;padding:0 10px;clear:both;border-top:1px solid #ddd}}@media (min-width:768px) and (max-width:991px){.site-nav{display:block!important}}@media (min-width:992px){.site-nav{display:block!important}}.menu{margin-top:20px;padding-left:0;text-align:center}.menu .menu-item{display:inline-block;margin:0 10px;list-style:none}@media screen and (max-width:767px){.menu .menu-item{margin-top:10px}}.menu .menu-item a{display:block;font-size:13px;line-height:inherit;border-bottom:1px solid transparent;transition-property:border-color;transition-duration:.2s;transition-timing-function:ease-in-out;transition-delay:0s}.menu .menu-item a:hover{border-bottom-color:#222}.menu .menu-item .fa{margin-right:5px}.use-motion .menu-item{opacity:0}.post-body{font-family:Lato,"PingFang SC","Microsoft YaHei",sans-serif}@media (max-width:767px){.post-body{word-break:break-word}}.post-body .fancybox img{display:block!important;margin:0 auto;cursor:pointer;cursor:zoom-in;cursor:-webkit-zoom-in}.post-body .figure .caption,.post-body .image-caption{margin:-20px auto 15px;text-align:center;font-size:14px;color:#999;font-weight:700;line-height:1}.post-sticky-flag{display:inline-block;font-size:16px;-ms-transform:rotate(30deg);-webkit-transform:rotate(30deg);-moz-transform:rotate(30deg);-ms-transform:rotate(30deg);-o-transform:rotate(30deg);transform:rotate(30deg)}.use-motion .comments,.use-motion .pagination,.use-motion .post-block{opacity:0}.use-motion .post-header{opacity:0}.use-motion .post-body{opacity:0}.use-motion .collection-title{opacity:0}.posts-expand{padding-top:40px}@media (max-width:767px){.posts-expand{margin:0 20px}.post-body pre .gutter pre{padding-right:10px}.post-body .highlight{margin-left:0;margin-right:0;padding:0}.post-body .highlight .gutter pre{padding-right:10px}}@media (min-width:992px){.posts-expand .post-body{text-align:justify}}.posts-expand .post-body h2,.posts-expand .post-body h3,.posts-expand .post-body h4,.posts-expand .post-body h5,.posts-expand .post-body h6{padding-top:10px}.posts-expand .post-body h2 .header-anchor,.posts-expand .post-body h3 .header-anchor,.posts-expand .post-body h4 .header-anchor,.posts-expand .post-body h5 .header-anchor,.posts-expand .post-body h6 .header-anchor{float:right;margin-left:10px;color:#ccc;border-bottom-style:none;visibility:hidden}.posts-expand .post-body h2 .header-anchor:hover,.posts-expand .post-body h3 .header-anchor:hover,.posts-expand .post-body h4 .header-anchor:hover,.posts-expand .post-body h5 .header-anchor:hover,.posts-expand .post-body h6 .header-anchor:hover{color:inherit}.posts-expand .post-body h2:hover .header-anchor,.posts-expand .post-body h3:hover .header-anchor,.posts-expand .post-body h4:hover .header-anchor,.posts-expand .post-body h5:hover .header-anchor,.posts-expand .post-body h6:hover .header-anchor{visibility:visible}.posts-expand .post-body ul li{list-style:circle}.posts-expand .post-body img{box-sizing:border-box;margin:auto;padding:3px;border:1px solid #ddd}.posts-expand .post-body .fancybox img{margin:0 auto 25px}.posts-expand .post-body img{margin:0 auto 25px}@media (max-width:767px){.posts-collapse{margin:0 20px}.posts-collapse .post-meta,.posts-collapse .post-title{display:block;width:auto;text-align:left}}.posts-collapse{position:relative;z-index:1010;margin-left:55px}.posts-collapse::after{content:" ";position:absolute;top:20px;left:0;margin-left:-2px;width:4px;height:100%;background:#f5f5f5;z-index:-1}@media (max-width:767px){.posts-collapse{margin:0 20px}}.posts-collapse .collection-title{position:relative;margin:60px 0}.posts-collapse .collection-title h1,.posts-collapse .collection-title h2{margin-left:20px}.posts-collapse .collection-title small{color:#bbb;margin-left:5px}.posts-collapse .collection-title::before{content:" ";position:absolute;left:0;top:50%;margin-left:-4px;margin-top:-4px;width:8px;height:8px;background:#bbb;border-radius:50%}.posts-collapse .post{margin:30px 0}.posts-collapse .post-header{position:relative;transition-duration:.2s;transition-timing-function:ease-in-out;transition-delay:0s;transition-property:border;border-bottom:1px dashed #ccc}.posts-collapse .post-header::before{content:" ";position:absolute;left:0;top:12px;width:6px;height:6px;margin-left:-4px;background:#bbb;border-radius:50%;border:1px solid #fff;transition-duration:.2s;transition-timing-function:ease-in-out;transition-delay:0s;transition-property:background}.posts-collapse .post-header:hover{border-bottom-color:#666}.posts-collapse .post-header:hover::before{background:#222}.posts-collapse .post-meta{position:absolute;font-size:12px;left:20px;top:5px}.posts-collapse .post-comments-count{display:none}.posts-collapse .post-title{margin-left:60px;font-size:16px;font-weight:400;line-height:inherit}.posts-collapse .post-title::after{margin-left:3px;opacity:.6}.posts-collapse .post-title a{color:#666;border-bottom:none}.page-home .post-type-quote .post-header,.page-home .post-type-quote .post-tags,.page-post-detail .post-type-quote .post-header,.page-post-detail .post-type-quote .post-tags{display:none}.posts-expand .post-title{text-align:center;word-break:break-word;font-weight:400}.posts-expand .post-title-link{display:inline-block;position:relative;color:#555;border-bottom:none;line-height:1.2;vertical-align:top}.posts-expand .post-title-link::before{content:"";position:absolute;width:100%;height:2px;bottom:0;left:0;background-color:#000;visibility:hidden;-webkit-transform:scaleX(0);-moz-transform:scaleX(0);-ms-transform:scaleX(0);-o-transform:scaleX(0);transform:scaleX(0);transition-duration:.2s;transition-timing-function:ease-in-out;transition-delay:0s}.posts-expand .post-title-link:hover::before{visibility:visible;-webkit-transform:scaleX(1);-moz-transform:scaleX(1);-ms-transform:scaleX(1);-o-transform:scaleX(1);transform:scaleX(1)}.posts-expand .post-title-link .fa{font-size:16px}.posts-expand .post-meta{margin:3px 0 60px 0;color:#999;font-family:Lato,"PingFang SC","Microsoft YaHei",sans-serif;font-size:12px;text-align:center}.posts-expand .post-meta .post-category-list{display:inline-block;margin:0;padding:3px}.posts-expand .post-meta .post-category-list-link{color:#999}.posts-expand .post-meta .post-description{font-size:14px;margin-top:2px}.posts-expand .post-meta time{border-bottom:1px dashed #999;cursor:help}.post-meta-divider{margin:0 .5em}.post-meta-item-icon{margin-right:3px}@media (min-width:768px) and (max-width:991px){.post-meta-item-icon{display:inline-block}}@media (max-width:767px){.post-meta-item-icon{display:inline-block}}@media (min-width:768px) and (max-width:991px){.post-meta-item-text{display:none}}@media (max-width:767px){.post-meta-item-text{display:none}}.post-button{margin-top:40px}.posts-expand .post-tags{margin-top:40px;text-align:center}.posts-expand .post-tags a{display:inline-block;margin-right:10px;font-size:13px}.post-nav{display:table;margin-top:15px;width:100%;border-top:1px solid #eee}.post-nav-divider{display:table-cell;width:10%}.post-nav-item{display:table-cell;padding:10px 0 0 0;width:45%;vertical-align:top}.post-nav-item a{position:relative;display:block;line-height:25px;font-size:14px;color:#555;border-bottom:none}.post-nav-item a:hover{color:#222;border-bottom:none}.post-nav-item a:active{top:2px}.post-nav-item .fa{position:absolute;top:8px;left:0;font-size:12px}.post-nav-next a{padding-left:15px}.post-nav-prev{text-align:right}.post-nav-prev a{padding-right:15px}.post-nav-prev .fa{right:0;left:auto}.posts-expand .post-eof{display:block;margin:80px auto 60px;width:8%;height:1px;background:#ccc;text-align:center}.post:last-child .post-eof.post-eof.post-eof{display:none}.post-gallery{display:table;table-layout:fixed;width:100%;border-collapse:separate}.post-gallery-row{display:table-row}.post-gallery .post-gallery-img{display:table-cell;text-align:center;vertical-align:middle;border:none}.post-gallery .post-gallery-img img{max-width:100%;max-height:100%;border:none}.fancybox-close,.fancybox-close:hover{border:none}.post-copyright{margin:2em 0 0;padding:.5em 1em;border-left:3px solid #ff1700;background-color:#f9f9f9;list-style:none}.rtl.post-body a,.rtl.post-body h1,.rtl.post-body h2,.rtl.post-body h3,.rtl.post-body h4,.rtl.post-body h5,.rtl.post-body h6,.rtl.post-body li,.rtl.post-body ol,.rtl.post-body p,.rtl.post-body ul{direction:rtl;font-family:UKIJ Ekran}.rtl.post-title{font-family:UKIJ Ekran}.sidebar{position:fixed;right:0;top:0;bottom:0;width:0;z-index:1040;box-shadow:inset 0 2px 6px #000;background:#222;-webkit-transform:translateZ(0)}.sidebar .exturl,.sidebar a{color:#999;border-bottom-color:#555}.sidebar .exturl:hover,.sidebar a:hover{color:#eee}@media (min-width:768px) and (max-width:991px){.sidebar{display:none!important}}@media (max-width:767px){.sidebar{display:none!important}}.sidebar-inner{position:relative;padding:20px 10px;color:#999;text-align:center}.site-overview-wrap{overflow:hidden}.site-overview{overflow-y:auto;overflow-x:hidden}.sidebar-toggle{position:fixed;right:30px;bottom:45px;width:14px;height:14px;padding:5px;background:#222;line-height:0;z-index:1050;cursor:pointer;-webkit-transform:translateZ(0)}@media (min-width:768px) and (max-width:991px){.sidebar-toggle{display:none!important}}@media (max-width:767px){.sidebar-toggle{display:none!important}}.sidebar-toggle-line{position:relative;display:inline-block;vertical-align:top;height:2px;width:100%;background:#fff;margin-top:3px}.sidebar-toggle-line:first-child{margin-top:0}.site-author-image{display:block;margin:0 auto;padding:2px;max-width:96px;height:auto;border:2px solid #333;opacity:1}.site-author-name{margin:5px 0 0;text-align:center;color:#f5f5f5;font-weight:400}.site-description{margin-top:5px;text-align:center;font-size:14px;color:#999}.site-state{overflow:hidden;line-height:1.4;white-space:nowrap;text-align:center}.site-state-item{display:inline-block;padding:0 15px;border-left:1px solid #333}.site-state-item:first-child{border-left:none}.site-state-item a{border-bottom:none}.site-state-item-count{display:block;text-align:center;color:inherit;font-weight:600;font-size:18px}.site-state-item-name{font-size:13px;color:inherit}.feed-link{margin-top:20px}.feed-link a{display:inline-block;padding:0 15px;color:#fc6423;border:1px solid #fc6423;border-radius:4px}.feed-link a i{color:#fc6423;font-size:14px}.feed-link a:hover{color:#fff;background:#fc6423}.feed-link a:hover i{color:#fff}.links-of-author{margin-top:20px}.links-of-author .exturl,.links-of-author a{display:inline-block;vertical-align:middle;margin-right:10px;margin-bottom:10px;border-bottom-color:#555;font-size:13px}.links-of-author .exturl:before,.links-of-author a:before{display:inline-block;vertical-align:middle;margin-right:3px;content:" ";width:4px;height:4px;border-radius:50%;background:#ffada3}.links-of-blogroll{font-size:13px}.links-of-blogroll-title{margin-top:20px;font-size:14px;font-weight:600}.links-of-blogroll-list{margin:0;padding:0;list-style:none}.links-of-blogroll-item{padding:2px 10px}.links-of-blogroll-item a{max-width:280px;box-sizing:border-box;display:inline-block;overflow:hidden;white-space:nowrap;text-overflow:ellipsis}.sidebar-nav{margin:0 0 20px;padding-left:0}.sidebar-nav li{display:inline-block;cursor:pointer;border-bottom:1px solid transparent;font-size:14px;color:#555}.sidebar-nav li:hover{color:#f5f5f5}.page-post-detail .sidebar-nav-toc{padding:0 5px}.page-post-detail .sidebar-nav-overview{margin-left:10px}.sidebar-nav .sidebar-nav-active{color:#87daff;border-bottom-color:#87daff}.sidebar-nav .sidebar-nav-active:hover{color:#87daff}.sidebar-panel{display:none}.sidebar-panel-active{display:block}.post-toc-empty{font-size:14px;color:#666}.post-toc-wrap{overflow:hidden}.post-toc{overflow:auto}.post-toc ol{margin:0;padding:0 2px 5px 10px;text-align:left;list-style:none;font-size:14px}.post-toc ol>ol{padding-left:0}.post-toc ol a{transition-duration:.2s;transition-timing-function:ease-in-out;transition-delay:0s;transition-property:all;color:#999;border-bottom-color:#555}.post-toc ol a:hover{color:#ccc;border-bottom-color:#ccc}.post-toc .nav-item{overflow:hidden;text-overflow:ellipsis;white-space:nowrap;line-height:1.8}.post-toc .nav .nav-child{display:none}.post-toc .nav .active>.nav-child{display:block}.post-toc .nav .active-current>.nav-child{display:block}.post-toc .nav .active-current>.nav-child>.nav-item{display:block}.post-toc .nav .active>a{color:#87daff;border-bottom-color:#87daff}.post-toc .nav .active-current>a{color:#87daff}.post-toc .nav .active-current>a:hover{color:#87daff}.footer{font-size:14px;color:#999}.footer img{border:none}.footer-inner{text-align:center}.with-love{display:inline-block;margin:0 5px;color:grey}.powered-by,.theme-info{display:inline-block}.cc-license{margin-top:10px;text-align:center}.cc-license .cc-opacity{opacity:.7;border-bottom:none}.cc-license .cc-opacity:hover{opacity:.9}.cc-license img{display:inline-block}@-moz-keyframes iconAnimate{0%,100%{-webkit-transform:scale(1);-moz-transform:scale(1);-ms-transform:scale(1);-o-transform:scale(1);transform:scale(1)}10%,30%{-webkit-transform:scale(.9);-moz-transform:scale(.9);-ms-transform:scale(.9);-o-transform:scale(.9);transform:scale(.9)}20%,40%,60%,80%{-webkit-transform:scale(1.1);-moz-transform:scale(1.1);-ms-transform:scale(1.1);-o-transform:scale(1.1);transform:scale(1.1)}50%,70%{-webkit-transform:scale(1.1);-moz-transform:scale(1.1);-ms-transform:scale(1.1);-o-transform:scale(1.1);transform:scale(1.1)}}@-webkit-keyframes iconAnimate{0%,100%{-webkit-transform:scale(1);-moz-transform:scale(1);-ms-transform:scale(1);-o-transform:scale(1);transform:scale(1)}10%,30%{-webkit-transform:scale(.9);-moz-transform:scale(.9);-ms-transform:scale(.9);-o-transform:scale(.9);transform:scale(.9)}20%,40%,60%,80%{-webkit-transform:scale(1.1);-moz-transform:scale(1.1);-ms-transform:scale(1.1);-o-transform:scale(1.1);transform:scale(1.1)}50%,70%{-webkit-transform:scale(1.1);-moz-transform:scale(1.1);-ms-transform:scale(1.1);-o-transform:scale(1.1);transform:scale(1.1)}}@-o-keyframes iconAnimate{0%,100%{-webkit-transform:scale(1);-moz-transform:scale(1);-ms-transform:scale(1);-o-transform:scale(1);transform:scale(1)}10%,30%{-webkit-transform:scale(.9);-moz-transform:scale(.9);-ms-transform:scale(.9);-o-transform:scale(.9);transform:scale(.9)}20%,40%,60%,80%{-webkit-transform:scale(1.1);-moz-transform:scale(1.1);-ms-transform:scale(1.1);-o-transform:scale(1.1);transform:scale(1.1)}50%,70%{-webkit-transform:scale(1.1);-moz-transform:scale(1.1);-ms-transform:scale(1.1);-o-transform:scale(1.1);transform:scale(1.1)}}@keyframes iconAnimate{0%,100%{-webkit-transform:scale(1);-moz-transform:scale(1);-ms-transform:scale(1);-o-transform:scale(1);transform:scale(1)}10%,30%{-webkit-transform:scale(.9);-moz-transform:scale(.9);-ms-transform:scale(.9);-o-transform:scale(.9);transform:scale(.9)}20%,40%,60%,80%{-webkit-transform:scale(1.1);-moz-transform:scale(1.1);-ms-transform:scale(1.1);-o-transform:scale(1.1);transform:scale(1.1)}50%,70%{-webkit-transform:scale(1.1);-moz-transform:scale(1.1);-ms-transform:scale(1.1);-o-transform:scale(1.1);transform:scale(1.1)}}#gitment-display-button{display:inline-block;padding:0 15px;color:#0a9caf;cursor:pointer;font-size:14px;border:1px solid #0a9caf;border-radius:4px}#gitment-display-button:hover{color:#fff;background:#0a9caf}.fa{font-family:FontAwesome!important}.local-search-pop-overlay{position:fixed;width:100%;height:100%;top:0;left:0;z-index:2080;background-color:rgba(0,0,0,.3)}.local-search-popup{display:none;position:fixed;top:10%;left:50%;margin-left:-350px;width:700px;height:80%;padding:0;background:#fff;color:#333;z-index:9999;border-radius:5px}@media (max-width:767px){.local-search-popup{padding:0;top:0;left:0;margin:0;width:100%;height:100%;border-radius:0}}.local-search-popup ul.search-result-list{padding:0;margin:0 5px}.local-search-popup p.search-result{border-bottom:1px dashed #ccc;padding:5px 0}.local-search-popup a.search-result-title{font-weight:700;font-size:16px}.local-search-popup .search-keyword{border-bottom:1px dashed red;font-weight:700;color:red}.local-search-popup .local-search-header{padding:5px;height:36px;background:#f5f5f5;border-top-left-radius:5px;border-top-right-radius:5px}.local-search-popup #local-search-result{overflow:auto;position:relative;padding:5px 25px;height:calc(100% - 55px)}.local-search-popup .local-search-input-wrapper{display:inline-block;width:calc(100% - 90px);height:36px;line-height:36px;padding:0 5px}.local-search-popup .local-search-input-wrapper input{padding:8px 0;height:20px;display:block;width:100%;outline:0;border:none;background:0 0;vertical-align:middle}.local-search-popup .popup-btn-close,.local-search-popup .search-icon{display:inline-block;font-size:18px;color:#999;height:36px;width:18px;padding-left:10px;padding-right:10px}.local-search-popup .search-icon{float:left}.local-search-popup .popup-btn-close{border-left:1px solid #eee;float:right;cursor:pointer}.local-search-popup #no-result{position:absolute;left:50%;top:50%;-webkit-transform:translate(-50%,-50%);-webkit-transform:translate(-50%,-50%);-moz-transform:translate(-50%,-50%);-ms-transform:translate(-50%,-50%);-o-transform:translate(-50%,-50%);transform:translate(-50%,-50%);color:#ccc}.page-pv,.site-pv,.site-uv{display:inline-block}.page-pv .busuanzi-value,.site-pv .busuanzi-value,.site-uv .busuanzi-value{margin:0 5px}.popular-posts-header{margin-top:60px;margin-bottom:10px;font-size:24px;border-bottom:1px solid #eee;display:block}ul.popular-posts{padding:0}ul.popular-posts .popular-posts-item{margin-left:2em}ul.popular-posts .popular-posts-item .popular-posts-title{font-weight:400;font-size:14px;margin:0;line-height:2.4}.page-archive .archive-page-counter{position:relative;top:3px;left:20px}@media (max-width:767px){.page-archive .archive-page-counter{top:5px}}.page-archive .posts-collapse .archive-move-on{position:absolute;top:11px;left:0;margin-left:-6px;width:10px;height:10px;opacity:.5;background:#555;border:1px solid #fff;border-radius:50%}.category-all-page .category-all-title{text-align:center}.category-all-page .category-all{margin-top:20px}.category-all-page .category-list{margin:0;padding:0;list-style:none}.category-all-page .category-list-item{margin:5px 10px}.category-all-page .category-list-count{color:#bbb}.category-all-page .category-list-count:before{display:inline;content:" ("}.category-all-page .category-list-count:after{display:inline;content:") "}.category-all-page .category-list-child{padding-left:10px}#schedule ul#event-list{padding-left:30px}#schedule ul#event-list hr{margin:20px 0 45px 0!important;background:#222}#schedule ul#event-list hr:after{display:inline-block;content:'NOW';background:#222;color:#fff;font-weight:700;text-align:right;padding:0 5px}#schedule ul#event-list li.event{margin:20px 0;background:#f9f9f9;padding-left:10px;min-height:40px}#schedule ul#event-list li.event h2.event-summary{margin:0;padding-bottom:3px}#schedule ul#event-list li.event h2.event-summary:before{display:inline-block;font-family:FontAwesome;font-size:8px;content:'\f111';vertical-align:middle;margin-right:25px;color:#bbb}#schedule ul#event-list li.event span.event-relative-time{display:inline-block;font-size:12px;font-weight:400;padding-left:12px;color:#bbb}#schedule ul#event-list li.event span.event-details{display:block;color:#bbb;margin-left:56px;padding-top:3px;padding-bottom:6px;text-indent:-24px;line-height:18px}#schedule ul#event-list li.event span.event-details:before{text-indent:0;display:inline-block;width:14px;font-family:FontAwesome;text-align:center;margin-right:9px;color:#bbb}#schedule ul#event-list li.event span.event-details.event-location:before{content:'\f041'}#schedule ul#event-list li.event span.event-details.event-duration:before{content:'\f017'}#schedule ul#event-list li.event-past{background:#fcfcfc}#schedule ul#event-list li.event-past>*{opacity:.6}#schedule ul#event-list li.event-past h2.event-summary{color:#bbb}#schedule ul#event-list li.event-past h2.event-summary:before{color:#dfdfdf}#schedule ul#event-list li.event-now{background:#222;color:#fff;padding:15px 0 15px 10px}#schedule ul#event-list li.event-now h2.event-summary:before{-webkit-transform:scale(1.2);-moz-transform:scale(1.2);-ms-transform:scale(1.2);-o-transform:scale(1.2);transform:scale(1.2);color:#fff;animation:dot-flash 1s alternate infinite ease-in-out}#schedule ul#event-list li.event-now *{color:#fff!important}@-moz-keyframes dot-flash{from{opacity:1;-webkit-transform:scale(1.1);-moz-transform:scale(1.1);-ms-transform:scale(1.1);-o-transform:scale(1.1);transform:scale(1.1)}to{opacity:0;-webkit-transform:scale(1);-moz-transform:scale(1);-ms-transform:scale(1);-o-transform:scale(1);transform:scale(1)}}@-webkit-keyframes dot-flash{from{opacity:1;-webkit-transform:scale(1.1);-moz-transform:scale(1.1);-ms-transform:scale(1.1);-o-transform:scale(1.1);transform:scale(1.1)}to{opacity:0;-webkit-transform:scale(1);-moz-transform:scale(1);-ms-transform:scale(1);-o-transform:scale(1);transform:scale(1)}}@-o-keyframes dot-flash{from{opacity:1;-webkit-transform:scale(1.1);-moz-transform:scale(1.1);-ms-transform:scale(1.1);-o-transform:scale(1.1);transform:scale(1.1)}to{opacity:0;-webkit-transform:scale(1);-moz-transform:scale(1);-ms-transform:scale(1);-o-transform:scale(1);transform:scale(1)}}@keyframes dot-flash{from{opacity:1;-webkit-transform:scale(1.1);-moz-transform:scale(1.1);-ms-transform:scale(1.1);-o-transform:scale(1.1);transform:scale(1.1)}to{opacity:0;-webkit-transform:scale(1);-moz-transform:scale(1);-ms-transform:scale(1);-o-transform:scale(1);transform:scale(1)}}.page-post-detail .sidebar-toggle-line{background:#87daff}.page-post-detail .comments{overflow:hidden}ul.breadcrumb{list-style:none;margin:1em 0;padding:0 2em;text-align:center;font-size:12px}ul.breadcrumb li{display:inline}ul.breadcrumb li+li:before{padding:.5em;font-weight:400;content:"/\00a0"}ul.breadcrumb li+li:last-child{font-weight:700}@media (max-width:767px){.container .main-inner,.footer-inner,.header-inner{width:auto}}embed{display:block;margin:0 auto 25px auto}.custom-logo .site-meta-headline{text-align:center}.custom-logo .brand{background:0 0}.custom-logo .site-title{margin:10px auto 0;font-size:24px;color:#222}.custom-logo .site-title a{border:none}.custom-logo-image{margin:0 auto;padding:5px;max-width:150px;background:#fff}@media (max-width:767px){.site-nav{position:absolute;left:0;top:52px;margin:0;width:100%;padding:0;background:#fff;border-bottom:1px solid #ddd;z-index:1030}}@media (max-width:767px){.menu{text-align:left}}@media (max-width:767px){.menu .menu-item{display:block;margin:0 10px;vertical-align:top}}.menu .menu-item .badge{display:inline-block;padding:1px 4px;margin-left:5px;font-weight:700;line-height:1;text-align:center;white-space:nowrap;background-color:#eee}@media (max-width:767px){.menu .menu-item .badge{float:right;margin:.35em 0 0 0}}@media (max-width:767px){.menu .menu-item br{display:none}}@media (max-width:767px){.menu .menu-item a{padding:5px 10px;border-bottom-color:#fff!important}}.menu .menu-item .fa{margin-right:0}.menu-item-active a{border-bottom-color:#222!important;color:#222}@media (max-width:767px){.menu-item-active a{border-bottom-color:#fff!important}}.site-search form{display:none}.links-of-blogroll-inline .links-of-blogroll-item{display:inline-block}</style><noscript><style type="text/css">.sidebar-inner,.use-motion .brand,.use-motion .collection-title,.use-motion .comments,.use-motion .menu-item,.use-motion .motion-element,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .logo,.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.logo-line-after i{right:initial}</style></noscript><script>function loadCss(l){var d=document,h=d.head,s=d.createElement('link');s.rel='stylesheet';s.href=l;!function e(f){if (d.body)return f();setTimeout(function(){e(f)})}(function(){h.appendChild(s);});}loadCss('https://cdn.staticfile.org/pace/1.0.2/themes/blue/pace-theme-big-counter.min.css');loadCss('//cdn.staticfile.org/fancybox/2.1.5/jquery.fancybox.min.js');loadCss('//cdn.staticfile.org/font-awesome/4.6.2/css/font-awesome.min.css');loadCss('https://imsun.github.io/gitment/style/default.css');</script><noscript><link rel="stylesheet" href="https://cdn.staticfile.org/pace/1.0.2/themes/blue/pace-theme-big-counter.min.css"><link rel="stylesheet" href="//cdn.staticfile.org/fancybox/2.1.5/jquery.fancybox.min.js"><link rel="stylesheet" href="//cdn.staticfile.org/font-awesome/4.6.2/css/font-awesome.min.css"><link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css"></noscript></head><body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-CN"><div class="container sidebar-position-left page-post-detail"><div class="headband"></div><header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-wrapper"><div class="site-meta"><div class="custom-logo-site-title"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span> <span class="site-title">慕湮</span> <span class="logo-line-after"><i></i></span></a></div><h1 class="site-subtitle" itemprop="description">白日放歌须纵酒</h1></div><div class="site-nav-toggle"><button aria-label="切换导航栏"><span class="btn-bar"></span> <span class="btn-bar"></span> <span class="btn-bar"></span></button></div></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i><br>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i><br>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i><br>标签</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i><br>归档</a></li></ul></nav></div></header><main id="main" class="main"><div class="main-inner"><div class="content-wrap"><div id="content" class="content"><div id="posts" class="posts-expand"><article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article"><div class="post-block"><link itemprop="mainEntityOfPage" href="http://muyaan.com/2019/02/01/PyCUDA学习笔记/"><span hidden="" itemprop="author" itemscope="" itemtype="http://schema.org/Person"><meta itemprop="name" content="慕湮"><meta itemprop="description" content=""><meta itemprop="image" content="https://avatars0.githubusercontent.com/u/3022000?s=460&amp;v=4"></span><span hidden="" itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization"><meta itemprop="name" content="慕湮"></span><header class="post-header"><h2 class="post-title" itemprop="name headline">PyCUDA学习笔记</h2><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2019-02-01 10:21:31 / 修改时间：10:25:30" itemprop="dateCreated datePublished" datetime="2019-02-01T10:21:31+08:00">2019-02-01</time> </span><span id="/2019/02/01/PyCUDA学习笔记/" class="leancloud_visitors" data-flag-title="PyCUDA学习笔记"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="post-meta-item-text">阅读次数：</span> <span class="leancloud-visitors-count"></span></span><div class="post-symbolscount"><span class="post-meta-item-icon"><i class="fa fa-file-word-o"></i> </span><span class="post-meta-item-text">本文字数：</span> <span title="本文字数">25k</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-clock-o"></i> </span><span class="post-meta-item-text">阅读时长 ≈</span> <span title="阅读时长">45 分钟</span></div></div></header><div class="post-body" itemprop="articleBody"><p>最近公司项目需要使用GPU进行加速，没有人会CUDA编程，所以开始了这个学习。做深度学习，CUDA编程也算是必备技能了吧。</p><a id="more"></a><hr><h2 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1. 介绍"></a>1. 介绍</h2><p>CUDA是NVIDIA的利用GPU进行并行计算的API。PyCUDA是用python封装的一个库，除了进行计算的kernel函数仍需用C++编程以外，其余的像内存分配、设备控制、编译等工作都可以使用python进行，还是便利了不少。经过我的资料查找，我认为学习顺序如下：</p><blockquote><ol><li>推荐先阅读<a href="https://zhuanlan.zhihu.com/p/34587739" rel="external nofollow noopener noreferrer" target="_blank">CUDA编程入门极简教程</a> ，介绍了CUDA编程的原理，异构编程执行逻辑，编程基础，CUDA编程的逻辑层和物理层介绍</li><li>学习<a href="https://documen.tician.de/pycuda/tutorial.html" rel="external nofollow noopener noreferrer" target="_blank">PyCUDA Tutorial</a>，熟悉PyCUDA的API</li><li>学习<a href="http://wiki.tiker.net/PyCuda/Examples" rel="external nofollow noopener noreferrer" target="_blank">PyCUDA Examples</a>，学习实际应用中的代码</li></ol></blockquote><p>官方站点如下：</p><blockquote><ul><li><a href="https://github.com/inducer/pycuda" rel="external nofollow noopener noreferrer" target="_blank">PyCUDA Github</a></li><li><a href="https://mathema.tician.de/software/pycuda/" rel="external nofollow noopener noreferrer" target="_blank">PyCUDA Site</a></li><li><a href="https://documen.tician.de/pycuda/" rel="external nofollow noopener noreferrer" target="_blank">PyCUDA Document</a></li><li><a href="https://wiki.tiker.net/PyCuda" rel="external nofollow noopener noreferrer" target="_blank">PyCUDA wiki</a></li></ul></blockquote><p>本文实际是对官方文档、例子的翻译，加入了一点注释和自己的思考。可以直接食用本文，也可学习上方列出的官方资料。不过学习本文之前最好先阅读<a href="https://zhuanlan.zhihu.com/p/34587739" rel="external nofollow noopener noreferrer" target="_blank">CUDA编程入门极简教程</a>。</p><p>写完本文后，笔者也试着实现工作中需要使用GPU的一个算法。感觉几个坐标系比较容易弄混：图片的宽高、block的x,y坐标、thread的x,y坐标。仅仅是写出可用，不追求极致的效率、并行的话，其余的部分倒没有太难。</p><h2 id="2-安装"><a href="#2-安装" class="headerlink" title="2. 安装"></a>2. 安装</h2><p>Linux下的官方的PyCUDA<a href="https://wiki.tiker.net/PyCuda/Installation" rel="external nofollow noopener noreferrer" target="_blank">安装步骤</a>大概如下：</p><blockquote><ol><li>确保CUDA已正确安装并配置</li><li>安装CUDA对应版本的gcc</li><li>安装Boost C++</li><li>安装numpy</li><li>安装PyCUDA</li></ol></blockquote><p>但搞深度学习的一般都使用了docker，带深度学习框架的镜像中通常都有CUDA、boost、numpy等，实测只需进行第5步：</p><pre><code># 安装依赖库
apt-get install build-essential python-dev python-setuptools libboost-python-dev libboost-thread-dev -y

#安装PyCUDA
pip install pycuda
</code></pre><p>还是非常简单方便的。</p><h2 id="3-Tutorial"><a href="#3-Tutorial" class="headerlink" title="3. Tutorial"></a>3. Tutorial</h2><p>本章是对<a href="https://documen.tician.de/pycuda/tutorial.html" rel="external nofollow noopener noreferrer" target="_blank">官方Tutorial</a>的一个翻译，供日后查阅。</p><h3 id="Getting-started"><a href="#Getting-started" class="headerlink" title="Getting started"></a>Getting started</h3><p>import与初始化</p><pre><code>import pycuda.driver as cuda
import pycuda.autoinit
from pycuda.compiler import SourceModule
</code></pre><h3 id="Transferring-Data"><a href="#Transferring-Data" class="headerlink" title="Transferring Data"></a>Transferring Data</h3><p>数据的转移。</p><p>将数据从<code>host</code>（CPU与内存）转移到<code>device</code>（GPU与显存）。数据通常是<code>numpy</code>格式，但其实任何满足python buffer接口的类型都可以，甚至是<code>str</code>。</p><p>创建一个$4 \times 4$的随机数矩阵：</p><pre><code>import numpy
a = numpy.random.randn(4,4)
</code></pre><p>a中是双精度浮点数，而NVIDIA设备通常只支持单精度：</p><pre><code>a = a.astype(numpy.float32)
</code></pre><p>在device上为a分配所需的显存：</p><pre><code>a_gpu = cuda.mem_alloc(a.nbytes)
</code></pre><p>将数据转移到GPU:</p><pre><code>cuda.memcpy_htod(a_gpu, a)
</code></pre><h3 id="Executing-a-Kernel"><a href="#Executing-a-Kernel" class="headerlink" title="Executing a Kernel"></a>Executing a Kernel</h3><p>CUDA计算：kernel函数</p><p>本节将把<code>a_gpu</code>中的值翻倍。</p><p>首先，编写对应的CUDA C代码，并送入<code>pycuda.compiler.SourceModule</code>：</p><pre><code>mod = SourceModule("""
  __global__ void doublify(float *a)
  {
    int idx = threadIdx.x + threadIdx.y*4;
    a[idx] *= 2;
  }
  """)
</code></pre><p>如果没有报错，则代码已成功编译并载入了device。我们得到一个对我们<code>pycuda.driver.Function</code>的引用并调用它。使用<code>a_gpu</code>为参数，block size为$4 \times 4$:</p><pre><code>func = mod.get_function("doublify")
func(a_gpu, block=(4,4,1))
</code></pre><p>最后，我们从GPU获得结果并打印它：</p><pre><code>a_doubled = numpy.empty_like(a)
cuda.memcpy_dtoh(a_doubled, a_gpu)
print a_doubled
print a
</code></pre><p>结果如下：</p><pre><code>[[ 0.51360393  1.40589952  2.25009012  3.02563429]
 [-0.75841576 -1.18757617  2.72269917  3.12156057]
 [ 0.28826082 -2.92448163  1.21624792  2.86353827]
 [ 1.57651746  0.63500965  2.21570683 -0.44537592]]
[[ 0.25680196  0.70294976  1.12504506  1.51281714]
 [-0.37920788 -0.59378809  1.36134958  1.56078029]
 [ 0.14413041 -1.46224082  0.60812396  1.43176913]
 [ 0.78825873  0.31750482  1.10785341 -0.22268796]]
</code></pre><h3 id="Shortcuts-for-Explicit-Memory-Copies"><a href="#Shortcuts-for-Explicit-Memory-Copies" class="headerlink" title="Shortcuts for Explicit Memory Copies"></a>Shortcuts for Explicit Memory Copies</h3><p>Argument handler <code>pycuda.driver.In</code>, <code>pycuda.driver.Out</code>, 和<code>pycuda.driver.InOut</code>能简化内存转移。上个例子中，如果可以覆盖<code>a</code>，则不需要创建<code>a_gpu</code>:</p><pre><code>func(cuda.InOut(a), block=(4, 4, 1))
</code></pre><h3 id="Bonus-Abstracting-Away-the-Complications"><a href="#Bonus-Abstracting-Away-the-Complications" class="headerlink" title="Bonus: Abstracting Away the Complications"></a>Bonus: Abstracting Away the Complications</h3><p>代码简化方法，无需编写kernel C++代码</p><p>使用<code>pycuda.gpuarray.GPUArray</code>，可以获得上个例子的同样效果：</p><pre><code>import pycuda.gpuarray as gpuarray
import pycuda.driver as cuda
import pycuda.autoinit
import numpy

a_gpu = gpuarray.to_gpu(numpy.random.randn(4,4).astype(numpy.float32))
a_doubled = (2*a_gpu).get()
print a_doubled
print a_gpu
</code></pre><h3 id="Advanced-Topics"><a href="#Advanced-Topics" class="headerlink" title="Advanced Topics"></a>Advanced Topics</h3><h4 id="Structures"><a href="#Structures" class="headerlink" title="Structures"></a>Structures</h4><p>假定我们有如下structure，用于对一个可变长度的array进行翻倍。<code>ptr</code>是array的指针，<code>datalen</code>规定了长度，<code>__padding</code>用于64位对齐：</p><pre><code>mod = SourceModule("""
struct DoubleOperation {
    int datalen, __padding; // so 64-bit ptrs can be aligned
    float *ptr;
};

__global__ void double_array(DoubleOperation *a) {
    a = &amp;a[blockIdx.x];
    for (int idx = threadIdx.x; idx &lt; a-&gt;datalen; idx += blockDim.x) {
        a-&gt;ptr[idx] *= 2;
    }
}
""")
</code></pre><p><code>grid</code>中的每个<code>block</code>（这是CUDA中的概念，见官方文档，或本文第一章中推荐的入门博客）会为array中的一个元素进行翻倍。里面的<code>for</code>循环可以允许比<code>threads</code>多的data elements被翻倍，但如果确定<code>threads</code>数量足够的话，这样效率不高。</p><p>接下来，为structure创建一个wrapper类，并初始化两个array：</p><pre><code>class DoubleOpStruct:
    # 计算内存大小，8是固定的8个字节，struct中datalen和__padding的占用。intp是numpy中用作指针的数据类型，nbytes意思是占用的字节数。这里不直接写4或8，而是通过numpy获取指针所需字节数，避免写死到64位或32位环境
    mem_size = 8 + numpy.intp(0).nbytes
    '''构造函数，第一个参数为python数组，第二个参数为要转移到的指针地址 '''
    def __init__(self, array, struct_arr_ptr):
        self.data = cuda.to_device(array)
        self.shape, self.dtype = array.shape, array.dtype
        # 转移datalen
        cuda.memcpy_htod(int(struct_arr_ptr), numpy.getbuffer(numpy.int32(array.size)))
        # 转移数组
        cuda.memcpy_htod(int(struct_arr_ptr) + 8, numpy.getbuffer(numpy.intp(int(self.data))))
    def __str__(self):
        return str(cuda.from_device(self.data, self.shape, self.dtype))

# 分配两个struct大小的内存，返回指针
struct_arr = cuda.mem_alloc(2 * DoubleOpStruct.mem_size)
# 通过偏移得到第二个的指针
do2_ptr = int(struct_arr) + DoubleOpStruct.mem_size

# 初始化两个wrapper类,分别为[1, 2, 3]和[0, 4]
array1 = DoubleOpStruct(numpy.array([1, 2, 3], dtype=numpy.float32), struct_arr)
array2 = DoubleOpStruct(numpy.array([0, 4], dtype=numpy.float32), do2_ptr)
print("original arrays", array1, array2)
</code></pre><p>上方代码使用了 <code>pycuda.driver.to_device()</code>和<code>pycuda.driver.from_device()</code>两个函数进行了值的allocate和copy。并演示了对内存已分配的block的用法。</p><p>接下来的代码对两个数组进行了翻倍，并只对第二个进行了翻倍：</p><pre><code>func = mod.get_function("double_array")
func(struct_arr, block = (32, 1, 1), grid=(2, 1))
print("doubled arrays", array1, array2)

func(numpy.intp(do2_ptr), block = (32, 1, 1), grid=(1, 1))
print("doubled second only", array1, array2, "\n")
</code></pre><p>注意对两个array进行翻倍时，grid尺寸为<code>(2,1)</code>，而单个时为<code>(1,1)</code>，即每个grid负责一个array的计算。注意对两个翻倍仅需执行一次，因为分配了两个gird。而通过偏移得到的指针需要用<code>numpy.intp()</code>函数封装一下，需要注意。</p><p>这里有点困惑的地方是block尺寸的设置，两个都设为了<code>(32,1,1)</code>。我更倾向于这里的32是随便写的，因为第一个例子里的<code>4*4</code>矩阵翻倍，block设为了<code>(4,4,1)</code>，即block里共<code>4*4</code>个threads，每个只为矩阵中的1个元素翻倍。我认为本例的kernel函数中由于有for循环，故block可以随意设置。笔者尝试过<code>(1,1,1)</code>，同样能够见效。如果这里理解有误，欢迎留言告知。</p><p>官方Tutorial到此结束。关于后续的学习，它推荐了Device Interface以及官方Example。</p><h2 id="4-Device-Interface"><a href="#4-Device-Interface" class="headerlink" title="4. Device Interface"></a>4. Device Interface</h2><p>设备相关接口，只做简单记录不进行全文翻译，详细可查看<a href="https://documen.tician.de/pycuda/driver.html#reference-doc" rel="external nofollow noopener noreferrer" target="_blank">Device Interface</a>。</p><p>可以查询版本，定义了Exception，定义了常量，定义了device和context，并发和流的相关函数，memory相关函数，以及在device上编程需要的<code>Module</code>和<code>Functions</code>。</p><h2 id="5-Metaprogramming"><a href="#5-Metaprogramming" class="headerlink" title="5. Metaprogramming"></a>5. Metaprogramming</h2><p>传统的软件开发，人们编写程序完成一个任务。而在<em>metaprogramming</em>中，人们编写程序来编写程序完成一个任务。</p><p>这听起来很复杂，我们先来看看为啥这是一个好主意。</p><h3 id="Why-metaprogramming"><a href="#Why-metaprogramming" class="headerlink" title="Why metaprogramming?"></a>Why metaprogramming?</h3><h4 id="Automated-Tuning"><a href="#Automated-Tuning" class="headerlink" title="Automated Tuning"></a>Automated Tuning</h4><p>CUDA程序员很多时间都用在了代码tuning上：</p><ul><li>每个block的thread数量为多少最优？</li><li>我每次需要处理多少数据？</li><li>哪些数据需加载到共享内存中，以及corresponding blocks需多大？</li></ul><p>幸运的话你可以形成一种模式，很快地选出最快的版本。但当下一代硬件出现时，这会失效。</p><p>PyCUDA的解决方案是：</p><blockquote><p>Forget heuristics. Benchmark at run time and use whatever works fastest.</p></blockquote><p>这也是PyCUDA相比CUDA的重要优点：它可以让你在代码运行时进行决策。</p><h4 id="Data-Types"><a href="#Data-Types" class="headerlink" title="Data Types"></a>Data Types</h4><p>代码运行时可能会需要处理多种数据类型。如单精度或双精度浮点数。你可以预编译两个版本，但何苦呢。只用在需要时生成需要的代码即可。</p><h4 id="Specialize-Code-for-the-Given-Problem"><a href="#Specialize-Code-for-the-Given-Problem" class="headerlink" title="Specialize Code for the Given Problem"></a>Specialize Code for the Given Problem</h4><p>假如你需要实现一个库，需要完成某些任务。想象一下如果你能为被需要的任务生成代码，而不是让代码不必要的泛化从而变慢，这有多爽。PyCUDA能让这变成现实。</p><h4 id="Constants-are-Faster-than-Variables"><a href="#Constants-are-Faster-than-Variables" class="headerlink" title="Constants are Faster than Variables"></a>Constants are Faster than Variables</h4><p>如果你每次运行时问题的大小变化很大，但你为唯一尺寸的数据进行了大量kernel调用时，你可以考虑把代码中的数据尺寸编译为常量。这会带来显著的性能提升，主要来自fetch时间的减少和register pressure的降低。不仅如此，乘以一个常量也比变量乘变量执行得更高效。</p><h4 id="Loop-Unrolling"><a href="#Loop-Unrolling" class="headerlink" title="Loop Unrolling"></a>Loop Unrolling</h4><p>CUDA编程手册介绍了<code>nvcc</code>以及其loop unroll功能。但据PyCUDA作者实验，在V2.1后就不是这么回事了。而通过元编程，可以自动地把循环unroll到需要的size。</p><h3 id="Metaprogramming-using-a-Templating-Engine"><a href="#Metaprogramming-using-a-Templating-Engine" class="headerlink" title="Metaprogramming using a Templating Engine"></a>Metaprogramming using a Templating Engine</h3><p>如果元编程需求比较简单，那么模板引擎是比较好的选择。Python有很多模板引擎，推荐<a href="http://jinja.pocoo.org/" rel="external nofollow noopener noreferrer" target="_blank">Jinja 2</a>和<a href="http://www.cheetahtemplate.org/" rel="external nofollow noopener noreferrer" target="_blank">Cheetah</a>。</p><p>下面的代码是在可配置的block size下进行向量加法的简单元程序：</p><pre><code>from jinja2 import Template

tpl = Template("""
    __global__ void add(
            {{ type_name }} *tgt,
            {{ type_name }} *op1,
            {{ type_name }} *op2)
    {
      int idx = threadIdx.x +
        {{ thread_block_size }} * {{block_size}}
        * blockIdx.x;

      {% for i in range(block_size) %}
              {% set offset = i*thread_block_size %}
              tgt[idx + {{ offset }}] =
                op1[idx + {{ offset }}]
                + op2[idx + {{ offset }}];
          {% endfor %}
    }""")

rendered_tpl = tpl.render(
    type_name="float", block_size=block_size,
    thread_block_size=thread_block_size)

mod = SourceModule(rendered_tpl)
</code></pre><p>可运行的代码见<code>examples/demo_meta_template.py</code>。还有使用Cheetah的模板元编程的矩阵乘法：<code>demo_meta_matrixmul_cheetah.py</code>和<code>demo_meta_matrixmul_cheetah.template.cu</code>。</p><h3 id="Metaprogramming-using-codepy"><a href="#Metaprogramming-using-codepy" class="headerlink" title="Metaprogramming using codepy"></a>Metaprogramming using <code>codepy</code></h3><p>更复杂的元编程，模板引擎就无法满足了。<code>codepy</code>提供了一种从python数据结构生成CUDA源代码的方法。</p><p>下方例子与上一个例子用途一致：</p><pre><code>from codepy.cgen import FunctionBody, \
    FunctionDeclaration, Typedef, POD, Value, \
    Pointer, Module, Block, Initializer, Assign
from codepy.cgen.cuda import CudaGlobal

mod = Module([
    FunctionBody(
        CudaGlobal(FunctionDeclaration(
            Value("void", "add"),
            arg_decls=[Pointer(POD(dtype, name))
                for name in ["tgt", "op1", "op2"]])),
        Block([
            Initializer(
                POD(numpy.int32, "idx"),
                "threadIdx.x + %d*blockIdx.x"
                % (thread_block_size*block_size)),
            ]+[
            Assign(
                "tgt[idx+%d]" % (o*thread_block_size),
                "op1[idx+%d] + op2[idx+%d]" % (
                    o*thread_block_size,
                    o*thread_block_size))
            for o in range(block_size)]))])

mod = SourceModule(mod)
</code></pre><p>完整代码见<code>examples/demo_meta_codepy.py</code>。</p><p>官方文档后续还介绍了Profiler、JIT编译、OpenGL、GPU Arrays、一些接口。不一一赘述了，接下来开始学习一些Example。</p><h2 id="6-Examples"><a href="#6-Examples" class="headerlink" title="6. Examples"></a>6. Examples</h2><p>官方共给出了42个demo，本文只会对博主觉得需要学习的进行说明。</p><h3 id="hello-gpu-py"><a href="#hello-gpu-py" class="headerlink" title="hello_gpu.py"></a>hello_gpu.py</h3><p>这个demo使用CUDA计算了两个长度为400的随机向量的积，并将结果与python计算的积相减，结果应为0向量。</p><pre><code>from __future__ import print_function
from __future__ import absolute_import
import pycuda.driver as drv
import pycuda.tools
import pycuda.autoinit
import numpy
import numpy.linalg as la
from pycuda.compiler import SourceModule

mod = SourceModule("""
__global__ void multiply_them(float *dest, float *a, float *b)
{
  const int i = threadIdx.x;
  dest[i] = a[i] * b[i];
}
""")

multiply_them = mod.get_function("multiply_them")

a = numpy.random.randn(400).astype(numpy.float32)
b = numpy.random.randn(400).astype(numpy.float32)

dest = numpy.zeros_like(a)
multiply_them(
        drv.Out(dest), drv.In(a), drv.In(b),
        block=(400,1,1))

print(dest-a*b)
</code></pre><h3 id="demo-py"><a href="#demo-py" class="headerlink" title="demo.py"></a>demo.py</h3><p>Tutorial中的代码，为一个<code>(4*4)</code>矩阵翻倍，分别是原始写法、通过<code>InOut</code>的简便写法、以及使用<code>gpuarray</code>的无kernel写法。</p><pre><code># Sample source code from the Tutorial Introduction in the documentation.
from __future__ import print_function
from __future__ import absolute_import
import pycuda.driver as cuda
import pycuda.autoinit  # noqa
from pycuda.compiler import SourceModule

import numpy
a = numpy.random.randn(4, 4)

a = a.astype(numpy.float32)

a_gpu = cuda.mem_alloc(a.size * a.dtype.itemsize)

cuda.memcpy_htod(a_gpu, a)

mod = SourceModule("""
    __global__ void doublify(float *a)
    {
      int idx = threadIdx.x + threadIdx.y*4;
      a[idx] *= 2;
    }
    """)

func = mod.get_function("doublify")
func(a_gpu, block=(4, 4, 1), grid=(1, 1), shared=0)

a_doubled = numpy.empty_like(a)
cuda.memcpy_dtoh(a_doubled, a_gpu)
print("original array:")
print(a)
print("doubled with kernel:")
print(a_doubled)

# alternate kernel invocation -------------------------------------------------

func(cuda.InOut(a), block=(4, 4, 1))
print("doubled with InOut:")
print(a)

# part 2 ----------------------------------------------------------------------

import pycuda.gpuarray as gpuarray
a_gpu = gpuarray.to_gpu(numpy.random.randn(4, 4).astype(numpy.float32))
a_doubled = (2*a_gpu).get()

print("original array:")
print(a_gpu)
print("doubled with gpuarray:")
print(a_doubled)
</code></pre><h3 id="demo-struct-py"><a href="#demo-struct-py" class="headerlink" title="demo_struct.py"></a>demo_struct.py</h3><p>Tutorial中的Advance topic里的代码</p><pre><code># prepared invocations and structures -----------------------------------------
from __future__ import print_function
from __future__ import absolute_import
import pycuda.driver as cuda
import pycuda.autoinit
import numpy
from pycuda.compiler import SourceModule

class DoubleOpStruct:
    mem_size = 8 + numpy.uintp(0).nbytes
    def __init__(self, array, struct_arr_ptr):
        self.data = cuda.to_device(array)
        self.shape, self.dtype = array.shape, array.dtype
        """
        numpy.getbuffer() needed due to lack of new-style buffer interface for
        scalar numpy arrays as of numpy version 1.9.1

        see: https://github.com/inducer/pycuda/pull/60
        """
        cuda.memcpy_htod(int(struct_arr_ptr),
                         numpy.getbuffer(numpy.int32(array.size)))
        cuda.memcpy_htod(int(struct_arr_ptr) + 8,
                         numpy.getbuffer(numpy.uintp(int(self.data))))

    def __str__(self):
        return str(cuda.from_device(self.data, self.shape, self.dtype))


struct_arr = cuda.mem_alloc(2 * DoubleOpStruct.mem_size)
do2_ptr = int(struct_arr) + DoubleOpStruct.mem_size

array1 = DoubleOpStruct(numpy.array([1, 2, 3], dtype=numpy.float32), struct_arr)
array2 = DoubleOpStruct(numpy.array([0, 4], dtype=numpy.float32), do2_ptr)

print("original arrays")
print(array1)
print(array2)

mod = SourceModule("""
    struct DoubleOperation {
        int datalen, __padding; // so 64-bit ptrs can be aligned
        float *ptr;
    };


    __global__ void double_array(DoubleOperation *a)
    {
        a = a + blockIdx.x;
        for (int idx = threadIdx.x; idx &lt; a-&gt;datalen; idx += blockDim.x)
        {
            float *a_ptr = a-&gt;ptr;
            a_ptr[idx] *= 2;
        }
    }
    """)
func = mod.get_function("double_array")
func(struct_arr, block=(32, 1, 1), grid=(2, 1))

print("doubled arrays")
print(array1)
print(array2)

func(numpy.uintp(do2_ptr), block=(32, 1, 1), grid=(1, 1))
print("doubled second only")
print(array1)
print(array2)

if cuda.get_version() &lt; (4, ):
    func.prepare("P", block=(32, 1, 1))
    func.prepared_call((2, 1), struct_arr)
else:
    func.prepare("P")
    block = (32, 1, 1)
    func.prepared_call((2, 1), block, struct_arr)


print("doubled again")
print(array1)
print(array2)

if cuda.get_version() &lt; (4, ):
    func.prepared_call((1, 1), do2_ptr)
else:
    func.prepared_call((1, 1), block, do2_ptr)


print("doubled second only again")
print(array1)
print(array2)
</code></pre><p>需要注意代码里提到了由于numpy高版本的原因，需要用<code>numpy.getbuffer(numpy.uintp(int(self.data)))</code>来传输数据。</p><h3 id="demo-elementwise-py"><a href="#demo-elementwise-py" class="headerlink" title="demo_elementwise.py"></a>demo_elementwise.py</h3><p>利用<code>pycuda.elementwise.ElementwiseKernel</code>完成的一次向量的加权线性组合运算。<code>ElementwiseKernel</code>的参数全都是字符串，第一个参数为入参声明，第二个参数叫<code>operation</code>定义了返回值的计算方法，其中用到了第四个参数声明的一个kernel函数。第三个参数为name。第四个参数可以引入其他文件，或者定义被<code>operation</code>使用的函数。</p><pre><code>from __future__ import absolute_import
import pycuda.gpuarray as gpuarray
import pycuda.autoinit
import numpy
from pycuda.curandom import rand as curand

a_gpu = curand((50,))
b_gpu = curand((50,))

from pycuda.elementwise import ElementwiseKernel
lin_comb = ElementwiseKernel(
        "float a, float *x, float b, float *y, float *z",
        "z[i] = my_f(a*x[i], b*y[i])",
        "linear_combination",
        preamble="""
        __device__ float my_f(float x, float y)
        { 
          return sin(x*y);
        }
        """)

c_gpu = gpuarray.empty_like(a_gpu)
lin_comb(5, a_gpu, 6, b_gpu, c_gpu)

import numpy.linalg as la
assert la.norm(c_gpu.get() - numpy.sin((5*a_gpu*6*b_gpu).get())) &lt; 1e-5
print(c_gpu)
</code></pre><h3 id="SimpleSpeedTest-py"><a href="#SimpleSpeedTest-py" class="headerlink" title="SimpleSpeedTest.py"></a>SimpleSpeedTest.py</h3><p>对比了GPU运算和CPU运算的速度。不管是作者注释中给出的结果还是博主实测的结果，GPU都大幅领先CPU。而GPU的几种不同实现中，<code>SourceModule</code>最为优秀，<code>GPUArray</code>表现最差。使用<code>ElementWise</code>的，在C++里循环的比在python里循环的快很多。可见最好还是完全使用C++源码实现kernel函数。</p><pre><code># Very simple speed testing code
# Shows you how to run a loop over sin() using different methods
# with a note of the time each method takes
# For the GPU this uses SourceModule, ElementwiseKernel, GPUArray
# For the CPU this uses numpy
# Ian@IanOzsvald.com

# Using a WinXP Intel Core2 Duo 2.66GHz CPU (1 CPU used)
# with a 9800GT GPU I get the following timings (smaller is better):
#
# Using nbr_values == 8192
# Calculating 100000 iterations
# SourceModule time and first three results:
# 0.166590s, [ 0.005477  0.005477  0.005477]
# Elementwise time and first three results:
# 0.171657s, [ 0.005477  0.005477  0.005477]
# Elementwise Python looping time and first three results:
# 1.487470s, [ 0.005477  0.005477  0.005477]
# GPUArray time and first three results:
# 4.740007s, [ 0.005477  0.005477  0.005477]
# CPU time and first three results:
# 32.933660s, [ 0.005477  0.005477  0.005477]
#
#
# Using Win 7 x64, GTX 470 GPU, X5650 Xeon,
# Driver v301.42, CUDA 4.2, Python 2.7 x64,
# PyCuda 2012.1 gave the following results:
#
# Using nbr_values == 8192
# Calculating 100000 iterations
# SourceModule time and first three results:
# 0.058321s, [ 0.005477  0.005477  0.005477]
# Elementwise time and first three results:
# 0.102110s, [ 0.005477  0.005477  0.005477]
# Elementwise Python looping time and first three results:
# 2.428810s, [ 0.005477  0.005477  0.005477]
# GPUArray time and first three results:
# 8.421861s, [ 0.005477  0.005477  0.005477]
# CPU time measured using :
# 5.905661s, [ 0.005477  0.005477  0.005477]


import pycuda.driver as drv
import pycuda.tools
import pycuda.autoinit
import numpy
from pycuda.compiler import SourceModule
import pycuda.gpuarray as gpuarray
import pycuda.cumath
from pycuda.elementwise import ElementwiseKernel

blocks = 64
block_size = 128
nbr_values = blocks * block_size

print "Using nbr_values ==", nbr_values

# Number of iterations for the calculations,
# 100 is very quick, 2000000 will take a while
n_iter = 100000
print "Calculating %d iterations" % (n_iter)

# create two timers so we can speed-test each approach
start = drv.Event()
end = drv.Event()

######################
# SourceModele SECTION
# We write the C code and the indexing and we have lots of control

mod = SourceModule("""
__global__ void gpusin(float *dest, float *a, int n_iter)
{
  const int i = blockDim.x*blockIdx.x + threadIdx.x;
  for(int n = 0; n &lt; n_iter; n++) {
    a[i] = sin(a[i]);
  }
  dest[i] = a[i];
}
""")

gpusin = mod.get_function("gpusin")

# create an array of 1s
a = numpy.ones(nbr_values).astype(numpy.float32)
# create a destination array that will receive the result
dest = numpy.zeros_like(a)

start.record() # start timing
gpusin(drv.Out(dest), drv.In(a), numpy.int32(n_iter), grid=(blocks,1), block=(block_size,1,1) )
end.record() # end timing
# calculate the run length
end.synchronize()
secs = start.time_till(end)*1e-3
print "SourceModule time and first three results:"
print "%fs, %s" % (secs, str(dest[:3]))


#####################
# Elementwise SECTION
# use an ElementwiseKernel with sin in a for loop all in C call from Python
kernel = ElementwiseKernel(
   "float *a, int n_iter",
   "for(int n = 0; n &lt; n_iter; n++) { a[i] = sin(a[i]);}",
   "gpusin")

a = numpy.ones(nbr_values).astype(numpy.float32)
a_gpu = gpuarray.to_gpu(a)
start.record() # start timing
kernel(a_gpu, numpy.int(n_iter))
end.record() # end timing
# calculate the run length
end.synchronize()
secs = start.time_till(end)*1e-3
print "Elementwise time and first three results:"
print "%fs, %s" % (secs, str(a_gpu.get()[:3]))


####################################
# Elementwise Python looping SECTION
# as Elementwise but the for loop is in Python, not in C
kernel = ElementwiseKernel(
   "float *a",
   "a[i] = sin(a[i]);",
   "gpusin")

a = numpy.ones(nbr_values).astype(numpy.float32)
a_gpu = gpuarray.to_gpu(a)
start.record() # start timing
for i in range(n_iter):
    kernel(a_gpu)
end.record() # end timing
# calculate the run length
end.synchronize()
secs = start.time_till(end)*1e-3
print "Elementwise Python looping time and first three results:"
print "%fs, %s" % (secs, str(a_gpu.get()[:3]))


##################
# GPUArray SECTION
# The result is copied back to main memory on each iteration, this is a bottleneck

a = numpy.ones(nbr_values).astype(numpy.float32)
a_gpu = gpuarray.to_gpu(a)
start.record() # start timing
for i in range(n_iter):
    a_gpu = pycuda.cumath.sin(a_gpu)
end.record() # end timing
# calculate the run length
end.synchronize()
secs = start.time_till(end)*1e-3
print "GPUArray time and first three results:"
print "%fs, %s" % (secs, str(a_gpu.get()[:3]))


#############
# CPU SECTION
# use numpy the calculate the result on the CPU for reference

a = numpy.ones(nbr_values).astype(numpy.float32)
start.record() # start timing
start.synchronize()

for i in range(n_iter):
    a = numpy.sin(a)

end.record() # end timing
# calculate the run length
end.synchronize()
secs = start.time_till(end)*1e-3
print "CPU time and first three results:"
print "%fs, %s" % (secs, str(a[:3]))
</code></pre><h3 id="ThreadsAndBlocks-py"><a href="#ThreadsAndBlocks-py" class="headerlink" title="ThreadsAndBlocks.py"></a>ThreadsAndBlocks.py</h3><p>这个demo演示了<code>grid</code>、<code>block</code>和<code>thread</code>之间的关系。</p><pre><code>import pycuda.driver as cuda
import pycuda.autoinit
from pycuda.compiler import SourceModule

mod = SourceModule("""
    #include &lt;stdio.h&gt;

    __global__ void say_hi()
    {
      printf("I am %dth thread in threadIdx.x:%d.threadIdx.y:%d  blockIdx.:%d blockIdx.y:%d blockDim.x:%d blockDim.y:%d\\n",(threadIdx.x+threadIdx.y*blockDim.x+(blockIdx.x*blockDim.x*blockDim.y)+(blockIdx.y*blockDim.x*blockDim.y)),threadIdx.x, threadIdx.y,blockIdx.x,blockIdx.y,blockDim.x,blockDim.y);
    }
    """)

func = mod.get_function("say_hi")
func(block=(4,4,1),grid=(2,2,1))
</code></pre><p>kernel函数那一坨有点不方便阅读，单独摘出来：</p><pre><code>#include &lt;stdio.h&gt;

    __global__ void say_hi()
    {
      printf("I am %dth thread 
      in threadIdx.x:%d.
      threadIdx.y:%d  
      blockIdx.:%d 
      blockIdx.y:%d 
      blockDim.x:%d 
      blockDim.y:%d\\n"
      ,(threadIdx.x+threadIdx.y*blockDim.x+(blockIdx.x*blockDim.x*blockDim.y)+(blockIdx.y*blockDim.x*blockDim.y))
      ,threadIdx.x
      ,threadIdx.y
      ,blockIdx.x
      ,blockIdx.y
      ,blockDim.x
      ,blockDim.y);
    }
</code></pre><p>kernel中可访问到以下属性，用于进行运算任务的分配：</p><ul><li><code>blockDim.x</code></li><li><code>blockDim.y</code></li><li><code>blockIdx.x</code></li><li><code>blockIdx.y</code></li><li><code>threadIdx.x</code></li><li><code>threadIdx.y</code></li></ul><p>其中<code>blockDim</code>为每个block的维度，被参数<code>block=(4,4,1)</code>控制，<code>threadIdx</code>将无法超过这个值，每个<code>block</code>中有16个<code>thread</code>。<code>blockIdx</code>是<code>block</code>在<code>grid</code>中的坐标，<code>grid</code>维度为<code>grid=(2,2,1)</code>，每个<code>grid</code>中有4个<code>block</code>。</p><p>demo中，thread的计数是<code>threadIdx.x + threadIdx.y * blockDim.x + (blockIdx.x * blockDim.x * blockDim.y) + (blockIdx.y * blockDim.x * blockDim.y</code>这样计算的。但在gird中，沿斜对角线对称的<code>block</code>里的<code>thread</code>，计算出的id会重复。</p><h3 id="MatrixmulSimple-py"><a href="#MatrixmulSimple-py" class="headerlink" title="MatrixmulSimple.py"></a>MatrixmulSimple.py</h3><p>用一个block计算两个矩阵的乘法，即每个thread负责计算结果矩阵中自己坐标位置的元素的值。</p><p>原demo为计算两个方阵的乘，改造为<code>[M*N] * [N*M]</code>。</p><pre><code>#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
Multiplies two square matrices together using a *single* block of threads and
global memory only. Each thread computes one element of the resulting matrix.
"""

import numpy as np
from pycuda import driver, compiler, gpuarray, tools

# -- initialize the device
import pycuda.autoinit

# [M*N] * [N*M] matrix multiply
kernel_code_template = """
__global__ void MatrixMulKernel(float *a, float *b, float *c)
{
    // 2D Thread ID (assuming that only *one* block will be executed)
    // y responsible for the left matrix's row
    // x responsible for the right matrix's column
    // calculate the result matrix[x,y]'s element's value
    int tx = threadIdx.x;
    int ty = threadIdx.y;

    // Pvalue is used to store the element of the matrix
    // that is computed by the thread
    float Pvalue = 0;

    // Each thread loads one row of M and one column of N,
    //   to produce one element of P.
    for (int i = 0; i &lt; %(N)s; ++i) {
        float Aelement = a[ty * %(N)s + i];
        float Belement = b[i * %(M)s + tx];
        Pvalue += Aelement * Belement;
    }

    // Write the matrix to device memory;
    // each thread writes one element
    c[ty * %(M)s + tx] = Pvalue;
}
"""

# define the (square) matrix size
#  note that we'll only use *one* block of threads here
#  as a consequence this number (squared) can't exceed max_threads,
#  see http://documen.tician.de/pycuda/util.html#pycuda.tools.DeviceData
#  for more information on how to get this number for your device
M = 2
N = 3

# create two random square matrices
a_cpu = np.random.randn(M, N).astype(np.float32)
b_cpu = np.random.randn(N, M).astype(np.float32)

# compute reference on the CPU to verify GPU computation
c_cpu = np.dot(a_cpu, b_cpu)

# transfer host (CPU) memory to device (GPU) memory
a_gpu = gpuarray.to_gpu(a_cpu)
b_gpu = gpuarray.to_gpu(b_cpu)

# create empty gpu array for the result (C = A * B)
c_gpu = gpuarray.empty((M, M), np.float32)

# get the kernel code from the template
# by specifying the constant MATRIX_SIZE
kernel_code = kernel_code_template % {
    'M': M,
    'N': N
    }

# compile the kernel code
mod = compiler.SourceModule(kernel_code)

# get the kernel function from the compiled module
matrixmul = mod.get_function("MatrixMulKernel")

# call the kernel on the card
matrixmul(
    # inputs
    a_gpu, b_gpu,
    # output
    c_gpu,
    # (only one) block of MATRIX_SIZE x MATRIX_SIZE threads
    block = (M, M, 1),
    )

# print the results
print "-" * 80
print "Matrix A (GPU):"
print a_gpu.get()

print "-" * 80
print "Matrix B (GPU):"
print b_gpu.get()

print "-" * 80
print "Matrix C (GPU):"
print c_gpu.get()

print "-" * 80
print "Matrix C (CPU):"
print c_cpu

print "-" * 80
print "CPU-GPU difference:"
print c_cpu - c_gpu.get()

np.allclose(c_cpu, c_gpu.get())
</code></pre></div><div class="popular-posts-header">相关文章</div><ul class="popular-posts"><li class="popular-posts-item"><div class="popular-posts-title"><a href="/2018/11/20/DenseNet-Densely-Connected-Convolutional-Networks/" rel="bookmark">DenseNet: Densely Connected Convolutional Networks</a></div></li><li class="popular-posts-item"><div class="popular-posts-title"><a href="/2019/04/01/CVPR-2018-车辆Re-ID-Vehicle-Re-Identification-with-the-Space-Time-Prior/" rel="bookmark">CVPR 2018 车辆Re-ID: Vehicle Re-Identification with the Space-Time Prior</a></div></li><li class="popular-posts-item"><div class="popular-posts-title"><a href="/2019/03/31/CVPR-2018-车辆Re-ID-Viewpoint-aware-Attentive-Multi-view-Inference-for-Vehicle-Re-identification/" rel="bookmark">CVPR 2018 车辆Re-ID:Viewpoint-aware Attentive Multi-view Inference for Vehicle Re-identification</a></div></li><li class="popular-posts-item"><div class="popular-posts-title"><a href="/2019/04/09/CVPR-2019人群检测计数-PSDDN-Point-in-Box-out-Beyond-Counting-Persons-in-Crowds/" rel="bookmark">CVPR 2019人群检测计数 PSDDN Point in, Box out: Beyond Counting Persons in Crowds</a></div></li><li class="popular-posts-item"><div class="popular-posts-title"><a href="/2019/04/16/CVPR-2019-领域自适应行人Re-ID-ECN-Invariance-Matters-Exemplar-Memory-for-Domain-Adaptive-Person-Re-identification/" rel="bookmark">CVPR 2019 领域自适应行人Re-ID ECN. Invariance Matters: Exemplar Memory for Domain Adaptive Person Re-identification</a></div></li></ul><div><ul class="post-copyright"><li class="post-copyright-author"><strong>本文作者： </strong>慕湮</li><li class="post-copyright-link"><strong>本文链接：</strong> <a href="http://muyaan.com/2019/02/01/PyCUDA学习笔记/" title="PyCUDA学习笔记">http://muyaan.com/2019/02/01/PyCUDA学习笔记/</a></li><li class="post-copyright-license"><strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="external nofollow noopener noreferrer" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明出处！</li></ul></div><footer class="post-footer"><div class="post-tags"><a href="/tags/Deep-Learning/" rel="tag"># Deep Learning</a> <a href="/tags/CUDA/" rel="tag"># CUDA</a> <a href="/tags/PyCUDA/" rel="tag"># PyCUDA</a> <a href="/tags/GPU/" rel="tag"># GPU</a></div><div class="post-nav"><div class="post-nav-next post-nav-item"><a href="/2019/01/16/语义分割-U-Net-Convolutional-Networks-for-Biomedical-Image-Segmentation/" rel="next" title="语义分割 U-Net: Convolutional Networks for Biomedical Image Segmentation"><i class="fa fa-chevron-left"></i> 语义分割 U-Net: Convolutional Networks for Biomedical Image Segmentation</a></div><span class="post-nav-divider"></span><div class="post-nav-prev post-nav-item"><a href="/2019/02/04/姿态估计与追踪-Simple-Baselines-for-Human-Pose-Estimation-and-Tracking/" rel="prev" title="姿态估计与追踪: Simple Baselines for Human Pose Estimation and Tracking">姿态估计与追踪: Simple Baselines for Human Pose Estimation and Tracking <i class="fa fa-chevron-right"></i></a></div></div></footer></div></article></div></div><div class="comments" id="comments"><div id="gitment-container"></div></div></div><div class="sidebar-toggle"><div class="sidebar-toggle-line-wrap"><span class="sidebar-toggle-line sidebar-toggle-line-first"></span> <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span> <span class="sidebar-toggle-line sidebar-toggle-line-last"></span></div></div><aside id="sidebar" class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">文章目录</li><li class="sidebar-nav-overview" data-target="site-overview-wrap">站点概览</li></ul><section class="site-overview-wrap sidebar-panel"><div class="site-overview"><div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" src="https://avatars0.githubusercontent.com/u/3022000?s=460&amp;v=4" alt="慕湮"><p class="site-author-name" itemprop="name">慕湮</p><p class="site-description motion-element" itemprop="description"></p></div><nav class="site-state motion-element"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">65</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/index.html"><span class="site-state-item-count">117</span> <span class="site-state-item-name">标签</span></a></div></nav><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/tycallen" target="_blank" title="GitHub" rel="external nofollow noopener noreferrer"><i class="fa fa-fw fa-github"></i>GitHub</a> </span><span class="links-of-author-item"><a href="mailto:tyc.allen@gmail.com" target="_blank" title="E-Mail" rel="external nofollow noopener noreferrer"><i class="fa fa-fw fa-envelope"></i>E-Mail</a> </span><span class="links-of-author-item"><a href="http://weibo.com/pojunallen" target="_blank" title="微博" rel="external nofollow noopener noreferrer"><i class="fa fa-fw fa-weibo"></i>微博</a> </span><span class="links-of-author-item"><a href="https://tuchong.com/1070837" target="_blank" title="图虫" rel="external nofollow noopener noreferrer"><i class="fa fa-fw fa-globe"></i>图虫</a></span></div><div class="links-of-blogroll motion-element links-of-blogroll-block"><div class="links-of-blogroll-title"><i class="fa fa-fw fa-link"></i> 友情链接</div><ul class="links-of-blogroll-list"><li class="links-of-blogroll-item"><a href="http://dotrabbit.tk" title="dotrabbit" target="_blank" rel="external nofollow noopener noreferrer">dotrabbit</a></li></ul></div></div></section><section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active"><div class="post-toc"><div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-介绍"><span class="nav-text">1. 介绍</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-安装"><span class="nav-text">2. 安装</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-Tutorial"><span class="nav-text">3. Tutorial</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Getting-started"><span class="nav-text">Getting started</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Transferring-Data"><span class="nav-text">Transferring Data</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Executing-a-Kernel"><span class="nav-text">Executing a Kernel</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Shortcuts-for-Explicit-Memory-Copies"><span class="nav-text">Shortcuts for Explicit Memory Copies</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Bonus-Abstracting-Away-the-Complications"><span class="nav-text">Bonus: Abstracting Away the Complications</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Advanced-Topics"><span class="nav-text">Advanced Topics</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Structures"><span class="nav-text">Structures</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-Device-Interface"><span class="nav-text">4. Device Interface</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-Metaprogramming"><span class="nav-text">5. Metaprogramming</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Why-metaprogramming"><span class="nav-text">Why metaprogramming?</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Automated-Tuning"><span class="nav-text">Automated Tuning</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Data-Types"><span class="nav-text">Data Types</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Specialize-Code-for-the-Given-Problem"><span class="nav-text">Specialize Code for the Given Problem</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Constants-are-Faster-than-Variables"><span class="nav-text">Constants are Faster than Variables</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Loop-Unrolling"><span class="nav-text">Loop Unrolling</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Metaprogramming-using-a-Templating-Engine"><span class="nav-text">Metaprogramming using a Templating Engine</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Metaprogramming-using-codepy"><span class="nav-text">Metaprogramming using codepy</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-Examples"><span class="nav-text">6. Examples</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#hello-gpu-py"><span class="nav-text">hello_gpu.py</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#demo-py"><span class="nav-text">demo.py</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#demo-struct-py"><span class="nav-text">demo_struct.py</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#demo-elementwise-py"><span class="nav-text">demo_elementwise.py</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#SimpleSpeedTest-py"><span class="nav-text">SimpleSpeedTest.py</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ThreadsAndBlocks-py"><span class="nav-text">ThreadsAndBlocks.py</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#MatrixmulSimple-py"><span class="nav-text">MatrixmulSimple.py</span></a></li></ol></li></ol></div></div></section></div></aside></div></main><footer id="footer" class="footer"><div class="footer-inner"><div class="copyright">© 2015 – <span itemprop="copyrightYear">2019</span> <span class="with-love" id="animate"><i class="fa fa-user"></i> </span><span class="author" itemprop="copyrightHolder">慕湮</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-area-chart"></i> </span><span title="站点总字数">511k</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-coffee"></i> </span><span title="站点阅读时长">15:30</span></div><div class="powered-by">由 <a class="theme-link" target="_blank" rel="external nofollow noopener noreferrer" href="https://hexo.io">Hexo</a> 强力驱动</div><span class="post-meta-divider">|</span><div class="theme-info">主题 – <a class="theme-link" target="_blank" rel="external nofollow noopener noreferrer" href="https://theme-next.org">NexT.Muse</a></div></div></footer><div class="back-to-top"><i class="fa fa-arrow-up"></i></div></div><script type="text/javascript">"[object Function]"!==Object.prototype.toString.call(window.Promise)&&(window.Promise=null)</script><script type="text/javascript" src="//cdn.staticfile.org/jquery/2.1.3/jquery.min.js"></script><script type="text/javascript" src="//cdn.staticfile.org/velocity/1.2.1/velocity.min.js"></script><script type="text/javascript" src="//cdn.staticfile.org/velocity/1.2.1/velocity.ui.min.js"></script><script type="text/javascript" src="//cdn.staticfile.org/fancybox/2.1.5/jquery.fancybox.min.js"></script><script src="https://www.wenjunjiang.win/js/gitment.js"></script><style>a.gitment-editor-footer-tip{display:none}.gitment-container.gitment-footer-container{display:none}</style><script type="text/javascript" src="//cdn.jsdelivr.net/npm/mathjax@2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script async="" src="http://muyaan.com/js/src/async.js"></script><script type="text/javascript" src="/bundle.js"></script><script type="text/javascript">function renderGitment(){new Gitment({id:"1548987691000",owner:"tycallen",repo:"gitment-comments",oauth:{client_secret:"3fdf2db56aaab427df527a899947caf5b371f6d1",client_id:"9cc5e5635cdf602646a5"}}).render("gitment-container")}renderGitment();
function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();

      Counter('get', '/classes/Counter', { where: JSON.stringify({ url }) })
        .done(function ({ results }) {
          if (results.length > 0) {
            var counter = results[0];
            
              var $element = $(document.getElementById(url));
              $element.find('.leancloud-visitors-count').text(counter.time + 1);
            
            Counter('put', `/classes/Counter/${counter.objectId}`, JSON.stringify({ time: { "__op":"Increment", "amount":1 } }))
            
            .fail(function ({ responseJSON }) {
                console.log('Failed to save Visitor num, with error message: ' + responseJSON.error);
            })
          } else {
            
              Counter('post', '/classes/Counter', JSON.stringify({ title: title, url: url, time: 1}))
                .done(function () {
                  var $element = $(document.getElementById(url));
                  $element.find('.leancloud-visitors-count').text(1);
                })
                .fail(function () {
                  console.log('Failed to create');
                });
            
          }
        })
      .fail(function ({ responseJSON }) {
        console.log('LeanCloud Counter Error:' + responseJSON.code + " " + responseJSON.error);
      });
    }
    

    $(function() {
      $.get('https://app-router.leancloud.cn/2/route?appId=' + "UWGXBMGbguCDhSCbC3NrUQtL-gzGzoHsz")
        .done(function ({ api_server }) {
          var Counter = function (method, url, data) {
            return $.ajax({
              method: method,
              url: `https://${api_server}/1.1${url}`,
              headers: {
                'X-LC-Id': "UWGXBMGbguCDhSCbC3NrUQtL-gzGzoHsz",
                'X-LC-Key': "ke1jrA5b6VyR89Kqqqwf2kPP",
                'Content-Type': 'application/json',
              },
              data: data,
            });
          };
          
          addCount(Counter);
          
        })
    });;
!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}();
MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      },
      TeX: {equationNumbers: { autoNumber: "AMS" }}
    });;
MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });</script></body></html>