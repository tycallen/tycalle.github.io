<!DOCTYPE html><html class="theme-next muse use-motion" lang="zh-CN"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><script src="https://cdn.staticfile.org/pace/1.0.2/pace.min.js"></script><link href="https://cdn.staticfile.org/pace/1.0.2/themes/blue/pace-theme-big-counter.min.css" rel="stylesheet"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link href="//cdn.staticfile.org/fancybox/2.1.5/jquery.fancybox.min.js" rel="stylesheet" type="text/css"><link href="//cdn.staticfile.org/font-awesome/4.6.2/css/font-awesome.min.css" rel="stylesheet" type="text/css"><link href="/css/main.css?v=6.4.1" rel="stylesheet" type="text/css"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=6.4.1"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=6.4.1"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=6.4.1"><link rel="mask-icon" href="/images/logo.svg?v=6.4.1" color="#222"><script type="text/javascript" id="hexo.configurations">var NexT=window.NexT||{},CONFIG={root:"/",scheme:"Muse",version:"6.4.1",sidebar:{position:"left",display:"post",offset:12,b2t:!1,scrollpercent:!1,onmobile:!1},fancybox:!0,fastclick:!1,lazyload:!0,tabs:!0,motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},algolia:{applicationID:"",apiKey:"",indexName:"",hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}}}</script><meta name="description" content="非常热门的GAN的论文，能用来做很多有趣的事情。数学知识有点多，看得不是特别明白。不再全篇翻译后，阅读论文速度提高了不少，一个工作日摸摸鱼，晚上加个班就能完成。Generative Adversarial NetworksIan J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Ward-Farley, Sherjil O"><meta name="keywords" content="Deep Learning,Convolutional Network,Paper,Adversarial Networks,GAN"><meta property="og:type" content="article"><meta property="og:title" content="GAN 生成式对抗网络"><meta property="og:url" content="http://muyaan.com/2018/09/05/GAN-生成式对抗网络/index.html"><meta property="og:site_name" content="慕湮"><meta property="og:description" content="非常热门的GAN的论文，能用来做很多有趣的事情。数学知识有点多，看得不是特别明白。不再全篇翻译后，阅读论文速度提高了不少，一个工作日摸摸鱼，晚上加个班就能完成。Generative Adversarial NetworksIan J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Ward-Farley, Sherjil O"><meta property="og:locale" content="zh-CN"><meta property="og:image" content="http://muyaan.com/2018/09/05/GAN-生成式对抗网络/1536025785107.png"><meta property="og:image" content="http://muyaan.com/2018/09/05/GAN-生成式对抗网络/1536029071634.png"><meta property="og:image" content="http://muyaan.com/2018/09/05/GAN-生成式对抗网络/1536046014360.png"><meta property="og:image" content="http://muyaan.com/2018/09/05/GAN-生成式对抗网络/1536046219638.png"><meta property="og:image" content="http://muyaan.com/2018/09/05/GAN-生成式对抗网络/1536046533228.png"><meta property="og:image" content="http://muyaan.com/2018/09/05/GAN-生成式对抗网络/1536046560483.png"><meta property="og:updated_time" content="2018-09-12T03:22:25.012Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="GAN 生成式对抗网络"><meta name="twitter:description" content="非常热门的GAN的论文，能用来做很多有趣的事情。数学知识有点多，看得不是特别明白。不再全篇翻译后，阅读论文速度提高了不少，一个工作日摸摸鱼，晚上加个班就能完成。Generative Adversarial NetworksIan J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Ward-Farley, Sherjil O"><meta name="twitter:image" content="http://muyaan.com/2018/09/05/GAN-生成式对抗网络/1536025785107.png"><link rel="canonical" href="http://muyaan.com/2018/09/05/GAN-生成式对抗网络/"><script type="text/javascript" id="page.configurations">CONFIG.page={sidebar:""}</script><title>GAN 生成式对抗网络 | 慕湮</title><script type="text/javascript">var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?ca5844321cfb80fdf6f12b4dcc326991";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><noscript><style type="text/css">.sidebar-inner,.use-motion .brand,.use-motion .collection-title,.use-motion .comments,.use-motion .menu-item,.use-motion .motion-element,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .logo,.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.logo-line-after i{right:initial}</style></noscript></head><body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-CN"><div class="container sidebar-position-left page-post-detail"><div class="headband"></div><header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-wrapper"><div class="site-meta"><div class="custom-logo-site-title"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span> <span class="site-title">慕湮</span> <span class="logo-line-after"><i></i></span></a></div><h1 class="site-subtitle" itemprop="description">白日放歌须纵酒</h1></div><div class="site-nav-toggle"><button aria-label="切换导航栏"><span class="btn-bar"></span> <span class="btn-bar"></span> <span class="btn-bar"></span></button></div></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i><br>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i><br>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i><br>标签</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i><br>归档</a></li></ul></nav></div></header><main id="main" class="main"><div class="main-inner"><div class="content-wrap"><div id="content" class="content"><div id="posts" class="posts-expand"><article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article"><div class="post-block"><link itemprop="mainEntityOfPage" href="http://muyaan.com/2018/09/05/GAN-生成式对抗网络/"><span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person"><meta itemprop="name" content="慕湮"><meta itemprop="description" content=""><meta itemprop="image" content="https://avatars0.githubusercontent.com/u/3022000?s=460&v=4"></span><span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization"><meta itemprop="name" content="慕湮"></span><header class="post-header"><h2 class="post-title" itemprop="name headline">GAN 生成式对抗网络</h2><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2018-09-05 09:43:54" itemprop="dateCreated datePublished" datetime="2018-09-05T09:43:54+08:00">2018-09-05</time> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-calendar-check-o"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2018-09-12 11:22:25" itemprop="dateModified" datetime="2018-09-12T11:22:25+08:00">2018-09-12</time> </span><span id="/2018/09/05/GAN-生成式对抗网络/" class="leancloud_visitors" data-flag-title="GAN 生成式对抗网络"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="post-meta-item-text">阅读次数：</span> <span class="leancloud-visitors-count"></span></span><div class="post-symbolscount"><span class="post-meta-item-icon"><i class="fa fa-file-word-o"></i> </span><span class="post-meta-item-text">本文字数：</span> <span title="本文字数">10k</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-clock-o"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span title="阅读时长">19 分钟</span></div></div></header><div class="post-body" itemprop="articleBody"><p>非常热门的GAN的论文，能用来做很多有趣的事情。数学知识有点多，看得不是特别明白。不再全篇翻译后，阅读论文速度提高了不少，一个工作日摸摸鱼，晚上加个班就能完成。</p><blockquote><h1 id="Generative-Adversarial-Networks"><a href="#Generative-Adversarial-Networks" class="headerlink" title="Generative Adversarial Networks"></a><a href="https://arxiv.org/abs/1406.2661" rel="external nofollow noopener noreferrer" target="_blank">Generative Adversarial Networks</a></h1><p>Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Ward-Farley, Sherjil Ozair, Aaron Courville, Yoshua Bengio,<br>Universite de Montreal, 2014</p></blockquote><h2><a href="#" class="headerlink"></a><a id="more"></a></h2><h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h2><p>深度学习的期望是发现富有、层级化的模型，表达AI应用遇到的数据类的概率分布。深度学习的长足进步来自于模型，通常将高维感知映射到类标签。其成功主要基于反向传播和dropout。深度生成模型影响较小，因极大似然估计的许多棘手概率计算，以及在生成上下文利用分段线性单元好处的困难。我们提出了新的生成模型估计流程，规避了这些困难。</p><p>在提出的对抗网络框架，生成模型为一个对抗挖坑：它训练来判断一个样本是来自模型分布还是数据分布。生成模型可以想成一队伪造者，试图生成伪币，而对抗模型可想做警察，试图检测伪币。竞争驱动两队提升它们的方法，直到伪币无法被区分。</p><h2 id="3-Adversarial-nets"><a href="#3-Adversarial-nets" class="headerlink" title="3. Adversarial nets"></a>3. Adversarial nets</h2><p>当模型都是多层感知机时，对抗模型最容易直接应用。要训练生成器在数据x上的分布$p_g$，我们定义一个噪音输入变量prior $p_z(z)$，接着表达一个到数据空间的映射$G(z; \theta_g)$，其中G是一个参数为$\theta_g$的多层感知机表达的可微函数。我们定义另一个多层感知机$D(x;\theta_d)$，输出一个标量。$D(x)$表达了x来自数据而不是$p_g$的概率。我们训练D，使它为来自数据和来自G的样本赋予正确标签的概率最高。我们同时训练G来最小化$\log (1 - (D(G(z)))$。</p><p>换句话说，D和G玩双人minimax游戏，得分函数V(G, D)：</p><script type="math/tex;mode=display">\min _G \max _D V(D,G) = \mathbb E _{x \sim p_{data}} [\log D(x)] + \mathbb E _{z \sim p_z(z)} [\log (1 - D(G(z)))] \ \  \tag 1</script><blockquote><p>译者注：$\mathbb E$指期望值，见<a href="https://en.wiktionary.org/wiki/%F0%9D%94%BC" rel="external nofollow noopener noreferrer" target="_blank">wiki</a></p></blockquote><p>我们进行k步优化D，一步优化G。使D保持在接近最优解，G变化得足够慢。这一策略类似SML/PCD。</p><p><img src="/2018/09/05/GAN-生成式对抗网络/./1536025785107.png" alt="图1"></p><p>实际应用中，等式1也许不能为G训练提供有效的梯度。训练早期，G还不充分时，D很容易拒绝来自它的样本，因为与训练集差得比较远。这一情况下$\log (1 - D(G(z)))$就饱和了。与其训练G，让它最小化$\log (1 - D(G(z)))$，不如让它最大化$\log D(G(z))$。这一目标函数在训练早期能提供强得多的梯度。</p><h2 id="4-Theoretical-Results"><a href="#4-Theoretical-Results" class="headerlink" title="4. Theoretical Results"></a>4. Theoretical Results</h2><p>生成器G隐式地定义了当$z \sim p_z$时获得的样本G(z)的概率分布$p_g$。因此我们希望当容量和时间足够时，算法1能收敛到$p_data$的好估计。</p><p><img src="/2018/09/05/GAN-生成式对抗网络/./1536029071634.png" alt="算法1"></p><h3 id="4-1-Global-Optimality-of-p-g-p-data"><a href="#4-1-Global-Optimality-of-p-g-p-data" class="headerlink" title="4.1 Global Optimality of $p_g = p_{data}$"></a>4.1 Global Optimality of $p_g = p_{data}$</h3><p>先考虑一个不管给什么生成器G，最优的discriminator D。</p><p><strong>Proposition 1.</strong> 当G固定时，最优D是：</p><script type="math/tex;mode=display">D^{\star}_G(x) =  \frac {p_{data} (x)} {p_{data} (x) +p_g (x)} \tag 2</script><p><em>Proof</em> 对于D的训练标准是，给予任何G，最大化数量V(G, D)</p><script type="math/tex;mode=display">\begin{split}
V(G,D) &  = \int _x p_{data} (x) \log (D(x)) dx + \int _z p_z(z) \log (1-D(g(z))) d_z \\
 & = \int _x p_{data} (x) \log (D(x)) + p_g (x) \log (1 - D(x)) d(x) \\
\end{split} \ \    \tag {3}</script><p>对于任意$(a,b) \in \mathbb R ^2 $\ $\{0,0 \}$，函数 $y \to a \log (y) + b \log (1-y) $在[0, 1]间极值点在$\frac a {a+b}$</p><p>D的训练目标可解读为最大化估计条件概率$P(Y = y | x)$的log-likelihood，其中Y指示了x来自$p_{data}$（y = 1）还是$p_g$（y=0）。等式1中的minimax游戏可以变换为：</p><script type="math/tex;mode=display">\begin{split}
C(G)&  = \max _D V(G, D) \\
 & = \mathbb E _{x \sim p_{data}} [\log D^{\star} _G (x)] + \mathbb E _{z \sim p_z} [\log (1-D^{\star}_G (G(z)))] \\
  & = \mathbb E _{x \sim p_{data}} [\log D^{\star} _G (x)] + \mathbb E _{z \sim p_g} [\log (1-D^{\star}_G (x)] \\
   & = \mathbb E _{x \sim p_{data}}  \left[   \log \frac {p_{data} (x)} {p_{data}(x)+p_g(x)} \right]  + \mathbb E _{x \sim p_{g}}  \left[  \log \frac {p_{g} (x)} {p_{data}(x)+p_g(x)} \right] \\
\end{split} \ \    \tag {4}</script><p><strong>定理Theorem 1</strong> Virtual training criterion C(G)的全局最小值当且仅当$p_g = p_{data}$时取得，该点C(G)的值为 log4</p><p><em>Proof.</em> 当$p_g = p_{data}$时，$D^{\star}_G(x) = \frac 1 2$（等式2），因此通过查看等式4$D^{\star}_G(x) = \frac 1 2$时，我们发现$C(G) = \log \frac 1 2 + \log \frac 1 2 = - \log 4$。要确定这是C(G)的最优值，且仅在$p_g = p_{data}$时达到，观察：</p><script type="math/tex;mode=display">\mathbb E _{x \sim p_{data}} [ - \log 2] + \mathbb E _{x \sim p_g} [- \log 2] = - \log 4</script><p>通过从$C(G) = V(D^{\star}_G, G)$中减去这一表达式，我们得到：</p><script type="math/tex;mode=display">C(G) = - \log(4) + KL\left( p_{data} \|  \frac { p_{data} +p_g} 2\right) + KL \left( p_g \|  \frac {p_{data}+p_g} 2 \right) \tag 5</script><p>其中KL是Kullback-Leibler divergence。我们认出了这个表达式中模型分布和数据生成过程中的Jensen-Shannon divergence:</p><blockquote><p>译者注：<a href="https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence" rel="external nofollow noopener noreferrer" target="_blank">Kullback-Leibler divergence</a>，又称相对熵，是两个概率分布差异的度量。应用包括信息系统中的相对（香农）熵 <a href="https://en.wikipedia.org/wiki/Entropy_%28information_theory%29" rel="external nofollow noopener noreferrer" target="_blank">relative (Shanno) entropy</a>，连续时间序列中的随机性 randomness in continuous <a href="https://en.wikipedia.org/wiki/Time_series" rel="external nofollow noopener noreferrer" target="_blank">time-series</a>，还有与统计模型相比时的信息增益information gain。</p></blockquote><script type="math/tex;mode=display">C(G) = - \log(4) + 2 \cdot JSD (p_{data} \| p_g) \tag 6</script><p>因为两个分布的JSD总是非负的，且在它们相等时为0，我们已证明$C^{\star} = - \log (4)$是C(G)的全局最小，当且仅当$p_g = p_{data}$时取得，也就是生成模型完美复制了数据生成过程。</p><h3 id="4-2-Convergence-of-Algorithm-1"><a href="#4-2-Convergence-of-Algorithm-1" class="headerlink" title="4.2 Convergence of Algorithm 1"></a>4.2 Convergence of Algorithm 1</h3><p><strong>Proposition 2.</strong> 如果G和D容量足够，而且在算法1中的每一步，discriminator都能达到给定G下其最优，且$p_g$被更新以提升标准：</p><script type="math/tex;mode=display">\mathbb E _{x \sim p_{data}} [\log D^{\star}_G (x)] + \mathbb E _{x \sim p_g} [\log (1 - D^{\star}_G (x))]</script><p>那么$p_g$能收敛为$p_{data}$</p><p><em>Proof</em>. 假设$V(G, D) = U(p_g, D)$是之前标准下完成的$p_g$的一个函数。注意$U(p_g, D)$是$p_g$的一个凸面contex。凸函数的上确界supremum的次导数subderivative包含了函数达到极大值时的偏导数。换句话说，如果$f(x) = \sup _{\alpha \in A} f_{\alpha} (x)$对任何$\alpha$都是x中的凸，那么$ \partial f _{\beta} (x) \in \partial f \ ,if \beta = \arg \sup _{\alpha \in A} f_{\alpha} (x) $。这等价于在给定G时，计算$p_g$在最优D的一个梯度下降。如定理1中证明过，$\sup _D U(p_g,D)$是$p_g$中的一个凸，且有全局最优值，因此$p_g$有充分小的更新时，它能收敛为$p_x$，得证。</p><p>实际中，对抗网络通过函数$G(z;\theta_g)$表达一个$p_g$分布的limited family，所以我们优化$\theta_g$而不是$p_g$本身。使用一个多层感知机来定义G会为参数空间引入多个关键点。但实际应用中多层感知机的优秀性能说明它们是一个合理的模型，尽管缺乏理论支持。</p><h2 id="5-Experiments"><a href="#5-Experiments" class="headerlink" title="5. Experiments"></a>5. Experiments</h2><p>我们在多个数据集上训练对抗网络，生成网络混合使用ReLU和sigmoid激活，辨识网络使用maxout$^{[10]}$激活。训练辨识网络时使用了Dropout。尽管理论上生成网络可以使用Dropout，中间层也能使用noise，我们仅在生成器最底层使用了noise作为输入。</p><p><img src="/2018/09/05/GAN-生成式对抗网络/./1536046014360.png" alt="表1"></p><p>我们通过将G生成的样本拟合到一个Gaussian Parzen window并报告在这个分布下的log似然率，估计测试集数据在$p_g$下的概率。高斯的参数$\sigma$通过在验证集上的交叉验证获得。结果见表1。这个估计似然率的方法有很高的差异，在高维空间表现不好，但已是已知最好方法。</p><p>图2图3中是训练后的生成器的样本。</p><p><img src="/2018/09/05/GAN-生成式对抗网络/./1536046219638.png" alt="图2"><br><img src="/2018/09/05/GAN-生成式对抗网络/./1536046533228.png" alt="图3"></p><h2 id="6-Advantages-and-disadvantages"><a href="#6-Advantages-and-disadvantages" class="headerlink" title="6. Advantages and disadvantages"></a>6. Advantages and disadvantages</h2><p>与之前的模型框架相比，这一新框架有着优缺点。缺点主要在于没有$p_g(x)$的显示表达，而且在训练中D和G必须同步得很好（特别是在不更新D时，G不能训练太多，来避免“the Helvetica scenario”模式坍塌），如同波兹曼机的Negative chain必须在训练步骤中保持最新。优点是不需要马尔科夫链，仅需反向传播以获得梯度，训练中无需inference，许多函数都能包含进这一模型。表2是总结。</p><p><img src="/2018/09/05/GAN-生成式对抗网络/./1536046560483.png" alt="表2"></p><h2 id="7-Conclusions-and-future-work"><a href="#7-Conclusions-and-future-work" class="headerlink" title="7. Conclusions and future work"></a>7. Conclusions and future work</h2><p>本框架可以有许多直接扩展：</p><ol><li>为G和D增加c作为输入，就能得到条件生成模型$p(x|c)$</li><li>通过训练一个额外的给定x预测z的网络，能得到learned approximate inference。这类似于wake-sleep算法训练得到的inference，但优点在于它是被训练完成的固定生成器训练的。</li><li>可以通过训练共享参数的family of conditional模型近似所有条件$p(x_S | x_{\sout S})$，其中S是x的指数的子集。本质上，可以使用对抗网络来实现MP-DBM的随机扩展。</li><li>半监督学习：当标注数据受限时，来自discriminator或推理网的特征能有助于分类器的性能。</li><li>效率提升：training could be accelerated greatly by divising better methods for coordinating G and D or determining better distributions to sample z from during training.</li></ol><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><p>[1] Bastien, F., Lamblin, P., Pascanu, R., Bergstra, J., Goodfellow, I. J., Bergeron, A., Bouchard, N., and Bengio, Y. (2012). Theano: new features and speed improvements. Deep Learning and Unsupervised Feature Learning NIPS 2012 Workshop.<br>[2] Bengio, Y. (2009). Learning deep architectures for AI. Now Publishers.<br>[3] Bengio, Y., Mesnil, G., Dauphin, Y., and Rifai, S. (2013a). Better mixing via deep representations. In ICML’13.<br>[4] Bengio, Y., Yao, L., Alain, G., and Vincent, P. (2013b). Generalized denoising auto-encoders as generative models. In NIPS26. Nips Foundation.<br>[5] Bengio, Y., Thibodeau-Laufer, E., and Yosinski, J. (2014a). Deep generative stochastic networks trainable by backprop. In ICML’14.<br>[6] Bengio, Y., Thibodeau-Laufer, E., Alain, G., and Yosinski, J. (2014b). Deep generative stochastic networks trainable by backprop. In Proceedings of the 30th International Conference on Machine Learning (ICML’14).<br>[7] Bergstra, J., Breuleux, O., Bastien, F., Lamblin, P., Pascanu, R., Desjardins, G., Turian, J., Warde-Farley, D., and Bengio, Y. (2010). Theano: a CPU and GPU math expression compiler. In Proceedings of the Python for Scientific Computing Conference (SciPy). Oral Presentation.<br>[8] Breuleux, O., Bengio, Y., and Vincent, P. (2011). Quickly generating representative samples from an RBM-derived process. Neural Computation, 23(8), 2053–2073.<br>[9] Glorot, X., Bordes, A., and Bengio, Y. (2011). Deep sparse rectifier neural networks. In AISTATS’2011.<br>[10] Goodfellow, I. J., Warde-Farley, D., Mirza, M., Courville, A., and Bengio, Y. (2013a). Maxout networks. In ICML’2013.<br>[11] Goodfellow, I. J., Mirza, M., Courville, A., and Bengio, Y. (2013b). Multi-prediction deep Boltzmann machines. In NIPS’2013.<br>[12] Goodfellow, I. J., Warde-Farley, D., Lamblin, P., Dumoulin, V., Mirza, M., Pascanu, R., Bergstra, J., Bastien, F., and Bengio, Y. (2013c). Pylearn2: a machine learning research library. arXiv preprint arXiv:1308.4214.<br>[13] Gutmann, M. and Hyvarinen, A. (2010). Noise-contrastive estimation: A new estimation principle for unnormalized statistical models. In AISTATS’2010.<br>[14] Hinton, G., Deng, L., Dahl, G. E., Mohamed, A., Jaitly, N., Senior, A., Vanhoucke, V., Nguyen, P., Sainath, T., and Kingsbury, B. (2012a). Deep neural networks for acoustic modeling in speech recognition. IEEE Signal Processing Magazine, 29(6), 82–97.<br>[15] Hinton, G. E., Dayan, P., Frey, B. J., and Neal, R. M. (1995). The wake-sleep algorithm for unsupervised neural networks. Science, 268, 1558–1161.<br>[16] Hinton, G. E., Osindero, S., and Teh, Y. (2006). A fast learning algorithm for deep belief nets. Neural Computation, 18, 1527–1554.<br>[17] Hinton, G. E., Srivastava, N., Krizhevsky, A., Sutskever, I., and Salakhutdinov, R. (2012b). Improving neural networks by preventing co adaptation of feature detectors. Technical report, arXiv:1207.0580.<br>[18] Hyvarinen, A. (2005). Estimation of non-normalized statistical models using score matching. ¨ J. Machine Learning Res., 6.<br>[19] Jarrett, K., Kavukcuoglu, K., Ranzato, M., and LeCun, Y. (2009). What is the best multi-stage architecture for object recognition? In Proc. International Conference on Computer Vision (ICCV’09), pages 2146–2153. IEEE.<br>[20] Kingma, D. P. and Welling, M. (2014). Auto-encoding variational bayes. In Proceedings of the International Conference on Learning Representations (ICLR).<br>[21] Krizhevsky, A. and Hinton, G. (2009). Learning multiple layers of features from tiny images. Technical report, University of Toronto.<br>[22] Krizhevsky, A., Sutskever, I., and Hinton, G. (2012). ImageNet classification with deep convolutional neural networks. In NIPS’2012.<br>[23] LeCun, Y., Bottou, L., Bengio, Y., and Haffner, P. (1998). Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11), 2278–2324.<br>[24] Rezende, D. J., Mohamed, S., and Wierstra, D. (2014). Stochastic backpropagation and approximate inference in deep generative models. Technical report, arXiv:1401.4082.<br>[25] Rifai, S., Bengio, Y., Dauphin, Y., and Vincent, P. (2012). A generative process for sampling contractive auto-encoders. In ICML’12.<br>[26] Salakhutdinov, R. and Hinton, G. E. (2009). Deep Boltzmann machines. In AISTATS’2009, pages 448– 455.<br>[27] Smolensky, P. (1986). Information processing in dynamical systems: Foundations of harmony theory. In D. E. Rumelhart and J. L. McClelland, editors, Parallel Distributed Processing, volume 1, chapter 6, pages 194–281. MIT Press, Cambridge.<br>[28] Susskind, J., Anderson, A., and Hinton, G. E. (2010). The Toronto face dataset. Technical Report UTML TR 2010-001, U. Toronto.<br>[29] Tieleman, T. (2008). Training restricted Boltzmann machines using approximations to the likelihood gradient. In W. W. Cohen, A. McCallum, and S. T. Roweis, editors, ICML 2008, pages 1064–1071. ACM.<br>[30] Vincent, P., Larochelle, H., Bengio, Y., and Manzagol, P.-A. (2008). Extracting and composing robust features with denoising autoencoders. In ICML 2008.<br>[31] Younes, L. (1999). On the convergence of Markovian stochastic algorithms with rapidly decreasing ergodicity rates. Stochastics and Stochastic Reports, 65(3), 177–228.</p></div><div class="popular-posts-header">相关文章</div><ul class="popular-posts"><li class="popular-posts-item"><div class="popular-posts-title"><a href="/2018/09/06/Aligned-ReID/" rel="bookmark">Aligned ReID</a></div></li><li class="popular-posts-item"><div class="popular-posts-title"><a href="/2018/07/22/ResNet/" rel="bookmark">ResNet</a></div></li><li class="popular-posts-item"><div class="popular-posts-title"><a href="/2018/07/21/LeNet/" rel="bookmark">LeNet</a></div></li><li class="popular-posts-item"><div class="popular-posts-title"><a href="/2018/08/21/Batch-Normalization/" rel="bookmark">Batch Normalization</a></div></li><li class="popular-posts-item"><div class="popular-posts-title"><a href="/2018/09/14/SIMPLE-ONLINE-AND-REALTIME-TRACKING-WITH-A-DEEP-ASSOCIATION-METRIC/" rel="bookmark">SIMPLE ONLINE AND REALTIME TRACKING WITH A DEEP ASSOCIATION METRIC</a></div></li></ul><div><ul class="post-copyright"><li class="post-copyright-author"><strong>本文作者： </strong>慕湮</li><li class="post-copyright-link"><strong>本文链接：</strong> <a href="http://muyaan.com/2018/09/05/GAN-生成式对抗网络/" title="GAN 生成式对抗网络">http://muyaan.com/2018/09/05/GAN-生成式对抗网络/</a></li><li class="post-copyright-license"><strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="external nofollow noopener noreferrer" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明出处！</li></ul></div><footer class="post-footer"><div class="post-tags"><a href="/tags/Deep-Learning/" rel="tag"># Deep Learning</a> <a href="/tags/Convolutional-Network/" rel="tag"># Convolutional Network</a> <a href="/tags/Paper/" rel="tag"># Paper</a> <a href="/tags/Adversarial-Networks/" rel="tag"># Adversarial Networks</a> <a href="/tags/GAN/" rel="tag"># GAN</a></div><div class="post-nav"><div class="post-nav-next post-nav-item"><a href="/2018/09/03/MTCNN/" rel="next" title="MTCNN"><i class="fa fa-chevron-left"></i> MTCNN</a></div><span class="post-nav-divider"></span><div class="post-nav-prev post-nav-item"><a href="/2018/09/06/Aligned-ReID/" rel="prev" title="Aligned ReID">Aligned ReID <i class="fa fa-chevron-right"></i></a></div></div></footer></div></article></div></div></div><div class="sidebar-toggle"><div class="sidebar-toggle-line-wrap"><span class="sidebar-toggle-line sidebar-toggle-line-first"></span> <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span> <span class="sidebar-toggle-line sidebar-toggle-line-last"></span></div></div><aside id="sidebar" class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">文章目录</li><li class="sidebar-nav-overview" data-target="site-overview-wrap">站点概览</li></ul><section class="site-overview-wrap sidebar-panel"><div class="site-overview"><div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" src="https://avatars0.githubusercontent.com/u/3022000?s=460&v=4" alt="慕湮"><p class="site-author-name" itemprop="name">慕湮</p><p class="site-description motion-element" itemprop="description"></p></div><nav class="site-state motion-element"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">23</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/index.html"><span class="site-state-item-count">31</span> <span class="site-state-item-name">标签</span></a></div></nav><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/tycallen" target="_blank" title="GitHub" rel="external nofollow noopener noreferrer"><i class="fa fa-fw fa-github"></i>GitHub</a> </span><span class="links-of-author-item"><a href="mailto:tyc.allen@gmail.com" target="_blank" title="E-Mail" rel="external nofollow noopener noreferrer"><i class="fa fa-fw fa-envelope"></i>E-Mail</a> </span><span class="links-of-author-item"><a href="http://weibo.com/pojunallen" target="_blank" title="微博" rel="external nofollow noopener noreferrer"><i class="fa fa-fw fa-weibo"></i>微博</a> </span><span class="links-of-author-item"><a href="https://tuchong.com/1070837" target="_blank" title="图虫" rel="external nofollow noopener noreferrer"><i class="fa fa-fw fa-globe"></i>图虫</a></span></div><div class="links-of-blogroll motion-element links-of-blogroll-block"><div class="links-of-blogroll-title"><i class="fa fa-fw fa-link"></i> 友情链接</div><ul class="links-of-blogroll-list"><li class="links-of-blogroll-item"><a href="http://dotrabbit.tk" title="dotrabbit" target="_blank" rel="external nofollow noopener noreferrer">dotrabbit</a></li></ul></div></div></section><section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active"><div class="post-toc"><div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Generative-Adversarial-Networks"><span class="nav-text">Generative Adversarial Networks</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#undefined"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-Introduction"><span class="nav-text">1. Introduction</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-Adversarial-nets"><span class="nav-text">3. Adversarial nets</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-Theoretical-Results"><span class="nav-text">4. Theoretical Results</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#4-1-Global-Optimality-of-p-g-p-data"><span class="nav-text">4.1 Global Optimality of $p_g = p_{data}$</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-2-Convergence-of-Algorithm-1"><span class="nav-text">4.2 Convergence of Algorithm 1</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-Experiments"><span class="nav-text">5. Experiments</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-Advantages-and-disadvantages"><span class="nav-text">6. Advantages and disadvantages</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#7-Conclusions-and-future-work"><span class="nav-text">7. Conclusions and future work</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#References"><span class="nav-text">References</span></a></li></ol></li></ol></div></div></section></div></aside></div></main><footer id="footer" class="footer"><div class="footer-inner"><div class="copyright">&copy; 2015 – <span itemprop="copyrightYear">2018</span> <span class="with-love" id="animate"><i class="fa fa-user"></i> </span><span class="author" itemprop="copyrightHolder">慕湮</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-area-chart"></i> </span><span title="站点总字数">320k</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-coffee"></i> </span><span title="站点阅读时长">9:42</span></div><div class="powered-by">由 <a class="theme-link" target="_blank" rel="external nofollow noopener noreferrer" href="https://hexo.io">Hexo</a> 强力驱动</div><span class="post-meta-divider">|</span><div class="theme-info">主题 – <a class="theme-link" target="_blank" rel="external nofollow noopener noreferrer" href="https://theme-next.org">NexT.Muse</a></div></div></footer><div class="back-to-top"><i class="fa fa-arrow-up"></i></div></div><script type="text/javascript">"[object Function]"!==Object.prototype.toString.call(window.Promise)&&(window.Promise=null)</script><script type="text/javascript" src="//cdn.staticfile.org/jquery/2.1.3/jquery.min.js"></script><script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script><script type="text/javascript" src="//cdn.staticfile.org/velocity/1.2.1/velocity.min.js"></script><script type="text/javascript" src="//cdn.staticfile.org/velocity/1.2.1/velocity.ui.min.js"></script><script type="text/javascript" src="//cdn.staticfile.org/fancybox/2.1.5/jquery.fancybox.min.js"></script><script type="text/javascript" src="/js/src/utils.js?v=6.4.1"></script><script type="text/javascript" src="/js/src/motion.js?v=6.4.1"></script><script type="text/javascript" src="/js/src/scrollspy.js?v=6.4.1"></script><script type="text/javascript" src="/js/src/post-details.js?v=6.4.1"></script><script type="text/javascript" src="/js/src/bootstrap.js?v=6.4.1"></script><script>function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();

      Counter('get', '/classes/Counter', { where: JSON.stringify({ url }) })
        .done(function ({ results }) {
          if (results.length > 0) {
            var counter = results[0];
            
              var $element = $(document.getElementById(url));
              $element.find('.leancloud-visitors-count').text(counter.time + 1);
            
            Counter('put', `/classes/Counter/${counter.objectId}`, JSON.stringify({ time: { "__op":"Increment", "amount":1 } }))
            
            .fail(function ({ responseJSON }) {
                console.log('Failed to save Visitor num, with error message: ' + responseJSON.error);
            })
          } else {
            
              Counter('post', '/classes/Counter', JSON.stringify({ title: title, url: url, time: 1}))
                .done(function () {
                  var $element = $(document.getElementById(url));
                  $element.find('.leancloud-visitors-count').text(1);
                })
                .fail(function () {
                  console.log('Failed to create');
                });
            
          }
        })
      .fail(function ({ responseJSON }) {
        console.log('LeanCloud Counter Error:' + responseJSON.code + " " + responseJSON.error);
      });
    }
    

    $(function() {
      $.get('https://app-router.leancloud.cn/2/route?appId=' + "UWGXBMGbguCDhSCbC3NrUQtL-gzGzoHsz")
        .done(function ({ api_server }) {
          var Counter = function (method, url, data) {
            return $.ajax({
              method: method,
              url: `https://${api_server}/1.1${url}`,
              headers: {
                'X-LC-Id': "UWGXBMGbguCDhSCbC3NrUQtL-gzGzoHsz",
                'X-LC-Key': "ke1jrA5b6VyR89Kqqqwf2kPP",
                'Content-Type': 'application/json',
              },
              data: data,
            });
          };
          
          addCount(Counter);
          
        })
    });</script><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}()</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      },
      TeX: {equationNumbers: { autoNumber: "AMS" }}
    });</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });</script><script type="text/javascript" src="//cdn.jsdelivr.net/npm/mathjax@2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script async src="http://muyaan.com/js/src/async.js"></script></body></html>