<!DOCTYPE html><html class="theme-next muse use-motion" lang="zh-CN"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><script src="https://cdn.staticfile.org/pace/1.0.2/pace.min.js"></script><link href="https://cdn.staticfile.org/pace/1.0.2/themes/blue/pace-theme-big-counter.min.css" rel="stylesheet"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link href="//cdn.staticfile.org/fancybox/2.1.5/jquery.fancybox.min.js" rel="stylesheet" type="text/css"><link href="//cdn.staticfile.org/font-awesome/4.6.2/css/font-awesome.min.css" rel="stylesheet" type="text/css"><link href="/css/main.css?v=6.4.1" rel="stylesheet" type="text/css"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=6.4.1"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=6.4.1"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=6.4.1"><link rel="mask-icon" href="/images/logo.svg?v=6.4.1" color="#222"><script type="text/javascript" id="hexo.configurations">var NexT=window.NexT||{},CONFIG={root:"/",scheme:"Muse",version:"6.4.1",sidebar:{position:"left",display:"post",offset:12,b2t:!1,scrollpercent:!1,onmobile:!1},fancybox:!0,fastclick:!1,lazyload:!0,tabs:!0,motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},algolia:{applicationID:"",apiKey:"",indexName:"",hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}}}</script><meta name="description" content="一篇将行人属性识别结合进Re-ID的论文。未来有一个项目需要识别属性，所以来学习了一下。4个小时完成，对速度感到满意。Improving Person Re-identification by Attribute and Identity LearningYutian Lin, Liang Zheng, Zhedong Zheng, Yu Wu, Yi YangUniversity of Tech"><meta name="keywords" content="Deep Learning,Paper,Pedestrian attribute,CV,re-ID"><meta property="og:type" content="article"><meta property="og:title" content="Improving Person Re-identification by Attribute and Identity Learning"><meta property="og:url" content="http://muyaan.com/2018/09/07/Improving-Person-Re-identification-by-Attribute-and-Identity-Learning/index.html"><meta property="og:site_name" content="慕湮"><meta property="og:description" content="一篇将行人属性识别结合进Re-ID的论文。未来有一个项目需要识别属性，所以来学习了一下。4个小时完成，对速度感到满意。Improving Person Re-identification by Attribute and Identity LearningYutian Lin, Liang Zheng, Zhedong Zheng, Yu Wu, Yi YangUniversity of Tech"><meta property="og:locale" content="zh-CN"><meta property="og:image" content="http://muyaan.com/2018/09/07/Improving-Person-Re-identification-by-Attribute-and-Identity-Learning/1536290910505.png"><meta property="og:image" content="http://muyaan.com/2018/09/07/Improving-Person-Re-identification-by-Attribute-and-Identity-Learning/1536291437741.png"><meta property="og:image" content="http://muyaan.com/2018/09/07/Improving-Person-Re-identification-by-Attribute-and-Identity-Learning/1536300576019.png"><meta property="og:image" content="http://muyaan.com/2018/09/07/Improving-Person-Re-identification-by-Attribute-and-Identity-Learning/1536301133849.png"><meta property="og:image" content="http://muyaan.com/2018/09/07/Improving-Person-Re-identification-by-Attribute-and-Identity-Learning/1536301260600.png"><meta property="og:image" content="http://muyaan.com/2018/09/07/Improving-Person-Re-identification-by-Attribute-and-Identity-Learning/1536301803827.png"><meta property="og:image" content="http://muyaan.com/2018/09/07/Improving-Person-Re-identification-by-Attribute-and-Identity-Learning/1536302047982.png"><meta property="og:image" content="http://muyaan.com/2018/09/07/Improving-Person-Re-identification-by-Attribute-and-Identity-Learning/1536304016997.png"><meta property="og:image" content="http://muyaan.com/2018/09/07/Improving-Person-Re-identification-by-Attribute-and-Identity-Learning/1536305174557.png"><meta property="og:image" content="http://muyaan.com/2018/09/07/Improving-Person-Re-identification-by-Attribute-and-Identity-Learning/1536306009035.png"><meta property="og:image" content="http://muyaan.com/2018/09/07/Improving-Person-Re-identification-by-Attribute-and-Identity-Learning/1536306376071.png"><meta property="og:image" content="http://muyaan.com/2018/09/07/Improving-Person-Re-identification-by-Attribute-and-Identity-Learning/1536307013494.png"><meta property="og:image" content="http://muyaan.com/2018/09/07/Improving-Person-Re-identification-by-Attribute-and-Identity-Learning/1536307396398.png"><meta property="og:image" content="http://muyaan.com/2018/09/07/Improving-Person-Re-identification-by-Attribute-and-Identity-Learning/1536307608289.png"><meta property="og:image" content="http://muyaan.com/2018/09/07/Improving-Person-Re-identification-by-Attribute-and-Identity-Learning/1536307806486.png"><meta property="og:image" content="http://muyaan.com/2018/09/07/Improving-Person-Re-identification-by-Attribute-and-Identity-Learning/1536307828493.png"><meta property="og:image" content="http://muyaan.com/2018/09/07/Improving-Person-Re-identification-by-Attribute-and-Identity-Learning/1536307930978.png"><meta property="og:updated_time" content="2018-09-12T03:22:25.019Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="Improving Person Re-identification by Attribute and Identity Learning"><meta name="twitter:description" content="一篇将行人属性识别结合进Re-ID的论文。未来有一个项目需要识别属性，所以来学习了一下。4个小时完成，对速度感到满意。Improving Person Re-identification by Attribute and Identity LearningYutian Lin, Liang Zheng, Zhedong Zheng, Yu Wu, Yi YangUniversity of Tech"><meta name="twitter:image" content="http://muyaan.com/2018/09/07/Improving-Person-Re-identification-by-Attribute-and-Identity-Learning/1536290910505.png"><link rel="canonical" href="http://muyaan.com/2018/09/07/Improving-Person-Re-identification-by-Attribute-and-Identity-Learning/"><script type="text/javascript" id="page.configurations">CONFIG.page={sidebar:""}</script><title>Improving Person Re-identification by Attribute and Identity Learning | 慕湮</title><script type="text/javascript">var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?ca5844321cfb80fdf6f12b4dcc326991";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><noscript><style type="text/css">.sidebar-inner,.use-motion .brand,.use-motion .collection-title,.use-motion .comments,.use-motion .menu-item,.use-motion .motion-element,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .logo,.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.logo-line-after i{right:initial}</style></noscript></head><body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-CN"><div class="container sidebar-position-left page-post-detail"><div class="headband"></div><header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-wrapper"><div class="site-meta"><div class="custom-logo-site-title"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span> <span class="site-title">慕湮</span> <span class="logo-line-after"><i></i></span></a></div><h1 class="site-subtitle" itemprop="description">白日放歌须纵酒</h1></div><div class="site-nav-toggle"><button aria-label="切换导航栏"><span class="btn-bar"></span> <span class="btn-bar"></span> <span class="btn-bar"></span></button></div></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i><br>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i><br>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i><br>标签</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i><br>归档</a></li></ul></nav></div></header><main id="main" class="main"><div class="main-inner"><div class="content-wrap"><div id="content" class="content"><div id="posts" class="posts-expand"><article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article"><div class="post-block"><link itemprop="mainEntityOfPage" href="http://muyaan.com/2018/09/07/Improving-Person-Re-identification-by-Attribute-and-Identity-Learning/"><span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person"><meta itemprop="name" content="慕湮"><meta itemprop="description" content=""><meta itemprop="image" content="https://avatars0.githubusercontent.com/u/3022000?s=460&v=4"></span><span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization"><meta itemprop="name" content="慕湮"></span><header class="post-header"><h2 class="post-title" itemprop="name headline">Improving Person Re-identification by Attribute and Identity Learning</h2><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2018-09-07 16:20:16" itemprop="dateCreated datePublished" datetime="2018-09-07T16:20:16+08:00">2018-09-07</time> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-calendar-check-o"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2018-09-12 11:22:25" itemprop="dateModified" datetime="2018-09-12T11:22:25+08:00">2018-09-12</time> </span><span id="/2018/09/07/Improving-Person-Re-identification-by-Attribute-and-Identity-Learning/" class="leancloud_visitors" data-flag-title="Improving Person Re-identification by Attribute and Identity Learning"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="post-meta-item-text">阅读次数：</span> <span class="leancloud-visitors-count"></span></span><div class="post-symbolscount"><span class="post-meta-item-icon"><i class="fa fa-file-word-o"></i> </span><span class="post-meta-item-text">本文字数：</span> <span title="本文字数">12k</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-clock-o"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span title="阅读时长">22 分钟</span></div></div></header><div class="post-body" itemprop="articleBody"><p>一篇将行人属性识别结合进Re-ID的论文。未来有一个项目需要识别属性，所以来学习了一下。4个小时完成，对速度感到满意。</p><blockquote><p><a href="https://arxiv.org/abs/1703.07220" rel="external nofollow noopener noreferrer" target="_blank">Improving Person Re-identification by Attribute and Identity Learning</a><br>Yutian Lin, Liang Zheng, Zhedong Zheng, Yu Wu, Yi Yang<br>University of Technology Sydney, 2017</p></blockquote><h2><a href="#" class="headerlink"></a><a id="more"></a></h2><h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h2><p>本论文的目标是使用属性标签作为补充线索，提升person Re-ID的性能。</p><p>本论文的主要出发点是person Re-ID依靠全局描述符，而属性识别通常指示一个人的局部结构。猜测属性的正确预测能有助于Re-ID的辨识力。如图1第四行，Re-ID没能分辨出着装相似的人，而属性或许能通过性别、帽子和包来区别出。</p><p><img src="/2018/09/07/Improving-Person-Re-identification-by-Attribute-and-Identity-Learning/./1536290910505.png" alt="图1"></p><p>本论文与之前的Re-ID和属性论文有两个区别。大部分方法使用属性来加强图片对或triplet的关系$^{[33, 34, 16, 21]}$。本论文主要讨论ID级属性，而不是Instance级属性。ID级属性与人有关，如性别年龄。Instance属性是短期外观或与外部环境有关的，如打电话和骑自行车。</p><p>我们是首个将属性集成进CNN分类模型，用于Re-ID的。我们提出了attribute-person recognition（APR）网络，将两个任务在loss级别结合了起来。两个基线都是CNN分类架构。APR结合了person Re-ID loss 和属性预测loss（图2）。实验发现Re-ID准确率达到前沿，同时提升了属性识别性能。</p><p><img src="/2018/09/07/Improving-Person-Re-identification-by-Attribute-and-Identity-Learning/./1536291437741.png" alt="图2"></p><h2 id="2-Related-Work"><a href="#2-Related-Work" class="headerlink" title="2. Related Work"></a>2. Related Work</h2><p><strong>CNN-based person Re-ID.</strong> 基于CNN的方法统治了Re-ID社区，可分作两类：深度度量学习和深度representative学习。前一类通常将图片pair或triplet输入到网络。Representative方法包括[44, 23]。通常将空间约束集成到相似度学习过程中$^{[1, 23, 44, 5]}$。例如在[38]中每个卷积层插入门函数，以捕获两个输入图片的细微差别。[5]中提出了为一个triplet输入通过实行一个ranking loss 和一个verification loss的多任务方法。总的来讲，深度度量学习在小数据集训练有优势，但在大的图集上效率有问题。</p><p>第二类因其优秀的准确率和不错的效率而变得流行，包括[41, 49, 42, 9, 53]。[41]提出通过训练一个来自多领域的分类模型，习得泛化特征。[53, 9]中verification 和 Classification loss的结合被证明是有效的。</p><p><strong>Attributes for person Re-ID.</strong> Re-ID领域已有几篇对属性的探索。属性主要用作Re-ID的额外信息。[21, 20, 19]中使用低级描述符和SVM来训练属性检测器，属性被集成到多个度量训练方法中。[33]通过多任务学习训练了一个有辨识力的模型，开发了多摄像头共享的特征和属性。[16]提出同时优化Re-ID的triplet loss和属性分类loss，但没显示出对属性识别的提升。</p><p><strong>Attributes for face applications.</strong> 用于人脸识别的属性已研究了很久。早期，[29]提出使用Haar特征来通过SVM预测性别。[18]比较了用于年龄预测的多种分类器。近期提出了许多深度学习方法。[48]把人脸属性识别当做额外任务，提升使用CNN的人脸对齐性能。[27]层叠两个CNN并同时调优，通过属性标签预测人脸属性。</p><h2 id="3-Attribute-Annotation"><a href="#3-Attribute-Annotation" class="headerlink" title="3. Attribute Annotation"></a>3. Attribute Annotation</h2><p>出于两个原因，我们重新手动标注了Market-1501和DukeMTMC-reID。首先，当前最大的行人属性集RAP，不包含ID标注。其次，PETA是相对小的Re-ID数据集组合的，每个ID的样本很有限，不利于深度学习。</p><p>尽管Market-1501和DukeMTMC-reID都采集自大学，ID主要是学生。但它们季节不同（夏vs冬）因此衣着差别很大。例如Market-1501中主要穿裙子和短裤。因此这两个数据集我们有两个不同属性集。属性考虑到数据集特性小心选取，避免属性分布（如是否戴帽子）有严重偏差。</p><p>Market-1501我们标注了27个属性：性别，头发长短，袖子长短，下装长短，下装类型（裤子，裙子），是否戴帽子，是否有包，是否背包，是否手包，8色上装（黑白红紫黄灰蓝绿），9色下装（黑白粉紫黄灰蓝绿棕），年龄（小孩，青年，成年，老年）。颜色属性都是二分的。图3是Market-1501的一些代表性正负样本。</p><p><img src="/2018/09/07/Improving-Person-Re-identification-by-Attribute-and-Identity-Learning/./1536300576019.png" alt="图3"></p><p>DukeMTMC-reID我们标注了23个属性。上下装颜色少一点，没有年龄，多了鞋子颜色。图4中有一些有代表属性的相关性。图5是属性的分布。</p><p><img src="/2018/09/07/Improving-Person-Re-identification-by-Attribute-and-Identity-Learning/./1536301133849.png" alt="图4"></p><p><img src="/2018/09/07/Improving-Person-Re-identification-by-Attribute-and-Identity-Learning/./1536301260600.png" alt="图5"></p><p>所有属性都在身份级标注。例如图3中，第二行前两个图片是一个身份，所以虽然第二张图看不见背包，其标签仍是背包。</p><h2 id="4-Proposed-Method"><a href="#4-Proposed-Method" class="headerlink" title="4. Proposed Method"></a>4. Proposed Method</h2><h3 id="4-1-Baseline-Methods"><a href="#4-1-Baseline-Methods" class="headerlink" title="4.1 Baseline Methods"></a>4.1 Baseline Methods</h3><p>我们构建了两个用于Re-ID和行人属性识别的baseline。baseline是ImageNet上预训练的ResNet-50。我们分别使用新标注的属性和近期得到的身份标签调优。</p><p><strong>Baseline 1（person Re-ID）.</strong>我们将base模型的最后一个FC层神经元数量设为K，K是训练身份数量。为了避免过拟合，在FC前插入了一个0.9的dropout层。测试时，为每张图片从pool5层提取一个2048维特征向量，在查询和图集间计算欧氏距离，再排序。结果见表1。</p><p><img src="/2018/09/07/Improving-Person-Re-identification-by-Attribute-and-Identity-Learning/./1536301803827.png" alt="表1"></p><p><strong>Baseline 2（pedestrian attribute recognition &amp; Re-ID）.</strong> 我们使用M个后接softmax层的FC层来识别属性，M是属性的数量。在CaffeNet中，M个FC层替换了FC8；ResNet-50中替换了FC。有m类的属性，FC层就是m维。我们也像Baseline 1一样插入了dropout层。结果见表3。</p><p><img src="/2018/09/07/Improving-Person-Re-identification-by-Attribute-and-Identity-Learning/./1536302047982.png" alt="表3"></p><h3 id="4-2-Attribute-Person-Recognition-APR-Network"><a href="#4-2-Attribute-Person-Recognition-APR-Network" class="headerlink" title="4.2 Attribute-Person Recognition (APR) Network"></a>4.2 Attribute-Person Recognition (APR) Network</h3><p><strong>Architecture.</strong> APR网络包括一个base模型，loss计算前的M+1个FC层，用于属性分类的M个loss，M是属性数量。新的FC层记做$FC_0, FC_1,…,FC_M$。其中$FC_0$用于ID分类，其余用于属性识别。它们的维度与Baseline 1，2中一致。网络会为输入图片同时预测其ID和属性集。预训练模型可以是ResNet-50和CaffeNet。</p><p>ResNet-50的FC层连接到Pool5，CaffeNet中FC连接到FC7。它们分别使用224和227见方的输入。</p><p><strong>Loss computation.</strong> 假设我们有K个身份的n张图片，每个身份有M个属性。设$D_i = \{ x_i, d_i, l_i \}$为训练集，$x_i$指第i张图片，$d_i$指它的ID，$l_i =\{ l_i^1,…,l_j^M\}$指第i张图的M个属性标签。</p><p>以ResNet-50为例，给定一个训练样本x，我们模型首先计算pool5描述符f。其输出向量为$1\times1\times2048$。$FC_0$的输出为$z = [z_1,z_2,…,z_K] \in R^K$。故每个身份标签$k \in 1,…,K$的概率如此计算：$p(k|x) = \frac {\exp z_k} {\sum _{i=1} ^K \exp (z_i)}$。让我们暂时忽略k和x之间的相关性，故ID分类的CE loss计算如下：</p><script type="math/tex;mode=display">L_{ID} (f,d) = - \sum _{k=1} ^K \log (p(k)) q(k) \tag 1</script><p>设y为gt ID标签，故$q(y) = 1$且对所有$k \neq y$，$q(k) = 0$。这一情况下最小化交叉熵loss等价于最大化赋予gt类的概率。</p><p>属性预测我们也使用 M softmax loss。我们设一个属性有m类，为样本x赋予属性类$j \in 1, … , m$的概率可写作$p(j|x) = \frac {\exp z_j} {\sum _{i=1} ^K \exp (z_j)}$。类似的，分类loss可以写作：</p><script type="math/tex;mode=display">L_{att} (f,l) = - \sum _{j=1} ^m \log (p(j)) q(j) \tag 2</script><p>设$y_m$为gt标签，故$q(y_m) = 1$，而所有$j \neq y_m$的$q(j) = 0$，其它符号如等式1。</p><p>最终loss函数如下：</p><script type="math/tex;mode=display">L = \lambda L_{ID} + \frac 1 M \sum _{i=1} ^M L_{att} \tag 3</script><p><img src="/2018/09/07/Improving-Person-Re-identification-by-Attribute-and-Identity-Learning/./1536304016997.png" alt="图6"></p><p>图6是CNN中的特征图可视化，说明了属性集成后对网络的可接受性的增强。</p><h2 id="5-Experiment"><a href="#5-Experiment" class="headerlink" title="5. Experiment"></a>5. Experiment</h2><h3 id="5-1-Datasets-and-Evaluation-Protocol"><a href="#5-1-Datasets-and-Evaluation-Protocol" class="headerlink" title="5.1 Datasets and Evaluation Protocol"></a>5.1 Datasets and Evaluation Protocol</h3><p><strong>Evaluation metrics.</strong> 对Re-ID任务我们使用Cumulative Matching Characteristic（CMC）曲线和mAP。对每个查询，其average precision（AP）计算自其precision-recall曲线。mAP是所有查询的AP平均。推测是CMC反映检索准确率，mAP反映召回率。我们使用了[51, 54]的评估包。</p><h3 id="5-2-Implementation-Details"><a href="#5-2-Implementation-Details" class="headerlink" title="5.2 Implementation Details"></a>5.2 Implementation Details</h3><h3 id="5-3-Evaluation-of-Person-Re-ID"><a href="#5-3-Evaluation-of-Person-Re-ID" class="headerlink" title="5.3 Evaluation of Person Re-ID"></a>5.3 Evaluation of Person Re-ID</h3><p><strong>Parameter validation.</strong> 我们验证了参数$\lambda$的效果，见图7。mAP和rank-1都是先增后减，最终我们使用了$\lambda = 8$</p><p><img src="/2018/09/07/Improving-Person-Re-identification-by-Attribute-and-Identity-Learning/./1536305174557.png" alt="图7"></p><p><strong>Attribute recognition improves re-ID over the baselines.</strong> 我们评估了APR是否超越了两个baseline，结果见表1和表2。</p><p><img src="/2018/09/07/Improving-Person-Re-identification-by-Attribute-and-Identity-Learning/./1536306009035.png" alt="表2"></p><p>首先，如我们预期的B1获得了好性能。但B2也有不错的准确率。B2仅利用了没有ID loss 的属性标签。这说明属性有能力区分不同的人。</p><p><img src="/2018/09/07/Improving-Person-Re-identification-by-Attribute-and-Identity-Learning/./1536306376071.png" alt="图8"></p><p>图8是一些Market-1501的Re-ID结果。Baseline 1的top-8中没有任何正确匹配。其中有背包和男性的都匹配了出来。当使用APR时，所有6个真匹配都找到了。本例中<em>包</em>和<em>女性</em>是关键属性。</p><p><strong>Results between camera pairs.</strong> 为了进一步理解在Market-1501上的性能，我们提供了所有摄像头对的Re-ID结果，见图10。尽管摄像头6是一个$720\times 576$SD摄像头，且与其它HD摄像头拍摄到的背景明显不同，Cam-6与其它的cam的Re-ID准确率相对高。</p><p><img src="/2018/09/07/Improving-Person-Re-identification-by-Attribute-and-Identity-Learning/./1536307013494.png" alt="Alt text"></p><p><strong>Scalability of the learned representation.</strong> 为了测试我们方法的可扩展性，我们报告了在Market-1501+500k上的结果。500k干扰集是由大量背景和无关行人组成。我们的模型（ResNet，751训练身份）的Re-ID准确率见图11。</p><p><img src="/2018/09/07/Improving-Person-Re-identification-by-Attribute-and-Identity-Learning/./1536307396398.png" alt="图11"></p><p><strong>Ablation studies.</strong> 我们评估了独立属性对Re-ID准确率的贡献。我们在固定$\lambda = 8$时移除一个属性，结果见图9。两个数据集影响最大的属性分别是<em>包类</em>和<em>鞋子颜色</em>。这说明两数据集的行人外观不一样。</p><p><img src="/2018/09/07/Improving-Person-Re-identification-by-Attribute-and-Identity-Learning/./1536307608289.png" alt="图9"></p><h3 id="5-4-Evaluation-of-Attribute-Recognition"><a href="#5-4-Evaluation-of-Attribute-Recognition" class="headerlink" title="5.4 Evaluation of Attribute Recognition"></a>5.4 Evaluation of Attribute Recognition</h3><p>我们测试了属性识别，结果见表3、4。</p><p><img src="/2018/09/07/Improving-Person-Re-identification-by-Attribute-and-Identity-Learning/./1536307806486.png" alt="表3"></p><p><img src="/2018/09/07/Improving-Person-Re-identification-by-Attribute-and-Identity-Learning/./1536307828493.png" alt="表4"></p><p>我们在图12中展示了两个属性预测的例子。我们的系统为左边的人正确预测了所有标签。右边的人，在长发和是否戴帽子上出错。</p><p><img src="/2018/09/07/Improving-Person-Re-identification-by-Attribute-and-Identity-Learning/./1536307930978.png" alt="图12"></p><h2 id="6-Conclusions"><a href="#6-Conclusions" class="headerlink" title="6. Conclusions"></a>6. Conclusions</h2><p>[1] E. Ahmed, M. Jones, and T. K. Marks. An improved deeplearning architecture for person re-identification. In CVPR,2015. 2<br>[2] I. B. Barbosa, M. Cristani, B. Caputo, A. Rognhaugen,and T. Theoharis. Looking beyond appearances:Synthetic training data for deep cnns in re-identification.arXiv:1701.03153, 2017. 2<br>[3] L. Bourdev, S. Maji, and J. Malik. Describing people: Aposelet-based approach to attribute classification. In ICCV,2011.<br>[4] D. Chen, Z. Yuan, B. Chen, and N. Zheng. Similarity learningwith spatial constraints for person re-identification. InCVPR, 2016. 6<br>[5] W. Chen, X. Chen, J. Zhang, and K. Huang. A multi-taskdeep network for person re-identification. In AAAI, 2017. 2<br>[6] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. FeiFei.Imagenet: A large-scale hierarchical image database. InCVPR, 2009. 4<br>[7] Y. Deng, P. Luo, C. C. Loy, and X. Tang. Pedestrian attributerecognition at far distance. In ACM MM, 2014. 3<br>[8] K. Duan, D. Parikh, D. Crandall, and K. Grauman. Discoveringlocalized attributes for fine-grained recognition. InCVPR, 2012. 9<br>[9] M. Geng, Y. Wang, T. Xiang, and Y. Tian. Deep transferlearning for person re-identification. arXiv:1611.05244,2016. 2, 6, 7<br>[10] G. Gkioxari, R. Girshick, and J. Malik. Actions and attributesfrom wholes and parts. In Proceedings of the IEEEInternational Conference on Computer Vision, pages 2470–2478, 2015.<br>[11] G. Gkioxari, R. Girshick, and J. Malik. Contextual actionrecognition with r* cnn. In Proceedings of the IEEE internationalconference on computer vision, pages 1080–1088,2015.<br>[12] D. Gray and H. Tao. Viewpoint invariant pedestrian recognitionwith an ensemble of localized features. In ECCV, 2008.3<br>[13] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learningfor image recognition. In CVPR, 2016. 4<br>[14] M. Hirzer, C. Beleznai, P. M. Roth, and H. Bischof. Personre-identification by descriptive and discriminative classification.In Scandinavian conference on Image analysis, pages91–102. Springer, 2011.<br>[15] C. Jose and F. Fleuret. Scalable metric learning via weightedapproximate rank component analysis. arXiv:1603.00370,2016. 6<br>[16] S. Khamis, C.-H. Kuo, V. K. Singh, V. D. Shet, and L. S.Davis. Joint learning for attribute-consistent person reidentification.In ECCV, 2014. 1, 3<br>[17] A. Krizhevsky, I. Sutskever, and G. E. Hinton. Imagenetclassification with deep convolutional neural networks. InNIPS, 2012. 4<br>[18] A. Lanitis, C. Draganova, and C. Christodoulou. Comparingdifferent classifiers for automatic age estimation. IEEETransactions on Systems, Man, and Cybernetics, Part B (Cybernetics),34(1):621–628, 2004. 3<br>[19] R. Layne, T. M. Hospedales, and S. Gong. Attributes-basedre-identification. In Person Re-Identification, pages 93–117.Springer, 2014. 3<br>[20] R. Layne, T. M. Hospedales, and S. Gong. Re-id: Huntingattributes in the wild. In BMVC, 2014. 3<br>[21] R. Layne, T. M. Hospedales, S. Gong, and Q. Mary. Personre-identification by attributes. In BMVC, 2012. 1, 3<br>[22] D. Li, Z. Zhang, X. Chen, H. Ling, and K. Huang. Arichly annotated dataset for pedestrian attribute recognition.arXiv:1603.07054, 2016. 3<br>[23] W. Li, R. Zhao, T. Xiao, and X. Wang. Deepreid: Deep filterpairing neural network for person re-identification. In CVPR,2014. 2<br>[24] S. Liao, Y. Hu, X. Zhu, and S. Z. Li. Person re-identificationby local maximal occurrence representation and metriclearning. In CVPR, 2015. 6<br>[25] Y. Lin, L. Zheng, Z. Zheng, Y. Wu, and Y. Yang. Improvingperson re-identification by attribute and identity learning.arXiv preprint arXiv:1703.07220, 2017.<br>[26] C. Liu, S. Gong, C. C. Loy, and X. Lin. Person reidentification:What features are important? In ECCV, pages391–401. Springer, 2012.<br>[27] Z. Liu, P. Luo, X. Wang, and X. Tang. Deep learning faceattributes in the wild. In ICCV, 2015. 3<br>[28] C. C. Loy, C. Liu, and S. Gong. Person re-identification bymanifold ranking. In ICIP, 2013. 3<br>[29] B. Moghaddam and M.-H. Yang. Learning gender with supportfaces. TPAMI, 24(5):707–711, 2002. 3<br>[30] D. Parikh and K. Grauman. Relative attributes. In ICCV,2011. 9<br>[31] E. Ristani, F. Solera, R. Zou, R. Cucchiara, and C. Tomasi.Performance measures and a data set for multi-target, multicameratracking. In ECCV, 2016. 5<br>[32] L. Shuang, X. Tong, L. Hongsheng, Z. Bolei, Y. Dayu, andW. Xiaogang. Person search with natural language description.arXiv:1702.05729, 2017. 3<br>[33] C. Su, F. Yang, S. Zhang, Q. Tian, L. S. Davis, and W. Gao.Multi-task learning with low rank attribute embedding forperson re-identification. In ICCV, 2015. 1, 3<br>[34] C. Su, S. Zhang, J. Xing, W. Gao, and Q. Tian.Deep attributes driven multi-camera person re-identification.arXiv:1605.03259, 2016. 1, 6<br>[35] Y. Sun, Y. Chen, X. Wang, and X. Tang. Deep learning facerepresentation by joint identification-verification. In NIPS,2014. 2<br>[36] E. S. Tetsu Matsukawa. Person re-identification using cnnfeatures learned from combination of attributes. ICPR, 2016.3<br>[37] E. Ustinova, Y. Ganin, and V. Lempitsky. Multiregionbilinear convolutional neural networks for person reidentification.arXiv:1512.05300, 2015. 6<br>[38] R. R. Varior, M. Haloi, and G. Wang. Gated siameseconvolutional neural network architecture for human reidentification.In ECCV, 2016. 2, 6<br>[39] R. R. Varior, B. Shuai, J. Lu, D. Xu, and G. Wang. Asiamese long short-term memory architecture for human reidentification.In ECCV, 2016. 6<br>[40] L. Wu, C. Shen, and A. v. d. Hengel. Deep linear discriminantanalysis on fisher networks: A hybrid architecture forperson re-identification. arXiv:1606.01595, 2016. 6<br>[41] T. Xiao, H. Li, W. Ouyang, and X. Wang. Learning deep featurerepresentations with domain guided dropout for personre-identification. arXiv:1604.07528, 2016. 2<br>[42] T. Xiao, S. Li, B. Wang, L. Lin, and X. Wang. End-to-enddeep learning for person search. arXiv:1604.01850, 2016. 2<br>[43] S. Yang, P. Luo, C.-C. Loy, and X. Tang. From facial partsresponses to face detection: A deep learning approach. InICCV, 2015. 3<br>[44] D. Yi, Z. Lei, S. Liao, and S. Z. Li. Deep metric learning forperson re-identification. In ICPR, 2014. 2<br>[45] L. Zhang, T. Xiang, and S. Gong. Learning a discriminativenull space for person re-identification. arXiv:1603.02139,2016. 6<br>[46] N. Zhang, R. Farrell, F. Iandola, and T. Darrell. Deformablepart descriptors for fine-grained recognition and attributeprediction. In ICCV, 2013.<br>[47] N. Zhang, M. Paluri, M. Ranzato, T. Darrell, and L. Bourdev.Panda: Pose aligned networks for deep attribute modeling. InCVPR, 2014.<br>[48] Z. Zhang, P. Luo, C. C. Loy, and X. Tang. Facial landmarkdetection by deep multi-task learning. In ECCV, 2014. 3<br>[49] L. Zheng, Z. Bie, Y. Sun, J. Wang, C. Su, S. Wang, andQ. Tian. Mars: A video benchmark for large-scale personre-identification. In ECCV, 2016. 2<br>[50] L. Zheng, Y. Huang, H. Lu, and Y. Yang. Pose invariant embeddingfor deep person re-identification. arXiv:1701.07732,2017. 6<br>[51] L. Zheng, L. Shen, L. Tian, S. Wang, J. Wang, and Q. Tian.Scalable person re-identification: A benchmark. In ICCV,2015. 1, 2, 3, 5, 6, 7<br>[52] L. Zheng, Y. Yang, and A. G. Hauptmann. Person reidentification:Past, present and future. arXiv:1610.02984,2016. 1, 2, 4, 6<br>[53] Z. Zheng, L. Zheng, and Y. Yang. A discriminativelylearned cnn embedding for person re-identification.arXiv:1611.05666, 2016. 2, 6, 7, 8<br>[54] Z. Zheng, L. Zheng, Y. Zheng, and Yang. Unlabeled samplesgenerated by gan improve the person re-identificationbaseline in vitro. arXiv:1701.07717v3, 2017. 1, 2, 3, 5, 6</p></div><div class="popular-posts-header">相关文章</div><ul class="popular-posts"><li class="popular-posts-item"><div class="popular-posts-title"><a href="/2018/09/11/Multi-attribute-learning-for-pedestrian-attribute-recognition-in-surveillance-scenarios/" rel="bookmark">Multi-attribute learning for pedestrian attribute recognition in surveillance scenarios</a></div></li><li class="popular-posts-item"><div class="popular-posts-title"><a href="/2018/08/29/Person-Re-identification-Past-Present-and-Future/" rel="bookmark">Person Re-identification: Past, Present and Future</a></div></li><li class="popular-posts-item"><div class="popular-posts-title"><a href="/2018/09/14/SIMPLE-ONLINE-AND-REALTIME-TRACKING-WITH-A-DEEP-ASSOCIATION-METRIC/" rel="bookmark">SIMPLE ONLINE AND REALTIME TRACKING WITH A DEEP ASSOCIATION METRIC</a></div></li><li class="popular-posts-item"><div class="popular-posts-title"><a href="/2018/09/06/Aligned-ReID/" rel="bookmark">Aligned ReID</a></div></li><li class="popular-posts-item"><div class="popular-posts-title"><a href="/2018/08/21/Batch-Normalization/" rel="bookmark">Batch Normalization</a></div></li></ul><div><ul class="post-copyright"><li class="post-copyright-author"><strong>本文作者： </strong>慕湮</li><li class="post-copyright-link"><strong>本文链接：</strong> <a href="http://muyaan.com/2018/09/07/Improving-Person-Re-identification-by-Attribute-and-Identity-Learning/" title="Improving Person Re-identification by Attribute and Identity Learning">http://muyaan.com/2018/09/07/Improving-Person-Re-identification-by-Attribute-and-Identity-Learning/</a></li><li class="post-copyright-license"><strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="external nofollow noopener noreferrer" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明出处！</li></ul></div><footer class="post-footer"><div class="post-tags"><a href="/tags/Deep-Learning/" rel="tag"># Deep Learning</a> <a href="/tags/Paper/" rel="tag"># Paper</a> <a href="/tags/Pedestrian-attribute/" rel="tag"># Pedestrian attribute</a> <a href="/tags/CV/" rel="tag"># CV</a> <a href="/tags/re-ID/" rel="tag"># re-ID</a></div><div class="post-nav"><div class="post-nav-next post-nav-item"><a href="/2018/09/06/Aligned-ReID/" rel="next" title="Aligned ReID"><i class="fa fa-chevron-left"></i> Aligned ReID</a></div><span class="post-nav-divider"></span><div class="post-nav-prev post-nav-item"><a href="/2018/09/11/Multi-attribute-learning-for-pedestrian-attribute-recognition-in-surveillance-scenarios/" rel="prev" title="Multi-attribute learning for pedestrian attribute recognition in surveillance scenarios">Multi-attribute learning for pedestrian attribute recognition in surveillance scenarios <i class="fa fa-chevron-right"></i></a></div></div></footer></div></article></div></div></div><div class="sidebar-toggle"><div class="sidebar-toggle-line-wrap"><span class="sidebar-toggle-line sidebar-toggle-line-first"></span> <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span> <span class="sidebar-toggle-line sidebar-toggle-line-last"></span></div></div><aside id="sidebar" class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">文章目录</li><li class="sidebar-nav-overview" data-target="site-overview-wrap">站点概览</li></ul><section class="site-overview-wrap sidebar-panel"><div class="site-overview"><div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" src="https://avatars0.githubusercontent.com/u/3022000?s=460&v=4" alt="慕湮"><p class="site-author-name" itemprop="name">慕湮</p><p class="site-description motion-element" itemprop="description"></p></div><nav class="site-state motion-element"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">23</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/index.html"><span class="site-state-item-count">31</span> <span class="site-state-item-name">标签</span></a></div></nav><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/tycallen" target="_blank" title="GitHub" rel="external nofollow noopener noreferrer"><i class="fa fa-fw fa-github"></i>GitHub</a> </span><span class="links-of-author-item"><a href="mailto:tyc.allen@gmail.com" target="_blank" title="E-Mail" rel="external nofollow noopener noreferrer"><i class="fa fa-fw fa-envelope"></i>E-Mail</a> </span><span class="links-of-author-item"><a href="http://weibo.com/pojunallen" target="_blank" title="微博" rel="external nofollow noopener noreferrer"><i class="fa fa-fw fa-weibo"></i>微博</a> </span><span class="links-of-author-item"><a href="https://tuchong.com/1070837" target="_blank" title="图虫" rel="external nofollow noopener noreferrer"><i class="fa fa-fw fa-globe"></i>图虫</a></span></div><div class="links-of-blogroll motion-element links-of-blogroll-block"><div class="links-of-blogroll-title"><i class="fa fa-fw fa-link"></i> 友情链接</div><ul class="links-of-blogroll-list"><li class="links-of-blogroll-item"><a href="http://dotrabbit.tk" title="dotrabbit" target="_blank" rel="external nofollow noopener noreferrer">dotrabbit</a></li></ul></div></div></section><section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active"><div class="post-toc"><div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#undefined"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-Introduction"><span class="nav-text">1. Introduction</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-Related-Work"><span class="nav-text">2. Related Work</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-Attribute-Annotation"><span class="nav-text">3. Attribute Annotation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-Proposed-Method"><span class="nav-text">4. Proposed Method</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#4-1-Baseline-Methods"><span class="nav-text">4.1 Baseline Methods</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-2-Attribute-Person-Recognition-APR-Network"><span class="nav-text">4.2 Attribute-Person Recognition (APR) Network</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-Experiment"><span class="nav-text">5. Experiment</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#5-1-Datasets-and-Evaluation-Protocol"><span class="nav-text">5.1 Datasets and Evaluation Protocol</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-2-Implementation-Details"><span class="nav-text">5.2 Implementation Details</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-3-Evaluation-of-Person-Re-ID"><span class="nav-text">5.3 Evaluation of Person Re-ID</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-4-Evaluation-of-Attribute-Recognition"><span class="nav-text">5.4 Evaluation of Attribute Recognition</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-Conclusions"><span class="nav-text">6. Conclusions</span></a></li></ol></div></div></section></div></aside></div></main><footer id="footer" class="footer"><div class="footer-inner"><div class="copyright">&copy; 2015 – <span itemprop="copyrightYear">2018</span> <span class="with-love" id="animate"><i class="fa fa-user"></i> </span><span class="author" itemprop="copyrightHolder">慕湮</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-area-chart"></i> </span><span title="站点总字数">320k</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-coffee"></i> </span><span title="站点阅读时长">9:42</span></div><div class="powered-by">由 <a class="theme-link" target="_blank" rel="external nofollow noopener noreferrer" href="https://hexo.io">Hexo</a> 强力驱动</div><span class="post-meta-divider">|</span><div class="theme-info">主题 – <a class="theme-link" target="_blank" rel="external nofollow noopener noreferrer" href="https://theme-next.org">NexT.Muse</a></div></div></footer><div class="back-to-top"><i class="fa fa-arrow-up"></i></div></div><script type="text/javascript">"[object Function]"!==Object.prototype.toString.call(window.Promise)&&(window.Promise=null)</script><script type="text/javascript" src="//cdn.staticfile.org/jquery/2.1.3/jquery.min.js"></script><script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script><script type="text/javascript" src="//cdn.staticfile.org/velocity/1.2.1/velocity.min.js"></script><script type="text/javascript" src="//cdn.staticfile.org/velocity/1.2.1/velocity.ui.min.js"></script><script type="text/javascript" src="//cdn.staticfile.org/fancybox/2.1.5/jquery.fancybox.min.js"></script><script type="text/javascript" src="/js/src/utils.js?v=6.4.1"></script><script type="text/javascript" src="/js/src/motion.js?v=6.4.1"></script><script type="text/javascript" src="/js/src/scrollspy.js?v=6.4.1"></script><script type="text/javascript" src="/js/src/post-details.js?v=6.4.1"></script><script type="text/javascript" src="/js/src/bootstrap.js?v=6.4.1"></script><script>function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();

      Counter('get', '/classes/Counter', { where: JSON.stringify({ url }) })
        .done(function ({ results }) {
          if (results.length > 0) {
            var counter = results[0];
            
              var $element = $(document.getElementById(url));
              $element.find('.leancloud-visitors-count').text(counter.time + 1);
            
            Counter('put', `/classes/Counter/${counter.objectId}`, JSON.stringify({ time: { "__op":"Increment", "amount":1 } }))
            
            .fail(function ({ responseJSON }) {
                console.log('Failed to save Visitor num, with error message: ' + responseJSON.error);
            })
          } else {
            
              Counter('post', '/classes/Counter', JSON.stringify({ title: title, url: url, time: 1}))
                .done(function () {
                  var $element = $(document.getElementById(url));
                  $element.find('.leancloud-visitors-count').text(1);
                })
                .fail(function () {
                  console.log('Failed to create');
                });
            
          }
        })
      .fail(function ({ responseJSON }) {
        console.log('LeanCloud Counter Error:' + responseJSON.code + " " + responseJSON.error);
      });
    }
    

    $(function() {
      $.get('https://app-router.leancloud.cn/2/route?appId=' + "UWGXBMGbguCDhSCbC3NrUQtL-gzGzoHsz")
        .done(function ({ api_server }) {
          var Counter = function (method, url, data) {
            return $.ajax({
              method: method,
              url: `https://${api_server}/1.1${url}`,
              headers: {
                'X-LC-Id': "UWGXBMGbguCDhSCbC3NrUQtL-gzGzoHsz",
                'X-LC-Key': "ke1jrA5b6VyR89Kqqqwf2kPP",
                'Content-Type': 'application/json',
              },
              data: data,
            });
          };
          
          addCount(Counter);
          
        })
    });</script><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}()</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      },
      TeX: {equationNumbers: { autoNumber: "AMS" }}
    });</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });</script><script type="text/javascript" src="//cdn.jsdelivr.net/npm/mathjax@2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script async src="http://muyaan.com/js/src/async.js"></script></body></html>