<!DOCTYPE html><html class="theme-next muse use-motion" lang="zh-CN"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><script src="https://cdn.staticfile.org/pace/1.0.2/pace.min.js"></script><link href="https://cdn.staticfile.org/pace/1.0.2/themes/blue/pace-theme-big-counter.min.css" rel="stylesheet"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link href="//cdn.staticfile.org/fancybox/2.1.5/jquery.fancybox.min.js" rel="stylesheet" type="text/css"><link href="//cdn.staticfile.org/font-awesome/4.6.2/css/font-awesome.min.css" rel="stylesheet" type="text/css"><link href="/css/main.css?v=6.4.1" rel="stylesheet" type="text/css"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=6.4.1"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=6.4.1"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=6.4.1"><link rel="mask-icon" href="/images/logo.svg?v=6.4.1" color="#222"><script type="text/javascript" id="hexo.configurations">var NexT=window.NexT||{},CONFIG={root:"/",scheme:"Muse",version:"6.4.1",sidebar:{position:"left",display:"post",offset:12,b2t:!1,scrollpercent:!1,onmobile:!1},fancybox:!0,fastclick:!1,lazyload:!0,tabs:!0,motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},algolia:{applicationID:"",apiKey:"",indexName:"",hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}}}</script><meta name="description" content="将移动和外观结合起来的在线实时追踪论文。挺多相关工作不懂，马氏距离、卡尔曼滤波、Hungarian算法、Association等，要停下来看看除了论文的相关知识了。SIMPLE ONLINE AND REALTIME TRACKING WITH A DEEP ASSOCIATION METRICNicolai Wojke, Alex Bewley, Dietrich PaulusUniversit"><meta name="keywords" content="Deep Learning,Paper,CV,Tracking"><meta property="og:type" content="article"><meta property="og:title" content="SIMPLE ONLINE AND REALTIME TRACKING WITH A DEEP ASSOCIATION METRIC"><meta property="og:url" content="http://muyaan.com/2018/09/14/SIMPLE-ONLINE-AND-REALTIME-TRACKING-WITH-A-DEEP-ASSOCIATION-METRIC/index.html"><meta property="og:site_name" content="慕湮"><meta property="og:description" content="将移动和外观结合起来的在线实时追踪论文。挺多相关工作不懂，马氏距离、卡尔曼滤波、Hungarian算法、Association等，要停下来看看除了论文的相关知识了。SIMPLE ONLINE AND REALTIME TRACKING WITH A DEEP ASSOCIATION METRICNicolai Wojke, Alex Bewley, Dietrich PaulusUniversit"><meta property="og:locale" content="zh-CN"><meta property="og:image" content="http://muyaan.com/2018/09/14/SIMPLE-ONLINE-AND-REALTIME-TRACKING-WITH-A-DEEP-ASSOCIATION-METRIC/1536906301090.png"><meta property="og:image" content="http://muyaan.com/2018/09/14/SIMPLE-ONLINE-AND-REALTIME-TRACKING-WITH-A-DEEP-ASSOCIATION-METRIC/1536906323339.png"><meta property="og:image" content="http://muyaan.com/2018/09/14/SIMPLE-ONLINE-AND-REALTIME-TRACKING-WITH-A-DEEP-ASSOCIATION-METRIC/1536917640754.png"><meta property="og:image" content="http://muyaan.com/2018/09/14/SIMPLE-ONLINE-AND-REALTIME-TRACKING-WITH-A-DEEP-ASSOCIATION-METRIC/1536652264583.png"><meta property="og:updated_time" content="2018-09-14T11:40:11.222Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="SIMPLE ONLINE AND REALTIME TRACKING WITH A DEEP ASSOCIATION METRIC"><meta name="twitter:description" content="将移动和外观结合起来的在线实时追踪论文。挺多相关工作不懂，马氏距离、卡尔曼滤波、Hungarian算法、Association等，要停下来看看除了论文的相关知识了。SIMPLE ONLINE AND REALTIME TRACKING WITH A DEEP ASSOCIATION METRICNicolai Wojke, Alex Bewley, Dietrich PaulusUniversit"><meta name="twitter:image" content="http://muyaan.com/2018/09/14/SIMPLE-ONLINE-AND-REALTIME-TRACKING-WITH-A-DEEP-ASSOCIATION-METRIC/1536906301090.png"><link rel="canonical" href="http://muyaan.com/2018/09/14/SIMPLE-ONLINE-AND-REALTIME-TRACKING-WITH-A-DEEP-ASSOCIATION-METRIC/"><script type="text/javascript" id="page.configurations">CONFIG.page={sidebar:""}</script><title>SIMPLE ONLINE AND REALTIME TRACKING WITH A DEEP ASSOCIATION METRIC | 慕湮</title><script type="text/javascript">var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?ca5844321cfb80fdf6f12b4dcc326991";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><noscript><style type="text/css">.sidebar-inner,.use-motion .brand,.use-motion .collection-title,.use-motion .comments,.use-motion .menu-item,.use-motion .motion-element,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .logo,.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.logo-line-after i{right:initial}</style></noscript></head><body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-CN"><div class="container sidebar-position-left page-post-detail"><div class="headband"></div><header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-wrapper"><div class="site-meta"><div class="custom-logo-site-title"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span> <span class="site-title">慕湮</span> <span class="logo-line-after"><i></i></span></a></div><h1 class="site-subtitle" itemprop="description">白日放歌须纵酒</h1></div><div class="site-nav-toggle"><button aria-label="切换导航栏"><span class="btn-bar"></span> <span class="btn-bar"></span> <span class="btn-bar"></span></button></div></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i><br>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i><br>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i><br>标签</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i><br>归档</a></li></ul></nav></div></header><main id="main" class="main"><div class="main-inner"><div class="content-wrap"><div id="content" class="content"><div id="posts" class="posts-expand"><article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article"><div class="post-block"><link itemprop="mainEntityOfPage" href="http://muyaan.com/2018/09/14/SIMPLE-ONLINE-AND-REALTIME-TRACKING-WITH-A-DEEP-ASSOCIATION-METRIC/"><span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person"><meta itemprop="name" content="慕湮"><meta itemprop="description" content=""><meta itemprop="image" content="https://avatars0.githubusercontent.com/u/3022000?s=460&v=4"></span><span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization"><meta itemprop="name" content="慕湮"></span><header class="post-header"><h2 class="post-title" itemprop="name headline">SIMPLE ONLINE AND REALTIME TRACKING WITH A DEEP ASSOCIATION METRIC</h2><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2018-09-14 19:20:19 / 修改时间：19:40:11" itemprop="dateCreated datePublished" datetime="2018-09-14T19:20:19+08:00">2018-09-14</time> </span><span id="/2018/09/14/SIMPLE-ONLINE-AND-REALTIME-TRACKING-WITH-A-DEEP-ASSOCIATION-METRIC/" class="leancloud_visitors" data-flag-title="SIMPLE ONLINE AND REALTIME TRACKING WITH A DEEP ASSOCIATION METRIC"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="post-meta-item-text">阅读次数：</span> <span class="leancloud-visitors-count"></span></span><div class="post-symbolscount"><span class="post-meta-item-icon"><i class="fa fa-file-word-o"></i> </span><span class="post-meta-item-text">本文字数：</span> <span title="本文字数">8.3k</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-clock-o"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span title="阅读时长">15 分钟</span></div></div></header><div class="post-body" itemprop="articleBody"><p>将移动和外观结合起来的在线实时追踪论文。挺多相关工作不懂，马氏距离、卡尔曼滤波、Hungarian算法、Association等，要停下来看看除了论文的相关知识了。</p><blockquote><p><a href="https://arxiv.org/abs/1703.07402" rel="external nofollow noopener noreferrer" target="_blank">SIMPLE ONLINE AND REALTIME TRACKING WITH A DEEP ASSOCIATION METRIC</a></p><p>Nicolai Wojke, Alex Bewley, Dietrich Paulus<br>University of Koblenz-Landau, Queensland University of Technology, 2017</p></blockquote><a id="more"></a><hr><h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h2><p>由于近期物体检测的成果，通过检测来追踪tracking-by-detection变成了流行的多物体追踪方法。这一方法中物体踪迹trajectory常常是全局最优问题，同时处理整批视频常。如flow network formulation和概率图模型都是这类流行框架。但因为批处理，它们无法应用到目标身份在每个time step都available的在线场景。更传统的方法是Multiple Hypothesis Tracking（MHT）和Joint Probabilistic Data Association Filter（JPDAF）。这些方法以frame-by-frame的方式进行数据关联。JPDAF通过为独立测量的相关性似然加权，生成single state hypothesis。MHT跟踪所有可能hypotheses，但因计算量必须进行剪枝。近期的tracking-by-detection都再次使用了这些方法，取得了不错的结果，但性能建立在计算量和实现复杂度的增长上。</p><p>简单在线实时追踪SORT是一个简单得多的框架，在图片空间进行卡尔曼Kalman滤波，并使用带一个度量了限位框重叠的关联度量的Hungarian方法进行逐帧数据关联。这一简单方法在高帧率下得到了良好的性能。</p><p>尽管获得了整体不错的追踪精度和准确率，SORT的身份交互数相对较多。这是因为使用的关联度量仅在状态估计不确定性低时准确。因此SORT在追踪有遮挡的轨迹时有缺陷，因为它们常出现在frontal-view正面视角场景中。我们把关联度量替换为一个合并了动作和外观信息的度量，克服了这个问题。特别地，我们训练了一个CNN来区分大规模Re-ID数据集中的行人。通过集成这一网络，我们增强了对缺失和遮挡的健壮性，同时保持了系统易实现、高效及能应用到在线场景的特性。</p><h2 id="2-Sort-With-Deep-Association-Metric"><a href="#2-Sort-With-Deep-Association-Metric" class="headerlink" title="2. Sort With Deep Association Metric"></a>2. Sort With Deep Association Metric</h2><p>我们采用了传统的单假设追踪方法，加上递归卡尔曼滤波和逐帧数据关联。</p><h3 id="2-1-Track-Handling-and-State-Estimation"><a href="#2-1-Track-Handling-and-State-Estimation" class="headerlink" title="2.1 Track Handling and State Estimation"></a>2.1 Track Handling and State Estimation</h3><p>跟踪控制和卡尔曼滤波几乎与原始方法$^{[12]}$一样。我们假定了一个非常通用的追踪场景，摄像头是无标定的，且我们没有运动平台ego-motion信息。这些情况为滤波网络提出了挑战，它主要设置考虑的是近期的多物体追踪benchmark。因此我们跟踪场景定义在八维状态空间（$u,v,\gamma,h,\dot x,\dot y,\dot \gamma,\dot h$），其中包含限位框中心位置($u,v$)，长宽比$\gamma$，高度h，和它们在图片坐标系中相对速度。我们使用一个带常量速度和线性observation模型的标准卡尔曼滤波器，我们把限位框坐标($u,v,\gamma,h$)作为物体状态的直接observations。</p><p>对于每个track k我们统计自最后一次成功关联度量$a_k$的帧数。超过预定义的最大age $A_{max}$的track认为是离开了场景，将从track集移除。对每个检测都不能关联到一个已有track的，初始化一个新的track假设。这些新的track在它们前3帧被分类为暂时性tentative的。在这段时间中我们期望每个time step都有成功的度量关联。前三帧未能成功关联到一个度量的track会被删除。</p><h3 id="2-2-Assignment-Problem"><a href="#2-2-Assignment-Problem" class="headerlink" title="2.2 Assignment Problem"></a>2.2 Assignment Problem</h3><p>关联预测的卡尔曼状态和新到达的度量的传统方法是，建立一个能用Hungarian算法解决的assignment问题。在问题方程中我们通过合并两个恰当appropriate度量来集成动作和外观信息。</p><p>为了包含动作信息，我们使用了（平方）马氏Mahalanobis距离预测的卡尔曼状态和新到达的度量：</p><script type="math/tex;mode=display">d^{(1)} (i,j) =(d_j-y_i)^T S_i^{-1} (d_j-y_i) \tag1</script><p>我们把第i个track分布到度量空间的投影记做$(y_i,S_i)$，第j个限位框记做$d_j$。马氏距离通过度量检测与平均track位置有多远的标准差，考虑不确定的状态估计。使用这一度量可以排除不像的管理，通过将马氏距离阈值设在95%，间距计算自inverse $x^2$分布。这一决策通过以下指示器决定。</p><script type="math/tex;mode=display">b_{i,j} ^{(1)} = \mathbb 1 [d^{(1)} (i,j) \leq t ^{(1)}] \tag2</script><p>如果第i个track和第j个检测是可接受的，则值为1。对于我们的4维度量空间，对应马氏距离阈值为$t^{(1)} = 9.4877$。</p><p>尽管马氏距离在移动不确定性低时是个合适的关联度量，我们的图片空间问题转换为从卡尔曼滤波框架提供的一个物体位置的粗略估计的状态分布预测问题。特别的，我们未考虑的摄像机运动会在图片平面产生快速移动，让马氏距离对通过遮挡的追踪变成一个无知的度量。因此我们为assignment问题集成了第二个度量。对每个限位框detection $d_j$我们计算一个外观描述符$r_j$，$|r_j| = 1$。不仅如此，我们还维护了一个图集$\mathfrak R_k=\{r_k^{(i)}\}_{k=1}^{L_k}$，对每个track k维护了最后$L_k = 100$相关外观描述符。接着我们使用第二个度量测量第i个track和第j个检测在外观空间中的最小cosine距离：</p><script type="math/tex;mode=display">d^{(2)} (i,j) = \min \{ 1- r_j ^T r_k^{(i)} | r_k ^ \in \mathfrak R_i \} \tag 3</script><p>同样，我们引入了一个二元变量来指示是否一个关联在这一度量下是可接受的：</p><script type="math/tex;mode=display">b_{i,j}^{(2)} = \mathbb 1 [d^{(2)] *i,j} \leq t^{(2)}] \tag 4</script><p>我们为这一指示器在特定训练集上找到了合适的阈值。实际应用中，我们使用了一个预训练的CNN来计算限位框伟哥描述符。网络结构见章节2.4。</p><p>合并后，两个度量都在assignment问题的不同领域互补。马氏距离基于对短期预测有用的移动提供可能的物体位置信息。余弦距离考虑对在长期遮挡后恢复id特别有用的外观信息。我们用一个加权和合并两个度量：</p><script type="math/tex;mode=display">c_{i,j} = \lambda d^{(1)} (i,j) + (1-\lambda) d^{(2)} (i,j) \tag 5</script><p>当某个关联满足两个度量时，我们称其可采纳的：</p><script type="math/tex;mode=display">b_{i,j} = \prod_{m=1}^2 b_{i,j}^{(m)} \tag 6</script><p>超参数$\lambda$用于控制各度量的影响。实验中我们发现当摄像头移动很大时，$\lambda = 1$是合理选择。这一设定下关联cost仅使用外观信息。不过马氏阈值仍用于丢弃候选。</p><h3 id="2-3-Matching-Cascade"><a href="#2-3-Matching-Cascade" class="headerlink" title="2.3 Matching Cascade"></a>2.3 Matching Cascade</h3><p>与其把measurement-to-track关联当做一个global assignment problem，我们采用了瀑布式的子问题集。考虑以下情况：当一个物体被遮挡很长时间，后续的卡尔曼滤波预测与物体位置不确定的关联会增加。相应的，概率质量mass散布于状态空间，observation likelihood就变得不那么陡峭。直觉上讲，关联度量应通过增加measurement-to-track距离来对这一概率质量散布负责。反直觉的是，当两个track为同一个detection竞争时，马氏距离青睐不确定性更大的，因为它能把任何检测对projected track mean的标准差距离有效降低。这是个不需要的特性，增加了track碎片和不稳定的track。所以我们提出了一个匹配级联，给与更近期的物体优先，to encode our notion of probability spread in the association likelihood</p><p>Listing 1是我们的匹配算法。输入包括track集合$\mathcal T$和检测索引$\mathcal D$，和最大age$\mathcal A_{\max}$。第1、2行我们计算了关联cost矩阵$\mathcal C$和可采纳的关联的矩阵$\mathcal B$。我们接着遍历track age n来解决一个随age增长的track的linear assignment问题。在第6行我们选择tracks $\mathcal T_n$的一个在过去n帧都没和任意检测关联的track的子集。在第7行，我们解决了$\mathcal T_n$和未匹配的检测集$\mathcal U$间的linear assignment。第8、9行我们更新了匹配了和未匹配的检测集，第11行返回它们。这一算法优先考虑有更小age的track，如更近期的track。</p><p><img src="/2018/09/14/SIMPLE-ONLINE-AND-REALTIME-TRACKING-WITH-A-DEEP-ASSOCIATION-METRIC/./1536906301090.png" alt="Listing 1"></p><p>在最终匹配阶段，我们如原始SORT算法$^{[12]}$一样，运行在$age n = 1$的未确认和未匹配的track集的IoU关联。这有助于考虑突然的外观变化，提升对不正确的初始化的健壮性。</p><h3 id="2-4-Deep-Appearance-Descriptor"><a href="#2-4-Deep-Appearance-Descriptor" class="headerlink" title="2.4 Deep Appearance Descriptor"></a>2.4 Deep Appearance Descriptor</h3><p>没有额外度量训练，仅使用简单最近邻查询时，我们的方法应用前需要离线训练一个有识别力的特征集。因此我们使用了一个在大规模person Re-ID数据集（超过1261个行人的1100000张图片）上预训练的CNN。</p><p>CNN架构见表1。我们使用了两个卷积层，后跟6个残差块。Dense10层计算了128维的全局特征图。最后一层使用batch和l2归一化将特征投影到unit 超球面hypersphere，来与我们的余弦外观度量兼容。网络共有2800864个参数，一次有32个限位框的前向传播在GTX 1050移动GPU上需30ms。</p><p><img src="/2018/09/14/SIMPLE-ONLINE-AND-REALTIME-TRACKING-WITH-A-DEEP-ASSOCIATION-METRIC/./1536906323339.png" alt="表1"></p><h2 id="3-Experiments"><a href="#3-Experiments" class="headerlink" title="3. Experiments"></a>3. Experiments</h2><p>我们在MOT16 benchmark上评定了我们的tracker的性能。它在7个有挑战的测试序列上评估追踪性能，包括移动摄像头的正面视角和高角度监控。我们依赖[16]的检测，作为我们tracker的输入。一个在公有和私有数据集上训练的Faster RCNN模型。我们也在同样的检测上运行了SORT作为对比。</p><p>测试时参数$\lambda = 0, A_{\max} = 30$。如[16]一样用confidence阈值为0.3过滤检测。测试按如下度量进行：</p><ul><li>Multi-object tracking accuracy(MOTA): 在false positive，false Negative和身份变化上的总体追踪准确率。</li><li>Multi-object tracking precision(MOTP): 报告的位置和gt的限位框重叠总体精度。</li><li>Mostly tracked(MT): 在80%以上的时间都标注为同样标签的gt track。</li><li>Mostly lost(ML): 最多仅track到20%的gt track</li><li>Identify switch(ID): 一个gt track上报的身份变化次数</li><li>Fragmentation(FM): 一个track被依赖检测打断的数量</li></ul><p>结果见表2。总的来说由于继承了外观信息，我们成功地在较长的遮挡后保持身份。</p><p><img src="/2018/09/14/SIMPLE-ONLINE-AND-REALTIME-TRACKING-WITH-A-DEEP-ASSOCIATION-METRIC/./1536917640754.png" alt="表2"></p><p><img src="/2018/09/14/SIMPLE-ONLINE-AND-REALTIME-TRACKING-WITH-A-DEEP-ASSOCIATION-METRIC/./1536652264583.png" alt="图1"></p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><p>[1] L. Zhang, Y. Li, and R. Nevatia, “Global data associationfor multi-object tracking using network flows,” inCVPR, 2008, pp. 1–8.<br>[2] H. Pirsiavash, D. Ramanan, and C. C. Fowlkes,“Globally-optimal greedy algorithms for tracking a variablenumber of objects,” in CVPR, 2011, pp. 1201–1208.<br>[3] J. Berclaz, F. Fleuret, E. Turetken, and P. Fua, “Multi- ¨ple object tracking using k-shortest paths optimization,”IEEE Trans. Pattern Anal. Mach. Intell., vol. 33, no. 9,pp. 1806–1819, 2011.<br>[4] B. Yang and R. Nevatia, “An online learned CRF modelfor multi-target tracking,” in CVPR, 2012, pp. 2034–2041.<br>[5] B. Yang and R. Nevatia, “Multi-target tracking by onlinelearning of non-linear motion patterns and robustappearance models,” in CVPR, 2012, pp. 1918–1925.<br>[6] A. Andriyenko, K. Schindler, and S. Roth, “Discretecontinuousoptimization for multi-target tracking,” inCVPR, 2012, pp. 1926–1933.<br>[7] A. Milan, K. Schindler, and S. Roth, “Detection- andtrajectory-level exclusion in multiple object tracking,”in CVPR, 2013, pp. 3682–3689.<br>[8] D. B. Reid, “An algorithm for tracking multiple targets,”IEEE Trans. Autom. Control, vol. 24, no. 6, pp. 843–854, 1979.<br>[9] T.E. Fortmann, Y. Bar-Shalom, and M. Scheffe, “Sonartracking of multiple targets using joint probabilistic dataassociation,” IEEE J. Ocean. Eng., vol. 8, no. 3, pp.173–184, 1983.<br>[10] C. Kim, F. Li, A. Ciptadi, and J. M. Rehg, “Multiplehypothesis tracking revisited,” in ICCV, 2015, pp. 4696–4704.<br>[11] S.H. Rezatofighi, A. Milan, Z. Zhang, Qi. Shi, An. Dick,and I. Reid, “Joint probabilistic data association revisited,”in ICCV, 2015, pp. 3047–3055.<br>[12] A. Bewley, G. Zongyuan, F. Ramos, and B. Upcroft,“Simple online and realtime tracking,” in ICIP, 2016,pp. 3464–3468.<br>[13] L. Leal-Taixe, A. Milan, I. Reid, S. Roth, and ´K. Schindler, “MOTChallenge 2015: Towards a benchmarkfor multi-target tracking,” arXiv:1504.01942 [cs],2015.<br>[14] S. Ren, K. He, R. Girshick, and J. Sun, “Faster R-CNN:Towards real-time object detection with region proposalnetworks,” in NIPS, 2015.<br>[15] A. Milan, L. Leal-Taixe, I. Reid, S. Roth, and ´K. Schindler, “Mot16: A benchmark for multi-objecttracking,” arXiv preprint arXiv:1603.00831, 2016.<br>[16] F. Yu, W. Li, Q. Li, Y. Liu, X. Shi, and J. Yan, “Poi:Multiple object tracking with high performance detectionand appearance feature,” in ECCV. Springer, 2016,pp. 36–42.<br>[17] M. Keuper, S. Tang, Y. Zhongjie, B. Andres, T. Brox,and B. Schiele, “A multi-cut formulation for jointsegmentation and tracking of multiple objects,” arXivpreprint arXiv:1607.06317, 2016.<br>[18] B. Lee, E. Erdenee, S. Jin, M. Y. Nam, Y. G. Jung, andP. K. Rhee, “Multi-class multi-object tracking usingchanging point detection,” in ECCV. Springer, 2016,pp. 68–83.<br>[19] W. Choi, “Near-online multi-target tracking with aggregatedlocal flow descriptor,” in ICCV, 2015, pp. 3029–3037.<br>[20] R. Sanchez-Matilla, F. Poiesi, and A. Cavallaro, “Onlinemulti-target tracking with strong and weak detections,”in European Conference on Computer Vision. Springer,2016, pp. 84–99.<br>[21] L. Zheng, Z. Bie, Y. Sun, J. Wang, C. Su, S. Wang, andQ. Tian, “MARS: A video benchmark for large-scaleperson re-identification,” in ECCV, 2016.<br>[22] S. Zagoruyko and N. Komodakis, “Wide residual networks,”in BMVC, 2016, pp. 1–12.<br>[23] K. Bernardin and R. Stiefelhagen, “Evaluating multipleobject tracking performance: The CLEAR MOTmetrics,” EURASIP J. Image Video Process, vol. 2008,2008.</p></div><div class="popular-posts-header">相关文章</div><ul class="popular-posts"><li class="popular-posts-item"><div class="popular-posts-title"><a href="/2018/09/11/Multi-attribute-learning-for-pedestrian-attribute-recognition-in-surveillance-scenarios/" rel="bookmark">Multi-attribute learning for pedestrian attribute recognition in surveillance scenarios</a></div></li><li class="popular-posts-item"><div class="popular-posts-title"><a href="/2018/09/07/Improving-Person-Re-identification-by-Attribute-and-Identity-Learning/" rel="bookmark">Improving Person Re-identification by Attribute and Identity Learning</a></div></li><li class="popular-posts-item"><div class="popular-posts-title"><a href="/2018/08/21/Batch-Normalization/" rel="bookmark">Batch Normalization</a></div></li><li class="popular-posts-item"><div class="popular-posts-title"><a href="/2018/09/03/MTCNN/" rel="bookmark">MTCNN</a></div></li><li class="popular-posts-item"><div class="popular-posts-title"><a href="/2018/08/29/Person-Re-identification-Past-Present-and-Future/" rel="bookmark">Person Re-identification: Past, Present and Future</a></div></li></ul><div><ul class="post-copyright"><li class="post-copyright-author"><strong>本文作者： </strong>慕湮</li><li class="post-copyright-link"><strong>本文链接：</strong> <a href="http://muyaan.com/2018/09/14/SIMPLE-ONLINE-AND-REALTIME-TRACKING-WITH-A-DEEP-ASSOCIATION-METRIC/" title="SIMPLE ONLINE AND REALTIME TRACKING WITH A DEEP ASSOCIATION METRIC">http://muyaan.com/2018/09/14/SIMPLE-ONLINE-AND-REALTIME-TRACKING-WITH-A-DEEP-ASSOCIATION-METRIC/</a></li><li class="post-copyright-license"><strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="external nofollow noopener noreferrer" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明出处！</li></ul></div><footer class="post-footer"><div class="post-tags"><a href="/tags/Deep-Learning/" rel="tag"># Deep Learning</a> <a href="/tags/Paper/" rel="tag"># Paper</a> <a href="/tags/CV/" rel="tag"># CV</a> <a href="/tags/Tracking/" rel="tag"># Tracking</a></div><div class="post-nav"><div class="post-nav-next post-nav-item"><a href="/2018/09/11/Multi-attribute-learning-for-pedestrian-attribute-recognition-in-surveillance-scenarios/" rel="next" title="Multi-attribute learning for pedestrian attribute recognition in surveillance scenarios"><i class="fa fa-chevron-left"></i> Multi-attribute learning for pedestrian attribute recognition in surveillance scenarios</a></div><span class="post-nav-divider"></span><div class="post-nav-prev post-nav-item"><a href="/2018/09/28/深度学习CV方向技能树/" rel="prev" title="深度学习CV方向技能树">深度学习CV方向技能树 <i class="fa fa-chevron-right"></i></a></div></div></footer></div></article></div></div></div><div class="sidebar-toggle"><div class="sidebar-toggle-line-wrap"><span class="sidebar-toggle-line sidebar-toggle-line-first"></span> <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span> <span class="sidebar-toggle-line sidebar-toggle-line-last"></span></div></div><aside id="sidebar" class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">文章目录</li><li class="sidebar-nav-overview" data-target="site-overview-wrap">站点概览</li></ul><section class="site-overview-wrap sidebar-panel"><div class="site-overview"><div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" src="https://avatars0.githubusercontent.com/u/3022000?s=460&v=4" alt="慕湮"><p class="site-author-name" itemprop="name">慕湮</p><p class="site-description motion-element" itemprop="description"></p></div><nav class="site-state motion-element"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">23</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/index.html"><span class="site-state-item-count">31</span> <span class="site-state-item-name">标签</span></a></div></nav><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/tycallen" target="_blank" title="GitHub" rel="external nofollow noopener noreferrer"><i class="fa fa-fw fa-github"></i>GitHub</a> </span><span class="links-of-author-item"><a href="mailto:tyc.allen@gmail.com" target="_blank" title="E-Mail" rel="external nofollow noopener noreferrer"><i class="fa fa-fw fa-envelope"></i>E-Mail</a> </span><span class="links-of-author-item"><a href="http://weibo.com/pojunallen" target="_blank" title="微博" rel="external nofollow noopener noreferrer"><i class="fa fa-fw fa-weibo"></i>微博</a> </span><span class="links-of-author-item"><a href="https://tuchong.com/1070837" target="_blank" title="图虫" rel="external nofollow noopener noreferrer"><i class="fa fa-fw fa-globe"></i>图虫</a></span></div><div class="links-of-blogroll motion-element links-of-blogroll-block"><div class="links-of-blogroll-title"><i class="fa fa-fw fa-link"></i> 友情链接</div><ul class="links-of-blogroll-list"><li class="links-of-blogroll-item"><a href="http://dotrabbit.tk" title="dotrabbit" target="_blank" rel="external nofollow noopener noreferrer">dotrabbit</a></li></ul></div></div></section><section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active"><div class="post-toc"><div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-Introduction"><span class="nav-text">1. Introduction</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-Sort-With-Deep-Association-Metric"><span class="nav-text">2. Sort With Deep Association Metric</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-Track-Handling-and-State-Estimation"><span class="nav-text">2.1 Track Handling and State Estimation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-Assignment-Problem"><span class="nav-text">2.2 Assignment Problem</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-3-Matching-Cascade"><span class="nav-text">2.3 Matching Cascade</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-4-Deep-Appearance-Descriptor"><span class="nav-text">2.4 Deep Appearance Descriptor</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-Experiments"><span class="nav-text">3. Experiments</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#References"><span class="nav-text">References</span></a></li></ol></div></div></section></div></aside></div></main><footer id="footer" class="footer"><div class="footer-inner"><div class="copyright">&copy; 2015 – <span itemprop="copyrightYear">2018</span> <span class="with-love" id="animate"><i class="fa fa-user"></i> </span><span class="author" itemprop="copyrightHolder">慕湮</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-area-chart"></i> </span><span title="站点总字数">320k</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-coffee"></i> </span><span title="站点阅读时长">9:42</span></div><div class="powered-by">由 <a class="theme-link" target="_blank" rel="external nofollow noopener noreferrer" href="https://hexo.io">Hexo</a> 强力驱动</div><span class="post-meta-divider">|</span><div class="theme-info">主题 – <a class="theme-link" target="_blank" rel="external nofollow noopener noreferrer" href="https://theme-next.org">NexT.Muse</a></div></div></footer><div class="back-to-top"><i class="fa fa-arrow-up"></i></div></div><script type="text/javascript">"[object Function]"!==Object.prototype.toString.call(window.Promise)&&(window.Promise=null)</script><script type="text/javascript" src="//cdn.staticfile.org/jquery/2.1.3/jquery.min.js"></script><script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script><script type="text/javascript" src="//cdn.staticfile.org/velocity/1.2.1/velocity.min.js"></script><script type="text/javascript" src="//cdn.staticfile.org/velocity/1.2.1/velocity.ui.min.js"></script><script type="text/javascript" src="//cdn.staticfile.org/fancybox/2.1.5/jquery.fancybox.min.js"></script><script type="text/javascript" src="/js/src/utils.js?v=6.4.1"></script><script type="text/javascript" src="/js/src/motion.js?v=6.4.1"></script><script type="text/javascript" src="/js/src/scrollspy.js?v=6.4.1"></script><script type="text/javascript" src="/js/src/post-details.js?v=6.4.1"></script><script type="text/javascript" src="/js/src/bootstrap.js?v=6.4.1"></script><script>function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();

      Counter('get', '/classes/Counter', { where: JSON.stringify({ url }) })
        .done(function ({ results }) {
          if (results.length > 0) {
            var counter = results[0];
            
              var $element = $(document.getElementById(url));
              $element.find('.leancloud-visitors-count').text(counter.time + 1);
            
            Counter('put', `/classes/Counter/${counter.objectId}`, JSON.stringify({ time: { "__op":"Increment", "amount":1 } }))
            
            .fail(function ({ responseJSON }) {
                console.log('Failed to save Visitor num, with error message: ' + responseJSON.error);
            })
          } else {
            
              Counter('post', '/classes/Counter', JSON.stringify({ title: title, url: url, time: 1}))
                .done(function () {
                  var $element = $(document.getElementById(url));
                  $element.find('.leancloud-visitors-count').text(1);
                })
                .fail(function () {
                  console.log('Failed to create');
                });
            
          }
        })
      .fail(function ({ responseJSON }) {
        console.log('LeanCloud Counter Error:' + responseJSON.code + " " + responseJSON.error);
      });
    }
    

    $(function() {
      $.get('https://app-router.leancloud.cn/2/route?appId=' + "UWGXBMGbguCDhSCbC3NrUQtL-gzGzoHsz")
        .done(function ({ api_server }) {
          var Counter = function (method, url, data) {
            return $.ajax({
              method: method,
              url: `https://${api_server}/1.1${url}`,
              headers: {
                'X-LC-Id': "UWGXBMGbguCDhSCbC3NrUQtL-gzGzoHsz",
                'X-LC-Key': "ke1jrA5b6VyR89Kqqqwf2kPP",
                'Content-Type': 'application/json',
              },
              data: data,
            });
          };
          
          addCount(Counter);
          
        })
    });</script><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}()</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      },
      TeX: {equationNumbers: { autoNumber: "AMS" }}
    });</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });</script><script type="text/javascript" src="//cdn.jsdelivr.net/npm/mathjax@2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script async src="http://muyaan.com/js/src/async.js"></script></body></html>