<!DOCTYPE html><html class="theme-next muse use-motion" lang="zh-CN"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><script src="https://cdn.staticfile.org/pace/1.0.2/pace.min.js"></script><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="google-site-verification" content="Ojd_HrL_PelaXvKK5IkbhLbjZ_sHt6IxRzP-XPaaTw4"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png"><link rel="mask-icon" href="/images/logo.svg" color="#222"><script type="text/javascript" id="hexo.configurations">var NexT=window.NexT||{},CONFIG={root:"/",scheme:"Muse",version:"6.4.1",sidebar:{position:"left",display:"post",offset:12,b2t:!1,scrollpercent:!1,onmobile:!1},fancybox:!0,fastclick:!1,lazyload:!0,tabs:!0,motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},algolia:{applicationID:"",apiKey:"",indexName:"",hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}}}</script><meta name="description" content="赫赫有名的BN论文，相较各个网络的论文要硬核得多，尚未理解的部分也较多。深度学习开始入门到现在已有50天，工作时划水外加业余啃完了13篇论文，涵盖了经典的分类和检测大部分论文，目前应该只剩余GoogLeNet的3个变种，MobileNet，还有RNN那一大堆没看了。公司业务一大部分在于行人检测与重识别，后续会开始看person re-identification相关的论文，剩余的几个网络啦，ReL"><meta name="keywords" content="Deep Learning,Paper,BN"><meta property="og:type" content="article"><meta property="og:title" content="Batch Normalization"><meta property="og:url" content="http://muyaan.com/2018/08/21/Batch-Normalization/index.html"><meta property="og:site_name" content="慕湮"><meta property="og:description" content="赫赫有名的BN论文，相较各个网络的论文要硬核得多，尚未理解的部分也较多。深度学习开始入门到现在已有50天，工作时划水外加业余啃完了13篇论文，涵盖了经典的分类和检测大部分论文，目前应该只剩余GoogLeNet的3个变种，MobileNet，还有RNN那一大堆没看了。公司业务一大部分在于行人检测与重识别，后续会开始看person re-identification相关的论文，剩余的几个网络啦，ReL"><meta property="og:locale" content="zh-CN"><meta property="og:image" content="http://muyaan.com/2018/08/21/Batch-Normalization/1534492714188.png"><meta property="og:image" content="http://muyaan.com/2018/08/21/Batch-Normalization/1534498696872.png"><meta property="og:image" content="http://muyaan.com/2018/08/21/Batch-Normalization/1534569465992.png"><meta property="og:image" content="http://muyaan.com/2018/08/21/Batch-Normalization/1534752642466.png"><meta property="og:image" content="http://muyaan.com/2018/08/21/Batch-Normalization/1534755191696.png"><meta property="og:image" content="http://muyaan.com/2018/08/21/Batch-Normalization/1534756301082.png"><meta property="og:image" content="http://muyaan.com/2018/08/21/Batch-Normalization/1534757847275.png"><meta property="og:updated_time" content="2018-09-12T03:22:25.026Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="Batch Normalization"><meta name="twitter:description" content="赫赫有名的BN论文，相较各个网络的论文要硬核得多，尚未理解的部分也较多。深度学习开始入门到现在已有50天，工作时划水外加业余啃完了13篇论文，涵盖了经典的分类和检测大部分论文，目前应该只剩余GoogLeNet的3个变种，MobileNet，还有RNN那一大堆没看了。公司业务一大部分在于行人检测与重识别，后续会开始看person re-identification相关的论文，剩余的几个网络啦，ReL"><meta name="twitter:image" content="http://muyaan.com/2018/08/21/Batch-Normalization/1534492714188.png"><link rel="canonical" href="http://muyaan.com/2018/08/21/Batch-Normalization/"><script type="text/javascript" id="page.configurations">CONFIG.page={sidebar:""}</script><title>Batch Normalization | 慕湮</title><script type="text/javascript">var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?ca5844321cfb80fdf6f12b4dcc326991";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><style>html{font-family:sans-serif;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}body{margin:0}article,aside,details,figcaption,figure,footer,header,hgroup,main,menu,nav,section,summary{display:block}audio,canvas,progress,video{display:inline-block;vertical-align:baseline}audio:not([controls]){display:none;height:0}[hidden],template{display:none}a{background-color:transparent}a:active,a:hover{outline:0}abbr[title]{border-bottom:1px dotted}b,strong{font-weight:700}dfn{font-style:italic}h1{font-size:2em;margin:.67em 0}mark{background:#ff0;color:#000}small{font-size:80%}sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}sup{top:-.5em}sub{bottom:-.25em}img{border:0}svg:not(:root){overflow:hidden}figure{margin:1em 40px}hr{-moz-box-sizing:content-box;box-sizing:content-box;height:0}pre{overflow:auto}code,kbd,pre,samp{font-family:monospace,monospace;font-size:1em}button,input,optgroup,select,textarea{color:inherit;font:inherit;margin:0}button{overflow:visible}button,select{text-transform:none}button,html input[type=button],input[type=reset],input[type=submit]{-webkit-appearance:button;cursor:pointer}button[disabled],html input[disabled]{cursor:default}button::-moz-focus-inner,input::-moz-focus-inner{border:0;padding:0}input{line-height:normal}input[type=checkbox],input[type=radio]{box-sizing:border-box;padding:0}input[type=number]::-webkit-inner-spin-button,input[type=number]::-webkit-outer-spin-button{height:auto}input[type=search]{-webkit-appearance:textfield;-moz-box-sizing:content-box;-webkit-box-sizing:content-box;box-sizing:content-box}input[type=search]::-webkit-search-cancel-button,input[type=search]::-webkit-search-decoration{-webkit-appearance:none}fieldset{border:1px solid silver;margin:0 2px;padding:.35em .625em .75em}legend{border:0;padding:0}textarea{overflow:auto}optgroup{font-weight:700}table{border-collapse:collapse;border-spacing:0}td,th{padding:0}::selection{background:#262a30;color:#fff}body{position:relative;font-family:Lato,"PingFang SC","Microsoft YaHei",sans-serif;font-size:14px;line-height:2;color:#555;background:#fff}@media (max-width:767px){body{padding-right:0!important}}@media (min-width:768px) and (max-width:991px){body{padding-right:0!important}}@media (min-width:1200px){body{font-size:16px}}h1,h2,h3,h4,h5,h6{margin:0;padding:0;font-weight:700;line-height:1.5;font-family:'Roboto Slab',Lato,"PingFang SC","Microsoft YaHei",sans-serif}h1,h2,h3,h4,h5,h6{margin:20px 0 15px}h1{font-size:22px}@media (max-width:767px){h1{font-size:18px}}h2{font-size:20px}@media (max-width:767px){h2{font-size:16px}}h3{font-size:18px}@media (max-width:767px){h3{font-size:14px}}h4{font-size:16px}@media (max-width:767px){h4{font-size:12px}}h5{font-size:14px}@media (max-width:767px){h5{font-size:10px}}h6{font-size:12px}@media (max-width:767px){h6{font-size:8px}}p{margin:0 0 20px 0}a{color:#555;text-decoration:none;outline:0;border-bottom:1px solid #999;word-wrap:break-word}a:hover{color:#222;border-bottom-color:#222}blockquote{margin:0;padding:0}img{display:block;margin:auto;max-width:100%;height:auto}hr{margin:40px 0;height:3px;border:none;background-color:#ddd;background-image:repeating-linear-gradient(-45deg,#fff,#fff 4px,transparent 4px,transparent 8px)}blockquote{padding:0 15px;color:#666;border-left:4px solid #ddd}blockquote cite::before{content:"-";padding:0 5px}dt{font-weight:700}dd{margin:0;padding:0}kbd{border:1px solid #ccc;border-radius:.2em;box-shadow:.1em .1em .2em rgba(0,0,0,.1);background-color:#f9f9f9;font-family:inherit;background-image:-webkit-linear-gradient(top,#eee,#fff,#eee);padding:.1em .3em;white-space:nowrap}.text-left{text-align:left}.text-center{text-align:center}.text-right{text-align:right}.text-justify{text-align:justify}.text-nowrap{white-space:nowrap}.text-lowercase{text-transform:lowercase}.text-uppercase{text-transform:uppercase}.text-capitalize{text-transform:capitalize}.center-block{display:block;margin-left:auto;margin-right:auto}.clearfix:after,.clearfix:before{content:" ";display:table}.clearfix:after{clear:both}.pullquote{width:45%}.pullquote.left{float:left;margin-left:5px;margin-right:10px}.pullquote.right{float:right;margin-left:10px;margin-right:5px}.affix.affix.affix{position:fixed}.translation{margin-top:-20px;font-size:14px;color:#999}.scrollbar-measure{width:100px;height:100px;overflow:scroll;position:absolute;top:-9999px}.use-motion .motion-element{opacity:0}table{margin:20px 0;width:100%;border-collapse:collapse;border-spacing:0;border:1px solid #ddd;font-size:14px;word-wrap:break-all}table>tbody>tr:nth-of-type(odd){background-color:#f9f9f9}table>tbody>tr:hover{background-color:#f5f5f5}caption,td,th{padding:8px;text-align:left;vertical-align:middle;font-weight:400}td,th{border-bottom:3px solid #ddd;border-right:1px solid #eee}th{padding-bottom:10px;font-weight:700}td{border-bottom-width:1px}body,html{height:100%}.container{position:relative;min-height:100%}.header-inner{margin:0 auto;padding:100px 0 70px;width:700px}@media (min-width:1200px){.container .header-inner{width:800px}}@media (min-width:1600px){.container .header-inner{width:900px}}.main{padding-bottom:150px}.main-inner{margin:0 auto;width:700px}@media (min-width:1200px){.container .main-inner{width:800px}}@media (min-width:1600px){.container .main-inner{width:900px}}.footer{position:absolute;left:0;bottom:0;width:100%;min-height:50px}.footer-inner{box-sizing:border-box;margin:20px auto;width:700px}@media (min-width:1200px){.container .footer-inner{width:800px}}@media (min-width:1600px){.container .footer-inner{width:900px}}.highlight,pre{overflow:auto;margin:20px 0;padding:0;font-size:14px;color:#4d4d4c;background:#f7f7f7;line-height:1.6}code,pre{font-family:consolas,Menlo,"PingFang SC","Microsoft YaHei",monospace}code{padding:2px 4px;word-wrap:break-word;color:#555;background:#eee;border-radius:3px;font-size:14px}pre{padding:10px}pre code{padding:0;color:#4d4d4c;background:0 0;text-shadow:none}.highlight{border-radius:1px}.highlight pre{border:none;margin:0;padding:10px 0}.highlight table{margin:0;width:auto;border:none}.highlight td{border:none;padding:0}.highlight figcaption{font-size:1em;color:#4d4d4c;line-height:1em;margin-bottom:1em;margin:0;padding:.5em;background:#eee;border-bottom:1px solid #e9e9e9}.highlight figcaption:after,.highlight figcaption:before{content:" ";display:table}.highlight figcaption:after{clear:both}.highlight figcaption a{float:right;color:#4d4d4c}.highlight figcaption a:hover{border-bottom-color:#4d4d4c}.highlight .gutter pre{padding-left:10px;padding-right:10px;color:#869194;text-align:right;background-color:#eff2f3}.highlight .code pre{width:100%;padding-left:10px;padding-right:10px;background-color:#f7f7f7}.highlight .line{height:20px}.gutter{-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.gist table{width:auto}.gist table td{border:none}pre .deletion{background:#fdd}pre .addition{background:#dfd}pre .meta{color:#8959a8}pre .comment{color:#8e908c}pre .attribute,pre .css .class,pre .css .id,pre .css .pseudo,pre .html .doctype,pre .regexp,pre .ruby .constant,pre .tag,pre .variable,pre .xml .doctype,pre .xml .pi,pre .xml .tag .title{color:#c82829}pre .built_in,pre .command,pre .constant,pre .literal,pre .number,pre .params,pre .preprocessor{color:#f5871f}pre .css .rules .attribute,pre .formula,pre .header,pre .inheritance,pre .number,pre .ruby .class .title,pre .ruby .symbol,pre .special,pre .string,pre .value,pre .xml .cdata{color:#718c00}pre .css .hexcolor,pre .title{color:#3e999f}pre .coffeescript .title,pre .function,pre .javascript .title,pre .perl .sub,pre .python .decorator,pre .python .title,pre .ruby .function .title,pre .ruby .title .keyword{color:#4271ae}pre .javascript .function,pre .keyword{color:#8959a8}.posts-expand .post-body img.full-image{border:none}.blockquote-center,.page-home .post-type-quote blockquote,.page-post-detail .post-type-quote blockquote{position:relative;margin:40px 0;padding:0;border-left:none;text-align:center}.blockquote-center::after,.blockquote-center::before,.page-home .post-type-quote blockquote::after,.page-home .post-type-quote blockquote::before,.page-post-detail .post-type-quote blockquote::after,.page-post-detail .post-type-quote blockquote::before{position:absolute;content:' ';display:block;width:100%;height:24px;opacity:.2;background-repeat:no-repeat;background-position:0 -6px;background-size:22px 22px}.blockquote-center::before,.page-home .post-type-quote blockquote::before,.page-post-detail .post-type-quote blockquote::before{top:-20px;background-image:url(../images/quote-l.svg);border-top:1px solid #ccc}.blockquote-center::after,.page-home .post-type-quote blockquote::after,.page-post-detail .post-type-quote blockquote::after{bottom:-20px;background-image:url(../images/quote-r.svg);border-bottom:1px solid #ccc;background-position:100% 8px}.blockquote-center div,.blockquote-center p,.page-home .post-type-quote blockquote div,.page-home .post-type-quote blockquote p,.page-post-detail .post-type-quote blockquote div,.page-post-detail .post-type-quote blockquote p{text-align:center}.post .post-body .group-picture img{box-sizing:border-box;padding:0 3px;border:none}.post .group-picture-row{overflow:hidden;margin-top:6px}.post .group-picture-row:first-child{margin-top:0}.post .group-picture-column{float:left}.page-post-detail .post-body .group-picture-column{float:none;margin-top:10px;width:auto!important}.page-post-detail .post-body .group-picture-column img{margin:0 auto}.page-archive .group-picture-container{overflow:hidden}.page-archive .group-picture-row{float:left}.page-archive .group-picture-row:first-child{margin-top:6px}.page-archive .group-picture-column{max-width:150px;max-height:150px}.post-body .note{position:relative;padding:15px;margin-bottom:20px;border:1px solid #eee;border-left-width:5px;border-radius:3px}.post-body .note h2,.post-body .note h3,.post-body .note h4,.post-body .note h5,.post-body .note h6{margin-top:0;margin-bottom:0;border-bottom:initial;padding-top:0!important}.post-body .note blockquote:first-child,.post-body .note ol:first-child,.post-body .note p:first-child,.post-body .note pre:first-child,.post-body .note table:first-child,.post-body .note ul:first-child{margin-top:0}.post-body .note blockquote:last-child,.post-body .note ol:last-child,.post-body .note p:last-child,.post-body .note pre:last-child,.post-body .note table:last-child,.post-body .note ul:last-child{margin-bottom:0}.post-body .note.default{border-left-color:#777}.post-body .note.default h2,.post-body .note.default h3,.post-body .note.default h4,.post-body .note.default h5,.post-body .note.default h6{color:#777}.post-body .note.primary{border-left-color:#6f42c1}.post-body .note.primary h2,.post-body .note.primary h3,.post-body .note.primary h4,.post-body .note.primary h5,.post-body .note.primary h6{color:#6f42c1}.post-body .note.info{border-left-color:#428bca}.post-body .note.info h2,.post-body .note.info h3,.post-body .note.info h4,.post-body .note.info h5,.post-body .note.info h6{color:#428bca}.post-body .note.success{border-left-color:#5cb85c}.post-body .note.success h2,.post-body .note.success h3,.post-body .note.success h4,.post-body .note.success h5,.post-body .note.success h6{color:#5cb85c}.post-body .note.warning{border-left-color:#f0ad4e}.post-body .note.warning h2,.post-body .note.warning h3,.post-body .note.warning h4,.post-body .note.warning h5,.post-body .note.warning h6{color:#f0ad4e}.post-body .note.danger{border-left-color:#d9534f}.post-body .note.danger h2,.post-body .note.danger h3,.post-body .note.danger h4,.post-body .note.danger h5,.post-body .note.danger h6{color:#d9534f}.post-body .label{display:inline;padding:0 2px;white-space:nowrap}.post-body .label.default{background-color:#f0f0f0}.post-body .label.primary{background-color:#efe6f7}.post-body .label.info{background-color:#e5f2f8}.post-body .label.success{background-color:#e7f4e9}.post-body .label.warning{background-color:#fcf6e1}.post-body .label.danger{background-color:#fae8eb}.post-body .tabs{position:relative;display:block;margin-bottom:20px;padding-top:10px}.post-body .tabs ul.nav-tabs{margin:0;padding:0;display:flex;margin-bottom:-1px}@media (max-width:413px){.post-body .tabs ul.nav-tabs{display:block;margin-bottom:5px}}.post-body .tabs ul.nav-tabs li.tab{list-style-type:none!important;margin:0 .25em 0 0;border-top:3px solid transparent;border-left:1px solid transparent;border-right:1px solid transparent}@media (max-width:413px){.post-body .tabs ul.nav-tabs li.tab{margin:initial;border-top:1px solid transparent;border-left:3px solid transparent;border-right:1px solid transparent;border-bottom:1px solid transparent}}.post-body .tabs ul.nav-tabs li.tab a{outline:0;border-bottom:initial;display:block;line-height:1.8em;padding:.25em .75em;transition-duration:.2s;transition-timing-function:ease-out;transition-delay:0s}.post-body .tabs ul.nav-tabs li.tab a i{width:1.285714285714286em}.post-body .tabs ul.nav-tabs li.tab.active{border-top:3px solid #fc6423;border-left:1px solid #ddd;border-right:1px solid #ddd;background-color:#fff}@media (max-width:413px){.post-body .tabs ul.nav-tabs li.tab.active{border-top:1px solid #ddd;border-left:3px solid #fc6423;border-right:1px solid #ddd;border-bottom:1px solid #ddd}}.post-body .tabs ul.nav-tabs li.tab.active a{cursor:default;color:#555}.post-body .tabs .tab-content{background-color:#fff}.post-body .tabs .tab-content .tab-pane{border:1px solid #ddd;padding:20px 20px 0 20px}.post-body .tabs .tab-content .tab-pane:not(.active){display:none!important}.post-body .tabs .tab-content .tab-pane.active{display:block!important}.btn{display:inline-block;padding:0 20px;font-size:14px;color:#fff;background:#222;border:2px solid #222;text-decoration:none;border-radius:0;transition-property:background-color;transition-duration:.2s;transition-timing-function:ease-in-out;transition-delay:0s;line-height:2}.btn:hover{border-color:#222;color:#222;background:#fff}.btn+.btn{margin:0 0 8px 8px}.btn .fa-fw{width:1.285714285714286em;text-align:left}.btn-bar{display:block;width:22px;height:2px;background:#555;border-radius:1px}.btn-bar+.btn-bar{margin-top:4px}.pagination{margin:120px 0 40px;text-align:center;border-top:1px solid #eee}.page-number-basic,.pagination .next,.pagination .page-number,.pagination .prev,.pagination .space{display:inline-block;position:relative;top:-1px;margin:0 10px;padding:0 11px}@media (max-width:767px){.page-number-basic,.pagination .next,.pagination .page-number,.pagination .prev,.pagination .space{margin:0 5px}}.pagination .next,.pagination .page-number,.pagination .prev{border-bottom:0;border-top:1px solid #eee;transition-property:border-color;transition-duration:.2s;transition-timing-function:ease-in-out;transition-delay:0s}.pagination .next:hover,.pagination .page-number:hover,.pagination .prev:hover{border-top-color:#222}.pagination .space{padding:0;margin:0}.pagination .prev{margin-left:0}.pagination .next{margin-right:0}.pagination .page-number.current{color:#fff;background:#ccc;border-top-color:#ccc}@media (max-width:767px){.pagination{border-top:none}.pagination .next,.pagination .page-number,.pagination .prev{margin-bottom:10px;border-top:0;border-bottom:1px solid #eee;padding:0 10px}.pagination .next:hover,.pagination .page-number:hover,.pagination .prev:hover{border-bottom-color:#222}}.comments{margin:60px 20px 0}.tag-cloud{text-align:center}.tag-cloud a{display:inline-block;margin:10px}.back-to-top{box-sizing:border-box;position:fixed;bottom:-100px;right:30px;z-index:1050;padding:0 6px;width:24px;background:#222;font-size:12px;opacity:1;color:#fff;cursor:pointer;text-align:center;-webkit-transform:translateZ(0);transition-property:bottom;transition-duration:.2s;transition-timing-function:ease-in-out;transition-delay:0s}@media (min-width:768px) and (max-width:991px){.back-to-top{display:none!important}}@media (max-width:767px){.back-to-top{display:none!important}}.back-to-top.back-to-top-on{bottom:19px}.header{background:0 0}.header-inner{position:relative}.headband{height:3px;background:#222}.site-meta{margin:0;text-align:center}@media (max-width:767px){.site-meta{text-align:center}}.brand{position:relative;display:inline-block;padding:0 40px;color:#fff;background:#222;border-bottom:none}.brand:hover{color:#fff}.logo{display:inline-block;margin-right:5px;line-height:36px;vertical-align:top}.site-title{display:inline-block;vertical-align:top;line-height:36px;font-size:20px;font-weight:400;font-family:Lato,"PingFang SC","Microsoft YaHei",sans-serif}.site-subtitle{margin-top:10px;font-size:13px;color:#999}.use-motion .brand{opacity:0}.use-motion .logo,.use-motion .site-subtitle,.use-motion .site-title{opacity:0;position:relative;top:-10px}.site-nav-toggle{display:none;position:absolute;top:10px;left:10px}@media (max-width:767px){.site-nav-toggle{display:block}}.site-nav-toggle button{margin-top:2px;padding:9px 10px;background:0 0;border:none}@media (max-width:767px){.site-nav{display:none;margin:0 -10px;padding:0 10px;clear:both;border-top:1px solid #ddd}}@media (min-width:768px) and (max-width:991px){.site-nav{display:block!important}}@media (min-width:992px){.site-nav{display:block!important}}.menu{margin-top:20px;padding-left:0;text-align:center}.menu .menu-item{display:inline-block;margin:0 10px;list-style:none}@media screen and (max-width:767px){.menu .menu-item{margin-top:10px}}.menu .menu-item a{display:block;font-size:13px;line-height:inherit;border-bottom:1px solid transparent;transition-property:border-color;transition-duration:.2s;transition-timing-function:ease-in-out;transition-delay:0s}.menu .menu-item a:hover{border-bottom-color:#222}.menu .menu-item .fa{margin-right:5px}.use-motion .menu-item{opacity:0}.post-body{font-family:Lato,"PingFang SC","Microsoft YaHei",sans-serif}@media (max-width:767px){.post-body{word-break:break-word}}.post-body .fancybox img{display:block!important;margin:0 auto;cursor:pointer;cursor:zoom-in;cursor:-webkit-zoom-in}.post-body .figure .caption,.post-body .image-caption{margin:-20px auto 15px;text-align:center;font-size:14px;color:#999;font-weight:700;line-height:1}.post-sticky-flag{display:inline-block;font-size:16px;-ms-transform:rotate(30deg);-webkit-transform:rotate(30deg);-moz-transform:rotate(30deg);-ms-transform:rotate(30deg);-o-transform:rotate(30deg);transform:rotate(30deg)}.use-motion .comments,.use-motion .pagination,.use-motion .post-block{opacity:0}.use-motion .post-header{opacity:0}.use-motion .post-body{opacity:0}.use-motion .collection-title{opacity:0}.posts-expand{padding-top:40px}@media (max-width:767px){.posts-expand{margin:0 20px}.post-body pre .gutter pre{padding-right:10px}.post-body .highlight{margin-left:0;margin-right:0;padding:0}.post-body .highlight .gutter pre{padding-right:10px}}@media (min-width:992px){.posts-expand .post-body{text-align:justify}}.posts-expand .post-body h2,.posts-expand .post-body h3,.posts-expand .post-body h4,.posts-expand .post-body h5,.posts-expand .post-body h6{padding-top:10px}.posts-expand .post-body h2 .header-anchor,.posts-expand .post-body h3 .header-anchor,.posts-expand .post-body h4 .header-anchor,.posts-expand .post-body h5 .header-anchor,.posts-expand .post-body h6 .header-anchor{float:right;margin-left:10px;color:#ccc;border-bottom-style:none;visibility:hidden}.posts-expand .post-body h2 .header-anchor:hover,.posts-expand .post-body h3 .header-anchor:hover,.posts-expand .post-body h4 .header-anchor:hover,.posts-expand .post-body h5 .header-anchor:hover,.posts-expand .post-body h6 .header-anchor:hover{color:inherit}.posts-expand .post-body h2:hover .header-anchor,.posts-expand .post-body h3:hover .header-anchor,.posts-expand .post-body h4:hover .header-anchor,.posts-expand .post-body h5:hover .header-anchor,.posts-expand .post-body h6:hover .header-anchor{visibility:visible}.posts-expand .post-body ul li{list-style:circle}.posts-expand .post-body img{box-sizing:border-box;margin:auto;padding:3px;border:1px solid #ddd}.posts-expand .post-body .fancybox img{margin:0 auto 25px}.posts-expand .post-body img{margin:0 auto 25px}@media (max-width:767px){.posts-collapse{margin:0 20px}.posts-collapse .post-meta,.posts-collapse .post-title{display:block;width:auto;text-align:left}}.posts-collapse{position:relative;z-index:1010;margin-left:55px}.posts-collapse::after{content:" ";position:absolute;top:20px;left:0;margin-left:-2px;width:4px;height:100%;background:#f5f5f5;z-index:-1}@media (max-width:767px){.posts-collapse{margin:0 20px}}.posts-collapse .collection-title{position:relative;margin:60px 0}.posts-collapse .collection-title h1,.posts-collapse .collection-title h2{margin-left:20px}.posts-collapse .collection-title small{color:#bbb;margin-left:5px}.posts-collapse .collection-title::before{content:" ";position:absolute;left:0;top:50%;margin-left:-4px;margin-top:-4px;width:8px;height:8px;background:#bbb;border-radius:50%}.posts-collapse .post{margin:30px 0}.posts-collapse .post-header{position:relative;transition-duration:.2s;transition-timing-function:ease-in-out;transition-delay:0s;transition-property:border;border-bottom:1px dashed #ccc}.posts-collapse .post-header::before{content:" ";position:absolute;left:0;top:12px;width:6px;height:6px;margin-left:-4px;background:#bbb;border-radius:50%;border:1px solid #fff;transition-duration:.2s;transition-timing-function:ease-in-out;transition-delay:0s;transition-property:background}.posts-collapse .post-header:hover{border-bottom-color:#666}.posts-collapse .post-header:hover::before{background:#222}.posts-collapse .post-meta{position:absolute;font-size:12px;left:20px;top:5px}.posts-collapse .post-comments-count{display:none}.posts-collapse .post-title{margin-left:60px;font-size:16px;font-weight:400;line-height:inherit}.posts-collapse .post-title::after{margin-left:3px;opacity:.6}.posts-collapse .post-title a{color:#666;border-bottom:none}.page-home .post-type-quote .post-header,.page-home .post-type-quote .post-tags,.page-post-detail .post-type-quote .post-header,.page-post-detail .post-type-quote .post-tags{display:none}.posts-expand .post-title{text-align:center;word-break:break-word;font-weight:400}.posts-expand .post-title-link{display:inline-block;position:relative;color:#555;border-bottom:none;line-height:1.2;vertical-align:top}.posts-expand .post-title-link::before{content:"";position:absolute;width:100%;height:2px;bottom:0;left:0;background-color:#000;visibility:hidden;-webkit-transform:scaleX(0);-moz-transform:scaleX(0);-ms-transform:scaleX(0);-o-transform:scaleX(0);transform:scaleX(0);transition-duration:.2s;transition-timing-function:ease-in-out;transition-delay:0s}.posts-expand .post-title-link:hover::before{visibility:visible;-webkit-transform:scaleX(1);-moz-transform:scaleX(1);-ms-transform:scaleX(1);-o-transform:scaleX(1);transform:scaleX(1)}.posts-expand .post-title-link .fa{font-size:16px}.posts-expand .post-meta{margin:3px 0 60px 0;color:#999;font-family:Lato,"PingFang SC","Microsoft YaHei",sans-serif;font-size:12px;text-align:center}.posts-expand .post-meta .post-category-list{display:inline-block;margin:0;padding:3px}.posts-expand .post-meta .post-category-list-link{color:#999}.posts-expand .post-meta .post-description{font-size:14px;margin-top:2px}.posts-expand .post-meta time{border-bottom:1px dashed #999;cursor:help}.post-meta-divider{margin:0 .5em}.post-meta-item-icon{margin-right:3px}@media (min-width:768px) and (max-width:991px){.post-meta-item-icon{display:inline-block}}@media (max-width:767px){.post-meta-item-icon{display:inline-block}}@media (min-width:768px) and (max-width:991px){.post-meta-item-text{display:none}}@media (max-width:767px){.post-meta-item-text{display:none}}.post-button{margin-top:40px}.posts-expand .post-tags{margin-top:40px;text-align:center}.posts-expand .post-tags a{display:inline-block;margin-right:10px;font-size:13px}.post-nav{display:table;margin-top:15px;width:100%;border-top:1px solid #eee}.post-nav-divider{display:table-cell;width:10%}.post-nav-item{display:table-cell;padding:10px 0 0 0;width:45%;vertical-align:top}.post-nav-item a{position:relative;display:block;line-height:25px;font-size:14px;color:#555;border-bottom:none}.post-nav-item a:hover{color:#222;border-bottom:none}.post-nav-item a:active{top:2px}.post-nav-item .fa{position:absolute;top:8px;left:0;font-size:12px}.post-nav-next a{padding-left:15px}.post-nav-prev{text-align:right}.post-nav-prev a{padding-right:15px}.post-nav-prev .fa{right:0;left:auto}.posts-expand .post-eof{display:block;margin:80px auto 60px;width:8%;height:1px;background:#ccc;text-align:center}.post:last-child .post-eof.post-eof.post-eof{display:none}.post-gallery{display:table;table-layout:fixed;width:100%;border-collapse:separate}.post-gallery-row{display:table-row}.post-gallery .post-gallery-img{display:table-cell;text-align:center;vertical-align:middle;border:none}.post-gallery .post-gallery-img img{max-width:100%;max-height:100%;border:none}.fancybox-close,.fancybox-close:hover{border:none}.post-copyright{margin:2em 0 0;padding:.5em 1em;border-left:3px solid #ff1700;background-color:#f9f9f9;list-style:none}.rtl.post-body a,.rtl.post-body h1,.rtl.post-body h2,.rtl.post-body h3,.rtl.post-body h4,.rtl.post-body h5,.rtl.post-body h6,.rtl.post-body li,.rtl.post-body ol,.rtl.post-body p,.rtl.post-body ul{direction:rtl;font-family:UKIJ Ekran}.rtl.post-title{font-family:UKIJ Ekran}.sidebar{position:fixed;right:0;top:0;bottom:0;width:0;z-index:1040;box-shadow:inset 0 2px 6px #000;background:#222;-webkit-transform:translateZ(0)}.sidebar .exturl,.sidebar a{color:#999;border-bottom-color:#555}.sidebar .exturl:hover,.sidebar a:hover{color:#eee}@media (min-width:768px) and (max-width:991px){.sidebar{display:none!important}}@media (max-width:767px){.sidebar{display:none!important}}.sidebar-inner{position:relative;padding:20px 10px;color:#999;text-align:center}.site-overview-wrap{overflow:hidden}.site-overview{overflow-y:auto;overflow-x:hidden}.sidebar-toggle{position:fixed;right:30px;bottom:45px;width:14px;height:14px;padding:5px;background:#222;line-height:0;z-index:1050;cursor:pointer;-webkit-transform:translateZ(0)}@media (min-width:768px) and (max-width:991px){.sidebar-toggle{display:none!important}}@media (max-width:767px){.sidebar-toggle{display:none!important}}.sidebar-toggle-line{position:relative;display:inline-block;vertical-align:top;height:2px;width:100%;background:#fff;margin-top:3px}.sidebar-toggle-line:first-child{margin-top:0}.site-author-image{display:block;margin:0 auto;padding:2px;max-width:96px;height:auto;border:2px solid #333;opacity:1}.site-author-name{margin:5px 0 0;text-align:center;color:#f5f5f5;font-weight:400}.site-description{margin-top:5px;text-align:center;font-size:14px;color:#999}.site-state{overflow:hidden;line-height:1.4;white-space:nowrap;text-align:center}.site-state-item{display:inline-block;padding:0 15px;border-left:1px solid #333}.site-state-item:first-child{border-left:none}.site-state-item a{border-bottom:none}.site-state-item-count{display:block;text-align:center;color:inherit;font-weight:600;font-size:18px}.site-state-item-name{font-size:13px;color:inherit}.feed-link{margin-top:20px}.feed-link a{display:inline-block;padding:0 15px;color:#fc6423;border:1px solid #fc6423;border-radius:4px}.feed-link a i{color:#fc6423;font-size:14px}.feed-link a:hover{color:#fff;background:#fc6423}.feed-link a:hover i{color:#fff}.links-of-author{margin-top:20px}.links-of-author .exturl,.links-of-author a{display:inline-block;vertical-align:middle;margin-right:10px;margin-bottom:10px;border-bottom-color:#555;font-size:13px}.links-of-author .exturl:before,.links-of-author a:before{display:inline-block;vertical-align:middle;margin-right:3px;content:" ";width:4px;height:4px;border-radius:50%;background:#cf692a}.links-of-blogroll{font-size:13px}.links-of-blogroll-title{margin-top:20px;font-size:14px;font-weight:600}.links-of-blogroll-list{margin:0;padding:0;list-style:none}.links-of-blogroll-item{padding:2px 10px}.links-of-blogroll-item a{max-width:280px;box-sizing:border-box;display:inline-block;overflow:hidden;white-space:nowrap;text-overflow:ellipsis}.sidebar-nav{margin:0 0 20px;padding-left:0}.sidebar-nav li{display:inline-block;cursor:pointer;border-bottom:1px solid transparent;font-size:14px;color:#555}.sidebar-nav li:hover{color:#f5f5f5}.page-post-detail .sidebar-nav-toc{padding:0 5px}.page-post-detail .sidebar-nav-overview{margin-left:10px}.sidebar-nav .sidebar-nav-active{color:#87daff;border-bottom-color:#87daff}.sidebar-nav .sidebar-nav-active:hover{color:#87daff}.sidebar-panel{display:none}.sidebar-panel-active{display:block}.post-toc-empty{font-size:14px;color:#666}.post-toc-wrap{overflow:hidden}.post-toc{overflow:auto}.post-toc ol{margin:0;padding:0 2px 5px 10px;text-align:left;list-style:none;font-size:14px}.post-toc ol>ol{padding-left:0}.post-toc ol a{transition-duration:.2s;transition-timing-function:ease-in-out;transition-delay:0s;transition-property:all;color:#999;border-bottom-color:#555}.post-toc ol a:hover{color:#ccc;border-bottom-color:#ccc}.post-toc .nav-item{overflow:hidden;text-overflow:ellipsis;white-space:nowrap;line-height:1.8}.post-toc .nav .nav-child{display:none}.post-toc .nav .active>.nav-child{display:block}.post-toc .nav .active-current>.nav-child{display:block}.post-toc .nav .active-current>.nav-child>.nav-item{display:block}.post-toc .nav .active>a{color:#87daff;border-bottom-color:#87daff}.post-toc .nav .active-current>a{color:#87daff}.post-toc .nav .active-current>a:hover{color:#87daff}.footer{font-size:14px;color:#999}.footer img{border:none}.footer-inner{text-align:center}.with-love{display:inline-block;margin:0 5px;color:grey}.powered-by,.theme-info{display:inline-block}.cc-license{margin-top:10px;text-align:center}.cc-license .cc-opacity{opacity:.7;border-bottom:none}.cc-license .cc-opacity:hover{opacity:.9}.cc-license img{display:inline-block}@-moz-keyframes iconAnimate{0%,100%{-webkit-transform:scale(1);-moz-transform:scale(1);-ms-transform:scale(1);-o-transform:scale(1);transform:scale(1)}10%,30%{-webkit-transform:scale(.9);-moz-transform:scale(.9);-ms-transform:scale(.9);-o-transform:scale(.9);transform:scale(.9)}20%,40%,60%,80%{-webkit-transform:scale(1.1);-moz-transform:scale(1.1);-ms-transform:scale(1.1);-o-transform:scale(1.1);transform:scale(1.1)}50%,70%{-webkit-transform:scale(1.1);-moz-transform:scale(1.1);-ms-transform:scale(1.1);-o-transform:scale(1.1);transform:scale(1.1)}}@-webkit-keyframes iconAnimate{0%,100%{-webkit-transform:scale(1);-moz-transform:scale(1);-ms-transform:scale(1);-o-transform:scale(1);transform:scale(1)}10%,30%{-webkit-transform:scale(.9);-moz-transform:scale(.9);-ms-transform:scale(.9);-o-transform:scale(.9);transform:scale(.9)}20%,40%,60%,80%{-webkit-transform:scale(1.1);-moz-transform:scale(1.1);-ms-transform:scale(1.1);-o-transform:scale(1.1);transform:scale(1.1)}50%,70%{-webkit-transform:scale(1.1);-moz-transform:scale(1.1);-ms-transform:scale(1.1);-o-transform:scale(1.1);transform:scale(1.1)}}@-o-keyframes iconAnimate{0%,100%{-webkit-transform:scale(1);-moz-transform:scale(1);-ms-transform:scale(1);-o-transform:scale(1);transform:scale(1)}10%,30%{-webkit-transform:scale(.9);-moz-transform:scale(.9);-ms-transform:scale(.9);-o-transform:scale(.9);transform:scale(.9)}20%,40%,60%,80%{-webkit-transform:scale(1.1);-moz-transform:scale(1.1);-ms-transform:scale(1.1);-o-transform:scale(1.1);transform:scale(1.1)}50%,70%{-webkit-transform:scale(1.1);-moz-transform:scale(1.1);-ms-transform:scale(1.1);-o-transform:scale(1.1);transform:scale(1.1)}}@keyframes iconAnimate{0%,100%{-webkit-transform:scale(1);-moz-transform:scale(1);-ms-transform:scale(1);-o-transform:scale(1);transform:scale(1)}10%,30%{-webkit-transform:scale(.9);-moz-transform:scale(.9);-ms-transform:scale(.9);-o-transform:scale(.9);transform:scale(.9)}20%,40%,60%,80%{-webkit-transform:scale(1.1);-moz-transform:scale(1.1);-ms-transform:scale(1.1);-o-transform:scale(1.1);transform:scale(1.1)}50%,70%{-webkit-transform:scale(1.1);-moz-transform:scale(1.1);-ms-transform:scale(1.1);-o-transform:scale(1.1);transform:scale(1.1)}}.fa{font-family:FontAwesome!important}.local-search-pop-overlay{position:fixed;width:100%;height:100%;top:0;left:0;z-index:2080;background-color:rgba(0,0,0,.3)}.local-search-popup{display:none;position:fixed;top:10%;left:50%;margin-left:-350px;width:700px;height:80%;padding:0;background:#fff;color:#333;z-index:9999;border-radius:5px}@media (max-width:767px){.local-search-popup{padding:0;top:0;left:0;margin:0;width:100%;height:100%;border-radius:0}}.local-search-popup ul.search-result-list{padding:0;margin:0 5px}.local-search-popup p.search-result{border-bottom:1px dashed #ccc;padding:5px 0}.local-search-popup a.search-result-title{font-weight:700;font-size:16px}.local-search-popup .search-keyword{border-bottom:1px dashed red;font-weight:700;color:red}.local-search-popup .local-search-header{padding:5px;height:36px;background:#f5f5f5;border-top-left-radius:5px;border-top-right-radius:5px}.local-search-popup #local-search-result{overflow:auto;position:relative;padding:5px 25px;height:calc(100% - 55px)}.local-search-popup .local-search-input-wrapper{display:inline-block;width:calc(100% - 90px);height:36px;line-height:36px;padding:0 5px}.local-search-popup .local-search-input-wrapper input{padding:8px 0;height:20px;display:block;width:100%;outline:0;border:none;background:0 0;vertical-align:middle}.local-search-popup .popup-btn-close,.local-search-popup .search-icon{display:inline-block;font-size:18px;color:#999;height:36px;width:18px;padding-left:10px;padding-right:10px}.local-search-popup .search-icon{float:left}.local-search-popup .popup-btn-close{border-left:1px solid #eee;float:right;cursor:pointer}.local-search-popup #no-result{position:absolute;left:50%;top:50%;-webkit-transform:translate(-50%,-50%);-webkit-transform:translate(-50%,-50%);-moz-transform:translate(-50%,-50%);-ms-transform:translate(-50%,-50%);-o-transform:translate(-50%,-50%);transform:translate(-50%,-50%);color:#ccc}.page-pv,.site-pv,.site-uv{display:inline-block}.page-pv .busuanzi-value,.site-pv .busuanzi-value,.site-uv .busuanzi-value{margin:0 5px}.popular-posts-header{margin-top:60px;margin-bottom:10px;font-size:24px;border-bottom:1px solid #eee;display:block}ul.popular-posts{padding:0}ul.popular-posts .popular-posts-item{margin-left:2em}ul.popular-posts .popular-posts-item .popular-posts-title{font-weight:400;font-size:14px;margin:0;line-height:2.4}.page-archive .archive-page-counter{position:relative;top:3px;left:20px}@media (max-width:767px){.page-archive .archive-page-counter{top:5px}}.page-archive .posts-collapse .archive-move-on{position:absolute;top:11px;left:0;margin-left:-6px;width:10px;height:10px;opacity:.5;background:#555;border:1px solid #fff;border-radius:50%}.category-all-page .category-all-title{text-align:center}.category-all-page .category-all{margin-top:20px}.category-all-page .category-list{margin:0;padding:0;list-style:none}.category-all-page .category-list-item{margin:5px 10px}.category-all-page .category-list-count{color:#bbb}.category-all-page .category-list-count:before{display:inline;content:" ("}.category-all-page .category-list-count:after{display:inline;content:") "}.category-all-page .category-list-child{padding-left:10px}#schedule ul#event-list{padding-left:30px}#schedule ul#event-list hr{margin:20px 0 45px 0!important;background:#222}#schedule ul#event-list hr:after{display:inline-block;content:'NOW';background:#222;color:#fff;font-weight:700;text-align:right;padding:0 5px}#schedule ul#event-list li.event{margin:20px 0;background:#f9f9f9;padding-left:10px;min-height:40px}#schedule ul#event-list li.event h2.event-summary{margin:0;padding-bottom:3px}#schedule ul#event-list li.event h2.event-summary:before{display:inline-block;font-family:FontAwesome;font-size:8px;content:'\f111';vertical-align:middle;margin-right:25px;color:#bbb}#schedule ul#event-list li.event span.event-relative-time{display:inline-block;font-size:12px;font-weight:400;padding-left:12px;color:#bbb}#schedule ul#event-list li.event span.event-details{display:block;color:#bbb;margin-left:56px;padding-top:3px;padding-bottom:6px;text-indent:-24px;line-height:18px}#schedule ul#event-list li.event span.event-details:before{text-indent:0;display:inline-block;width:14px;font-family:FontAwesome;text-align:center;margin-right:9px;color:#bbb}#schedule ul#event-list li.event span.event-details.event-location:before{content:'\f041'}#schedule ul#event-list li.event span.event-details.event-duration:before{content:'\f017'}#schedule ul#event-list li.event-past{background:#fcfcfc}#schedule ul#event-list li.event-past>*{opacity:.6}#schedule ul#event-list li.event-past h2.event-summary{color:#bbb}#schedule ul#event-list li.event-past h2.event-summary:before{color:#dfdfdf}#schedule ul#event-list li.event-now{background:#222;color:#fff;padding:15px 0 15px 10px}#schedule ul#event-list li.event-now h2.event-summary:before{-webkit-transform:scale(1.2);-moz-transform:scale(1.2);-ms-transform:scale(1.2);-o-transform:scale(1.2);transform:scale(1.2);color:#fff;animation:dot-flash 1s alternate infinite ease-in-out}#schedule ul#event-list li.event-now *{color:#fff!important}@-moz-keyframes dot-flash{from{opacity:1;-webkit-transform:scale(1.1);-moz-transform:scale(1.1);-ms-transform:scale(1.1);-o-transform:scale(1.1);transform:scale(1.1)}to{opacity:0;-webkit-transform:scale(1);-moz-transform:scale(1);-ms-transform:scale(1);-o-transform:scale(1);transform:scale(1)}}@-webkit-keyframes dot-flash{from{opacity:1;-webkit-transform:scale(1.1);-moz-transform:scale(1.1);-ms-transform:scale(1.1);-o-transform:scale(1.1);transform:scale(1.1)}to{opacity:0;-webkit-transform:scale(1);-moz-transform:scale(1);-ms-transform:scale(1);-o-transform:scale(1);transform:scale(1)}}@-o-keyframes dot-flash{from{opacity:1;-webkit-transform:scale(1.1);-moz-transform:scale(1.1);-ms-transform:scale(1.1);-o-transform:scale(1.1);transform:scale(1.1)}to{opacity:0;-webkit-transform:scale(1);-moz-transform:scale(1);-ms-transform:scale(1);-o-transform:scale(1);transform:scale(1)}}@keyframes dot-flash{from{opacity:1;-webkit-transform:scale(1.1);-moz-transform:scale(1.1);-ms-transform:scale(1.1);-o-transform:scale(1.1);transform:scale(1.1)}to{opacity:0;-webkit-transform:scale(1);-moz-transform:scale(1);-ms-transform:scale(1);-o-transform:scale(1);transform:scale(1)}}.page-post-detail .sidebar-toggle-line{background:#87daff}.page-post-detail .comments{overflow:hidden}ul.breadcrumb{list-style:none;margin:1em 0;padding:0 2em;text-align:center;font-size:12px}ul.breadcrumb li{display:inline}ul.breadcrumb li+li:before{padding:.5em;font-weight:400;content:"/\00a0"}ul.breadcrumb li+li:last-child{font-weight:700}@media (max-width:767px){.container .main-inner,.footer-inner,.header-inner{width:auto}}embed{display:block;margin:0 auto 25px auto}.custom-logo .site-meta-headline{text-align:center}.custom-logo .brand{background:0 0}.custom-logo .site-title{margin:10px auto 0;font-size:24px;color:#222}.custom-logo .site-title a{border:none}.custom-logo-image{margin:0 auto;padding:5px;max-width:150px;background:#fff}@media (max-width:767px){.site-nav{position:absolute;left:0;top:52px;margin:0;width:100%;padding:0;background:#fff;border-bottom:1px solid #ddd;z-index:1030}}@media (max-width:767px){.menu{text-align:left}}@media (max-width:767px){.menu .menu-item{display:block;margin:0 10px;vertical-align:top}}.menu .menu-item .badge{display:inline-block;padding:1px 4px;margin-left:5px;font-weight:700;line-height:1;text-align:center;white-space:nowrap;background-color:#eee}@media (max-width:767px){.menu .menu-item .badge{float:right;margin:.35em 0 0 0}}@media (max-width:767px){.menu .menu-item br{display:none}}@media (max-width:767px){.menu .menu-item a{padding:5px 10px;border-bottom-color:#fff!important}}.menu .menu-item .fa{margin-right:0}.menu-item-active a{border-bottom-color:#222!important;color:#222}@media (max-width:767px){.menu-item-active a{border-bottom-color:#fff!important}}.site-search form{display:none}.links-of-blogroll-inline .links-of-blogroll-item{display:inline-block}</style><noscript><style type="text/css">.sidebar-inner,.use-motion .brand,.use-motion .collection-title,.use-motion .comments,.use-motion .menu-item,.use-motion .motion-element,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .logo,.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.logo-line-after i{right:initial}</style></noscript><script>function loadCss(l){var d=document,h=d.head,s=d.createElement('link');s.rel='stylesheet';s.href=l;!function e(f){if (d.body)return f();setTimeout(function(){e(f)})}(function(){h.appendChild(s);});}loadCss('https://cdn.staticfile.org/pace/1.0.2/themes/blue/pace-theme-big-counter.min.css');loadCss('//cdn.staticfile.org/fancybox/2.1.5/jquery.fancybox.min.js');loadCss('//cdn.staticfile.org/font-awesome/4.6.2/css/font-awesome.min.css');</script><noscript><link rel="stylesheet" href="https://cdn.staticfile.org/pace/1.0.2/themes/blue/pace-theme-big-counter.min.css"><link rel="stylesheet" href="//cdn.staticfile.org/fancybox/2.1.5/jquery.fancybox.min.js"><link rel="stylesheet" href="//cdn.staticfile.org/font-awesome/4.6.2/css/font-awesome.min.css"></noscript></head><body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-CN"><div class="container sidebar-position-left page-post-detail"><div class="headband"></div><header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-wrapper"><div class="site-meta"><div class="custom-logo-site-title"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span> <span class="site-title">慕湮</span> <span class="logo-line-after"><i></i></span></a></div><h1 class="site-subtitle" itemprop="description">白日放歌须纵酒</h1></div><div class="site-nav-toggle"><button aria-label="切换导航栏"><span class="btn-bar"></span> <span class="btn-bar"></span> <span class="btn-bar"></span></button></div></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i><br>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i><br>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i><br>标签</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i><br>归档</a></li></ul></nav></div></header><main id="main" class="main"><div class="main-inner"><div class="content-wrap"><div id="content" class="content"><div id="posts" class="posts-expand"><article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article"><div class="post-block"><link itemprop="mainEntityOfPage" href="http://muyaan.com/2018/08/21/Batch-Normalization/"><span hidden="" itemprop="author" itemscope="" itemtype="http://schema.org/Person"><meta itemprop="name" content="慕湮"><meta itemprop="description" content=""><meta itemprop="image" content="https://avatars0.githubusercontent.com/u/3022000?s=460&amp;v=4"></span><span hidden="" itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization"><meta itemprop="name" content="慕湮"></span><header class="post-header"><h2 class="post-title" itemprop="name headline">Batch Normalization</h2><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2018-08-21 15:32:47" itemprop="dateCreated datePublished" datetime="2018-08-21T15:32:47+08:00">2018-08-21</time> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-calendar-check-o"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2018-09-12 11:22:25" itemprop="dateModified" datetime="2018-09-12T11:22:25+08:00">2018-09-12</time> </span><span id="/2018/08/21/Batch-Normalization/" class="leancloud_visitors" data-flag-title="Batch Normalization"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="post-meta-item-text">阅读次数：</span> <span class="leancloud-visitors-count"></span></span><div class="post-symbolscount"><span class="post-meta-item-icon"><i class="fa fa-file-word-o"></i> </span><span class="post-meta-item-text">本文字数：</span> <span title="本文字数">17k</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-clock-o"></i> </span><span class="post-meta-item-text">阅读时长 ≈</span> <span title="阅读时长">30 分钟</span></div></div></header><div class="post-body" itemprop="articleBody"><p>赫赫有名的BN论文，相较各个网络的论文要硬核得多，尚未理解的部分也较多。深度学习开始入门到现在已有50天，工作时划水外加业余啃完了13篇论文，涵盖了经典的分类和检测大部分论文，目前应该只剩余GoogLeNet的3个变种，MobileNet，还有RNN那一大堆没看了。公司业务一大部分在于行人检测与重识别，后续会开始看person re-identification相关的论文，剩余的几个网络啦，ReLU啦，后面合适的时候再说吧~</p><blockquote><p><a href="https://arxiv.org/abs/1502.03167" rel="external nofollow noopener noreferrer" target="_blank">Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</a><br>Sergey Ioffe, Christian Szegedy 2015.02</p><p>Google Inc.</p></blockquote><h2><a href="#" class="headerlink"></a><a id="more"></a></h2><h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h2><p>深度学习显著地推进了视觉、语音及其他领域的前沿水平。SGD被证明是训练深度网络的有效方法，而SGD的变种如动量（Sutskever等人，2013）和Adagrad（Duchi等人，2011）也已用于获得前沿性能水平。SGD优化网络的参数$\Theta$，使loss最小</p><script type="math/tex;mode=display">\Theta = \arg \min_{\Theta} \frac 1 N \sum _{i=1} ^N l(x_i,\Theta)</script><p>其中$x_{1…N}$是训练数据集。在SGD中，训练是分步的，每一步我们使用一个大小为m的mini-batch$x_{1…m}$。mini-batch用于估计loss对参数的梯度：</p><script type="math/tex;mode=display">\frac 1 m \frac {\partial l(x_i, \Theta)} {\partial \Theta}</script><p>使用mini-batch样本，而不是一次一个样本，有多个好处。首先，mini-batch的loss的梯度是对训练集的一个估计，其质量随着batch大小增长而提高。其次，对一个batch进行计算比m次独立计算单个样本高效得多，得益于现代计算平台的并行能力。</p><p>尽管随机梯度简单而有效，但它需要小心地调优模型的超参数，特别是学习率以及模型参数的初始值。应为每一层的输入都受之前所有层的参数影响，训练非常复杂——因此随着网络变得更深，参数的小改动都会被放大。</p><p>层的输入分布变化造成了一个问题，因为这些层不得不断的适应新的分布。当学习系统的输入分布变化时，据说它正在经历<em>covariate shift</em>(Shimodaira, 2000)。这通常通过领域适应（Jiang, 2008）来控制。但covariate shift的概念不仅仅局限于整个学习系统，也能应用于部分，如子网络或一层。假设一个网络计算</p><script type="math/tex;mode=display">l = F_2(F_1(u,\Theta _1), \Theta _2)</script><p>其中F1和F2都是任意变换，参数$\Theta_1 , \Theta_2$被训练使loss函数l最小。训练$\Theta_2$可以看做训练输入为$x = F_1(u,\Theta_1)$的子网络。</p><script type="math/tex;mode=display">l = F_2(x, \Theta_2)</script><p>例如，一个梯度下降步骤</p><script type="math/tex;mode=display">\Theta_2 \leftarrow \Theta_2 - \frac {\alpha} {m} \sum_{i=1}^m \frac {\partial F_2 (x_i, \Theta_2)} {\partial \Theta_2}</script><p>（batch尺寸为m，学习率为$\alpha$）是完全与独立网络F2，输入x相同的。因此，能让训练更高效的输入分布属性——如训练和测试数据的分布一样——应用到子网络也同样有效。就其本身而言，x的分布不变化也是一种优势。那么$\Theta_2$不需要重新适应以补偿x分布的变化。</p><p>为子网络提供固定分布的输入也能为子网络之外的层造成积极的影响。设想一个有着sigmoid激活的层 $z = g(Wu+b)$，其中u是层的输入，权重矩阵W和bias向量b都是层所需训练的参数，而$g(x) = \frac 1 {1+ \exp (-x)}$。随着$|x|$增长，$g’(x)$趋近于0。这意味着对所有维度的$x=Wu+b$，除了绝对值较小的，对u的梯度都会消失，模型训练缓慢。不过，因为x受W，b以及所有下面层的参数影响，训练中改变这些参数很可能会将x的大部分维度移到非线性中的饱和区间，拖慢收敛速度。随着网络深度增加，这一影响还会放大。在实践中饱和问题和它导致的梯度消失通常使用ReLU（Nair和Hinton，2010）$ReLU(x) = max(x,0)$，小心的初始化（Bengio和Glorot，2010；Saxe等人，2013）和小的学习率来解决。如果我们能保证训练中非线性输入的分布更稳定，那么优化者更不易卡在饱和区，训练能得以加速。</p><p>我们把深度网络内部节点的分布变化叫做<em>Internal Covariate Shift</em>。消除它应该能让训练更快。我们提出了一个新的技巧，叫做Batch Normalization，向着消除Internal Covariate Shift迈出了一步，在训练深度神经网络时有极大的加速。它通过一个固定层的均值和方差的归一化步骤来做到这一点。BN同样对于流过网络的梯度有好处，它降低了梯度对参数尺度或它们初始值的依赖。这允许了更高的学习率的使用，而无需担心分歧的出现。而且BN正则化了模型，降低了对于Dropout（Srivastava等人）的需要。最后，BN让饱和非线性的使用变得可能。</p><p>在章节4.2，我们将BN应用于ImageNet最佳网络，我们仅需7%的训练次数就能达到其性能，进一步训练则会超越其精度一截。使用多个用BN训练的模型组合，我们获得了有史以来最佳的top-5错误率。</p><h2 id="2-Towards-Reducing-Internal-Covariate-Shift"><a href="#2-Towards-Reducing-Internal-Covariate-Shift" class="headerlink" title="2. Towards Reducing Internal Covariate Shift"></a>2. Towards Reducing Internal Covariate Shift</h2><p>我们将Internal Covariate Shift定义为因训练中网络参数的变化而导致的网络激活分布的变化。为了提升训练，我们寻找消减Internal Covariate Shift的方法。通过在训练中固定层的输入x的分布，我们期望能提升训练速度。很早就知道（LeCun等人，1988；Wiesler和Ney，2011）如果输入是白化的whitened，网络收敛会快很多——如，线性转换为有0的均值和单元方差，并去相关化。因为每一层的输入都由其下的所有层产生，那么每一层的输入都得到同样的白化是会有帮助的。通过为每一层输入进行白化，我们朝着输入固定分布更进一步，移除Internal Covariate Shift的负面影响。</p><p>我们可能会考虑在每一个训练迭代或某些间隔来白化激活，通过直接修改网络或修改依赖网络激活值的优化算法参数（Wiesler等人，2014；Raiko等人，2012；Povey等人，2014；Desjardins和Kavukcuoglu）。但是，如果这些修改散步在优化迭代中，那么梯度下降时也许会尝试将参数更新到需要归一化的状态，降低了梯度下降步骤的效果。例如，有一层的输入为u，学到的bias为b，通过减去训练数据的激活值的平均来归一化：$\hat x = x - E[x]$，其中$x = u + b, X = \{x_{1…N}\}$是训练集中x的值，而$E[x] = \frac 1 N \sum_{i=1}^N x_i$。如果一个梯度步骤忽略了$E[x]$对b的依赖，则它会$b\leftarrow b+\Delta b$，其中$\Delta b \propto - \partial l / \partial \hat x$。那么$u+(b+\Delta b) - E[u+(b+\Delta b) ]= u+b -E[u+b]$。因此对b的更新与随后归一化的改变组合导致层的输出和loss都没有改变。随着训练继续，b会无限增长而loss固定。如果归一化不仅聚集，而且还缩放了激活的话，问题还会更严重。我们已在早期实验中观察到此现象，当归一化参数在梯度步骤外计算时，模型会爆炸。</p><p>以上方法的这个问题是梯度下降优化未考虑归一化。为了解决它，我们需要保证对于任何参数值，网络总是用所需的分布产生激活值。这会使loss对模型参数的梯度考虑到归一化。设x为层的输入，X为整个训练集。则归一化可写作变换</p><script type="math/tex;mode=display">\hat x = Norm (x,X)</script><p>它不仅依赖于给定的训练样本x，而是所有样本X——如果x是由另一层产生的话，每个都依赖于$\Theta$。为了反向传播，我们需要计算Jacobian：</p><script type="math/tex;mode=display">\frac {\partial Norm(x,X)}{\partial x} and \frac {\partial Norm(x,X)}{\partial X}</script><p>忽略第二项会导致前面提到的爆炸问题。在这一框架下，白化层输入很昂贵，因为它需要计算协方差矩阵$Cov[x]=E_{x\in X}[xx^\mathrm{T}] - E[x] E[x]^\mathrm{T}$及其平方根的导数，来产生白化激活$Cov[x]^{-1/2} (x-E[x])$，以及用于反向传播的这些转换的偏导。这趋势我们寻找一种以可微的方式进行输入归一化的方法，且无需在每次参数更新后分析整个训练集。</p><p>一些之前的方法（如Lyu和Simoncelli，2008）使用在单个训练样本的统计，或在图片网络的情况，在指定位置的不同特征图的统计。但这因为丢弃了激活的绝对温标absolute scale，改变了网络的表达能力。我们希望保留网络中的信息，用整个训练集数据统计信息归一化一个训练样本的激活。</p><h2 id="3-Normalization-via-Mini-Batch-Statistics"><a href="#3-Normalization-via-Mini-Batch-Statistics" class="headerlink" title="3. Normalization via Mini-Batch Statistics"></a>3. Normalization via Mini-Batch Statistics</h2><p>因为对每层的输入都进行完全白化耗费极高，且不是哪里都可微的，我们进行了两项必要的简化。首先是与其同时白化层的输入输出特征，我们会为每个标量scalar特征独立归一化，使它们有0的均值和1的方差。对于一个有d维输入$x=(x^{(1)}…x^{(d)})$的层，我们会归一化每个维度</p><script type="math/tex;mode=display">\hat x ^{(k)} = \frac {x^{(k)} - E[x^{(k)}]} {\sqrt {Var [x^{(k)}]}}</script><p>其中期望和方程在整个训练集上计算。如已证明过的那样（LeCun等人，1998），这样的归一化能加速收敛，就算特征没有去相关。</p><p>注意到仅仅归一化一层的每个输入可能会改变该层能表达的东西。比如归一化一个sigmoid的输入会将它们约束到非线性化中的线性区域中。为了解决这个问题，我们保证<em>插入进网络中的变换能表达一致性转换</em>。为了达到这一目标，我们提出了，为每个激活$x^{(k)}$，引入一对参数$\gamma ^{(k)}, \beta ^{(k)}$，对归一化后的值进行缩放和平移：</p><script type="math/tex;mode=display">y^{(k)} = \gamma ^{(k)} \hat x ^{(k)} + \beta ^{(k)}</script><p>这些参数与原始模型参数一起训练，修复了网络的表达能力。实际上，通过设置$\gamma^{(k)} = \sqrt {Var [x^{(k)}]}$和$\beta ^{(k)} = E[x^{(k)}]$，我们能还原为原始激活。</p><p>在那些每一个训练步骤都基于整个训练集的batch设定中，我们能使用整个数据集来归一化激活。不过在使用SGD时不实际。因此我们进行了第二项简化：因为我们在SGD训练中使用mini-batch，使用mini-batch来近似每个激活的均值和方差。这一用于归一化的统计就能应用到SGD训练中。需要注意mini-batch的使用是被逐维度方差计算允许的，而不是联合协方差；在协方差的情况下会需要正则化，因为mini-batch尺寸很可能比被白化的激活数小，得到一个奇异协方差矩阵。</p><p>设想一个大小为m的mini-batch$\mathfrak{B}$，因为归一化是独立应用于各个激活的，让我们关注特定激活$x^{(k)}$并出于简洁省略k。在mini-batch中有m个值，</p><script type="math/tex;mode=display">\mathfrak {B} = \{x_{1...m}\}</script><p>设被归一化后的值为$\hat {x} _{1…m}$，它们的线性变换为$y_{1…m}$。我们把变换</p><script type="math/tex;mode=display">BN_{\gamma,\beta} : x_{1...m} \rightarrow y_{1...m}</script><p>称作Batch Normalizing Transform。我们在算法1中提供了BN转换。算法中的$\epsilon $是一个加入到mini-batch 方差的常量，以提供数值稳定性。</p><p><img src="/2018/08/21/Batch-Normalization/./1534492714188.png" alt="算法1"></p><p>BN转换能加入到网络中以操作任何机会。在表达式$y = BN_{\gamma,\beta} (x)$中，指$\gamma 和 \beta$均需训练，但需要注意的是BN转行没有为每个训练样本独立处理激活。$BN_{\gamma,\beta} (x)$依赖训练样本和所有其它mini-batch中的样本。被缩放、平移后的值y传入其它层中。被归一化后的激活$\hat x$是转变过程中的内部值，但它们非常关键。只要mini-batch中每个元素都自同一分布采样，并忽略$\epsilon$的情况下，任意$\hat x$的值的分布都可以期待有0的值和1的方差。这可以观察到$\sum_{i=1} ^m \hat x_i = 0$和$\frac 1 m \sum _{i=1}^m \hat x_i^2=1$。每个归一化后的激活$\hat x ^{(k)}$可被看做一个由线性变换$y^{(k)} = \gamma ^{(k)} \hat x ^{(k)} + \beta ^{(k)}$组成的子网络的输入，接着由原始网络继续处理。子网络的输入都有固定的均值和方程，尽管归一化后的$\hat x^{(k)}$的联合分布会随训练进程而改变，我们认为归一化输入的引入加速了整个网络的训练。</p><p>在训练中我们需要将loss l的梯度反向传播过这一变换，并计算BN变换参数的梯度。我们用了如下的链式法则：<br><img src="/2018/08/21/Batch-Normalization/./1534498696872.png" alt="Alt text"></p><p>这样BN就是一个可微的变换，能为网络引入归一化的激活。这保证了模型随着训练，层能在更少internal covariate shift的输入分布上训练，从而加速训练。不仅如此，应用到这些归一化的激活上的训练好的仿射变换允许BN转换表达一致性转换并保留网络能力。</p><h3 id="3-1-Training-and-Inference-with-Batch-Normalized-Networks"><a href="#3-1-Training-and-Inference-with-Batch-Normalized-Networks" class="headerlink" title="3.1 Training and Inference with Batch Normalized Networks"></a>3.1 Training and Inference with Batch Normalized Networks</h3><p>要BN化一个网络，我们制定了一个激活的子集，并为它们按照算法1应用了BN。所有之前接收输入为x的层，现在输入为BN(x)。使用BN的模型能用batch梯度下降，mini-batch大小大于1的SGD，或任意变种训练，如Adagrad。基于mini-batch的BN让训练高效，但在使用时就不需要了；我们希望输出仅依赖于输入。一旦网络训练结束，我们使用的归一化</p><script type="math/tex;mode=display">\hat x  = \frac {x - E[x ]} {\sqrt {Var [x ] + \epsilon} }</script><p>使用全体人口而不是mini-batch的统计。忽略$\epsilon$，归一化的激活与训练中一样，有0的均值和1的方差。我们使用无偏差的方差估计$Var[x] = \frac {m} {m-1} \cdot E _{\mathfrak {B}} [\sigma ^2 _{\mathfrak {B}}] $，其中期望是基于训练mini-batch的m个样本，而$\sigma ^2 _{\mathfrak {B}}$是样本方差。使用moving average，我们能在模型训练时追踪其准确度。因为在使用过程中均值和方差固定，归一化仅仅是用于各层的一个线性变换。也许未来会基于缩放$\gamma$和偏移$\beta$构建一个单线性变换来替代BN(x)。算法2总结了训练BN网络的过程</p><p><img src="/2018/08/21/Batch-Normalization/./1534569465992.png" alt="算法2"></p><h3 id="3-2-Batch-Normalized-Convolutional-Networks"><a href="#3-2-Batch-Normalized-Convolutional-Networks" class="headerlink" title="3.2 Batch-Normalized Convolutional Networks"></a>3.2 Batch-Normalized Convolutional Networks</h3><p>BN能应用到网络中任意激活上。在这里，我们关注一个后跟逐元素非线性函数的的仿射affine变换</p><script type="math/tex;mode=display">z = g(Wu+b)</script><p>其中W和b是模型训练的参数，$g(\cdot )$是sigmoid或ReLU这样的非线性函数。这一方程覆盖了全连接和卷积层。我们把BN加入到非线性前，归一化$x = Wu+b$。我们也能归一化层的输入u，但因为u是其他非线性的输出，其分布形状在训练中很可能变换，约束它的第一第二矩moments不能消除covariate shift。与其相反，$Wu+b$更易有一个对称的、非稀疏的分布，即“more Gaussian”（Hyvarinen和Oja，2000）；归一化它更容易产生有稳定分布的激活。</p><p>需要注意的是，因为我们归一化了$Wu+b$，bias b可以被忽略，因为其影响会被减去均值操作消除。因此，$z = g(Wu+b)$被以下方程替代</p><script type="math/tex;mode=display">z = g(BN(Wu))</script><p>BN独立应用于$x=Wu$的每个维度，每个维度使用隔离的训练好的参数$\gamma ^{(k)},\beta ^{(k)}$。</p><p>对于卷积层，我们还希望归一化服从卷积属性——同一个特征图的不同元素，它们在不同位置，但以同样的方法进行归一化。为了实现这一点，我们在所有位置共同地归一化了一个mini-batch中的所有激活。在算法1中，我们让$\mathfrak {B}$作为mini-batch中所有元素和空间位置的特征图所有值的集合，对于大小为m的mini-batch，尺寸为$p\times q$的特征图，我们实际的mini-batch大小为$m’ = |\mathfrak {B}| = m \cdot pq$。我们为每个特征图训练一对$\gamma^{(k)}, \beta ^{(k)}$，而不是每个激活。算法2也进行了类似修改，让使用过程中BN在给定特征图上的每个激活应用同样的线性变换。</p><h3 id="3-3-Batch-Normalization-enables-higher-learning-rates"><a href="#3-3-Batch-Normalization-enables-higher-learning-rates" class="headerlink" title="3.3 Batch Normalization enables higher learning rates"></a>3.3 Batch Normalization enables higher learning rates</h3><p>在传统的深度网络中，过高的学习率会导致梯度消失或爆炸，以及卡在不太好的局部最小值。BN能解决这些问题。通过归一化网络中的激活，它能防止参数的小改变震荡到更大，以及梯度中对于激活非最优的改变。</p><p>BN同样让训练对于参数尺度更有弹性resilient。通常来说，更大的学习率也许会增大层的参数的尺度，在模型反向传播时增大，从而导致模型爆炸。但对于BN，反向传播不会受参数尺度影响。比如，对于尺度a,</p><script type="math/tex;mode=display">BN(Wu) = BN((aW)u)</script><p>我们可以得到</p><script type="math/tex;mode=display">\begin {align}
\frac {\partial BN((aW)u)} {\partial u} &= \frac {\partial BN(Wu)} {\partial u} \notag \\
\frac {\partial BN((aW)u)} {\partial (aW)} &= \frac {1} {a} \cdot \frac {\partial BN(Wu)} {\partial W} \notag \\
\end {align}</script><p>这一尺度不会影响层的雅克比矩阵或梯度传播。此外，更大的权重会导致更小的梯度，BN会稳定参数的增长。</p><p>我们进一步推测，BN可能会是的层的雅克比矩阵有解决1的奇异值，据称它有利于训练（Saxe等人，2013）。考虑两个有归一化输入的连续层，归一化的向量间变换为$\hat z = F(\hat x)$。如果我们假定$\hat x, \hat z$均为高斯的且不相关，而且$F(\hat x) \approx J \hat x$是对给定模型参数的线性变换，那么$\hat x, \hat z$都有1的协方差 unit covariances，且$I = Cov[\hat z] = JCov[\hat x] J^T = J J^T$。那么$JJ^T=I$，故所有J的奇异值都等于1，从而保持了在反向传播中的梯度量级。在实际应用中，变换不是线性的，归一化后的值也不能保证是高斯的或独立的，但我们可以期待BN使梯度传播得更好。BN对梯度传播的精确影响仍需研究。</p><h3 id="3-4-Batch-Normalization-regularized-the-model"><a href="#3-4-Batch-Normalization-regularized-the-model" class="headerlink" title="3.4 Batch Normalization regularized the model"></a>3.4 Batch Normalization regularized the model</h3><p>当使用BN训练时，训练样本可以看做与mini-batch中其余样本连接，受训网络也不再为给定训练样本输出确定的值。在我们实验中，我们发现它有助于网络的泛化。由于Dropout通常用于降低过拟合，使用BN后可以去除或降低强度。</p><h2 id="4-Experiments"><a href="#4-Experiments" class="headerlink" title="4. Experiments"></a>4. Experiments</h2><h3 id="4-1-Activations-over-time"><a href="#4-1-Activations-over-time" class="headerlink" title="4.1 Activations over time"></a>4.1 Activations over time</h3><p>为了验证训练中internal covariate shift的影响以及BN对抗它的能力，我们考虑了MNIST数据集。我们使用了一个非常简单的网络，使用$28\times28$的输入，及3个全连接中间层，每个有100个激活。每个中间层计算带sigmoid激活的$y = g(Wu+b)$，权重W使用小的随机高斯值初始化。最后接一个10个激活的全连接层和一个交叉熵loss。我们训练了50k步，每个mini-batch有60个样本。我们为所有中间层增加了BN。我们对于基线和BN化的网络的比较感兴趣，而不是在MNIST上取得前沿结果。</p><p><img src="/2018/08/21/Batch-Normalization/./1534752642466.png" alt="图1"></p><p>图1(a)显示了两个网络随着训练进程在测试数据上的分数。BN化的网络有着更高的准确率。为了了解其原因，我们研究了sigmoid的输入随着训练进程变化的情况，如图1(b,c)，来自各个网络最后一个中间层。原始网络的分布情况随着时间有显著变化，包括其均值和方差，使得随后的层的训练复杂化。与其相反，使用了BN的网络的分布就稳定得多，帮助了训练。</p><h3 id="4-2-ImageNet-classification"><a href="#4-2-ImageNet-classification" class="headerlink" title="4.2 ImageNet classification"></a>4.2 ImageNet classification</h3><p>我们将BN应用到一个Inception网络的新变种上，在ImageNet分类任务上训练。网络有更多的卷积和池化，使用softmax进行1000类预测。与Szegedy等人2014年的网络相比，主要不同是$5\times5$卷积层被连续的两个有着最多128个核的$3\times3$卷积层替代。网络有$13.6\cdot 10^6$个参数，除了最上方的softmax层，不含全连接层。附录中有更多细节。后文我们将使用Inception指代此模型。模型使用带动量的SGD训练，mini-batch大小为32。训练使用大规模分布式架构（类似Dean等人，2012）完成。所有网络都在训练中对测试集每张图片使用一个切块使用top-1准确度验证。</p><p>在我们的实验中，我们测试了多个带BN的Inception。所有模型都如3.2一样以卷积的形式应用到所有非线性的输入上，同时保持其余部分不变。</p><h4 id="4-2-1-Accelerating-BN-Networks"><a href="#4-2-1-Accelerating-BN-Networks" class="headerlink" title="4.2.1 Accelerating BN Networks"></a>4.2.1 Accelerating BN Networks</h4><p>简单地将BN加入网络不能完全发挥我们方法的优势。我们进一步对网络和它的训练参数做了如下改变：</p><p><strong>Increase learning rate. </strong>BN模型中我们可以从更高的学习率中获得训练加速，而没有任何副作用</p><p><strong>Remove Dropout.</strong> 如3.4中描述，BN实现了与Dropout一些目标相同的效果。移除Dropout加速了训练，而不会带来过拟合。</p><p><strong>Reduce the $L_2$ weight regularization.</strong> 在Inception中，有一个$L_2$loss控制过拟合。在BN化的版本中该参数权重除以了5。这一改动提升了在验证集上的准确度。</p><p><strong>Accelerate the learning rate decay.</strong> 在训练Inception时，学习率以指数级衰减。因为我们的网络训练更快，我们将降低学习率的速度提升了6倍。</p><p><strong>Remove Local Response Normalization.</strong> 尽管Inception和其它网络从中受益，但我们发现使用BN后它不再必要。</p><p><strong>Shuffle training examples more thoroughly.</strong>我们为训练集启用了within-shard洗牌，防止了某些样本反复在mini-batch中同时出现。这在验证集上得到了1%的提升，这与BN是一种正则化的看法一致：当一个样本每次使用时都不一样时，我们的方法获利最大。</p><p><strong>Reduce the photometric distortions.</strong> 因为BN网络训练更快，观察到每个样本次数更少，我们通过降低失真度来让它专注于更”real”的图片。</p><h4 id="4-2-2-Single-Network-Classification"><a href="#4-2-2-Single-Network-Classification" class="headerlink" title="4.2.2 Single-Network Classification"></a>4.2.2 Single-Network Classification</h4><p>所有网络都在ILSVRC 02训练集上训练，在验证集上测试，如下：</p><ul><li>Inception: 在4.2开始描述的网络，初始学习率为0.0015</li><li>BN-Baseline: 在每个非线性前增加了BN，其余同Inception</li><li>BN-x5: 带BN的Inception，有4.2.1描述的改动。初始学习率增加了5，来到0.0075。如果原始模型也如此增大的话，会导致模型参数达到机器的无穷值。</li><li>BN-x30: 同BN-x5，但初始学习率为0.045（Inception的30倍）</li><li>BN-x5-Sigmoid: 类似BN-x5，但使用sigmoid$g(t) = \frac {1} {1+\exp (-x)}$代替ReLU。我们也在原始Inception进行了这一尝试，但模型精度不变。<br>在图2中我们展示了各网络随着训练进行的验证准确度。Inception在$31\cdot 10^6$次step后，精度达到了72.2%。图3显示了各个网络达到72.2%的精度需要的step数，以及各自能达到的最高精度。</li></ul><p><img src="/2018/08/21/Batch-Normalization/./1534755191696.png" alt="图2"></p><p><img src="/2018/08/21/Batch-Normalization/./1534756301082.png" alt="图3"></p><p>仅使用BN（BN-Baseline），我们仅用一半的step树就达到了Inception的最大精度。应用4.2.1中的修改，我们显著地提升了网络训练速度。BN-x5相比Inception，只需14分之1的step就达到72.2%的精度。有趣的是，继续增大学习率（BN-x30）会使训练一开始慢一点，但最终得到了更高的准确度，在$6\cdot 10^6$后达到了74.8%，比Inception达到72.2%还少5倍。</p><p>尽管训练这样的网络众所周知的难，我们还是验证了通过BN降低了internal covariate shift后，使用sigmoid作为非线性的网络也可以被训练。事实上BN-x5-Sigmoid得到了69.8%的准确度，而非BN化的Sigmoid Inception精度从未达到过0.1%。</p><h4 id="4-2-3-Ensemble-Classification"><a href="#4-2-3-Ensemble-Classification" class="headerlink" title="4.2.3 Ensemble Classification"></a>4.2.3 Ensemble Classification</h4><p>目前在ILSVRC上最高的结果是通过传统模型（<a href="https://arxiv.org/abs/1501.02876v1" rel="external nofollow noopener noreferrer" target="_blank">Wu等人，2015</a>）和另一模型（<a href="https://arxiv.org/abs/1502.01852" rel="external nofollow noopener noreferrer" target="_blank">He等人，2015</a>）组合得到的。最新结果是4.94%的top-5错误率。我们得到了top-5验证错误率4.9%，测试错误率为4.82%。超过了之前最好的结果，以及人类的水平（Russakovsky等人，2014）。</p><p>我们使用了6个网络组合。每个都基于BN-x30，进行了如下修改：增大卷积层初始权重；使用Dropout（概率为5%或10%，原始Inception使用了40%）；在模型最后的中间层使用非卷积式的逐激活的BN。每个网络在约$6\cdot 10^6$step后达到最大精度。组合预测基于各网络预测的算术平均。组合和multicrop inference的细节类似（Szegedy等人，2014）。</p><p>我们在图4中展示了BN与各前沿结果在ImageNet分类挑战上的比较。</p><p><img src="/2018/08/21/Batch-Normalization/./1534757847275.png" alt="图4"></p><h2 id="5-Conclusion"><a href="#5-Conclusion" class="headerlink" title="5. Conclusion"></a>5. Conclusion</h2><p>我们提出了一个用于加速深度网络训练的新方法。它基于covariance shift这一前提，众所周知它会是机器学习系统训练复杂化，从网络内部激活移除它也许能帮助训练。我们的方法通过归一化激活函数和将归一化合并进网络架构中得到力量。这保证了任意用于训练网络的优化方法都能合适地控制归一化。为了使用常用的SGD，我们为每个mini-batch进行归一化，并在反向传播中计算归一化参数的梯度。BN通过为每个激活增加两个额外参数，为网络保留了表达力。我们提出了一个构建、训练和使用BN化的网络的算法。所得到的网络能用饱和非线性训练，能容忍更大的学习率，通常不再需要Dropout进行正则化。</p><p>仅仅为前沿图片分类模型添加BN就能产生相当大的训练加速。通过进一步加大学习率，移除Dropout，应用BN提供的修改，我们仅需一小部分的训练就能达到前沿准确率，继续训练就超过了它。不仅如此，通过组合使用BN训练的模型，我们比已知最佳的ImageNet成绩还高一大截。</p><p>有趣的是，我们的方法与Gulcehre和Bengio，2013的standardization层有相似处，尽管两个方法的目标不同，任务不同。BN的目标是在训练中获得稳定的激活值分布，我们实验中应用于非线性之前，因为这样更易得到稳定的分布。与之相反，standardization应用到非线性的输出上，以产生更稀疏的激活值。在我们的ILSVRC实验中，不管是否使用BN，我们都未观测点非线性的输入变得稀疏。另一个值得注意的区别是BN包含了学到的scale和shift，允许BN表达为一致性映射（standardization层不需要，因为它跟在训练好的线性变换之后，从概念上说，吸收了必要的尺度变换和偏移），控制卷积层，使用时不基于mini-batch，能为网络中每个卷积层BN化。</p><p>在本论文中，我们没有调查所有BN可能能完成东西。我们未来的研究会包括将方法应用到RNN（Pascanu等人，2013），那里的internal covariate shift和梯度消失、爆炸问题可能特别严重，能让我们更完整的测试章节3.3的猜测：归一化能提升梯度传播。我们计划调查BN是否能帮助领域适应——如，是否BN化的网络能更容易地泛化到新的数据分布上，也许仅仅重新计算分布的均值和方差即可。最后，我们相信对于本算法的进一步理论分析会带来更多提升和应用。</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><p>Bengio, Yoshua and Glorot, Xavier. Understanding the<br>difficulty of training deep feedforward neural networks.<br>In Proceedings of AISTATS 2010, volume 9, pp. 249–<br>256, May 2010.<br>Dean, Jeffrey, Corrado, Greg S., Monga, Rajat, Chen, Kai,<br>Devin, Matthieu, Le, Quoc V., Mao, Mark Z., Ranzato,<br>Marc’Aurelio, Senior, Andrew, Tucker, Paul, Yang, Ke,<br>and Ng, Andrew Y. Large scale distributed deep networks.<br>In NIPS, 2012.<br>Desjardins, Guillaume and Kavukcuoglu, Koray. Natural<br>neural networks. (unpublished).<br>Duchi, John, Hazan, Elad, and Singer, Yoram. Adaptive<br>subgradient methods for online learning and stochasticoptimization. J. Mach. Learn. Res., 12:2121–2159, July2011. ISSN 1532-4435.<br>G¨ulc¸ehre, C¸ aglar and Bengio, Yoshua. Knowledge matters:<br>Importance of prior information for optimization.<br>CoRR, abs/1301.4083, 2013.<br>He, K., Zhang, X., Ren, S., and Sun, J. Delving Deep<br>into Rectifiers: Surpassing Human-Level Performance<br>on ImageNet Classification. ArXiv e-prints, February2015.<br>Hyv¨arinen, A. and Oja, E. Independent component analysis:<br>Algorithms and applications. Neural Netw., 13<br>(4-5):411–430, May 2000.<br>Jiang, Jing. A literature survey on domain adaptation of<br>statistical classifiers, 2008.<br>LeCun, Y., Bottou, L., Bengio, Y., and Haffner, P.<br>Gradient-based learning applied to document recognition.<br>Proceedings of the IEEE, 86(11):2278–2324,<br>November 1998a.<br>LeCun, Y., Bottou, L., Orr, G., and Muller, K. Efficient<br>backprop. In Orr, G. and K., Muller (eds.), Neural Networks:<br>Tricks of the trade. Springer, 1998b.<br>Lyu, S and Simoncelli, E P. Nonlinear image representation<br>using divisive normalization. In Proc. Computer<br>Vision and Pattern Recognition, pp. 1–8. IEEE Computer<br>Society, Jun 23-28 2008. doi: 10.1109/CVPR.<br>2008.4587821.<br>Nair, Vinod and Hinton, Geoffrey E. Rectified linear units<br>improve restricted boltzmann machines. In ICML, pp.<br>807–814. Omnipress, 2010.<br>Pascanu, Razvan, Mikolov, Tomas, and Bengio, Yoshua.<br>On the difficulty of training recurrent neural networks.<br>In Proceedings of the 30th International Conference on<br>Machine Learning, ICML 2013, Atlanta, GA, USA, 16-<br>21 June 2013, pp. 1310–1318, 2013.<br>Povey, Daniel, Zhang, Xiaohui, and Khudanpur, Sanjeev.<br>Parallel training of deep neural networks with<br>natural gradient and parameter averaging. CoRR,<br>abs/1410.7455, 2014.<br>Raiko, Tapani, Valpola, Harri, and LeCun, Yann. Deep<br>learning made easier by linear transformations in perceptrons.<br>In International Conference on Artificial Intelligence<br>and Statistics (AISTATS), pp. 924–932, 2012.<br>Russakovsky, Olga, Deng, Jia, Su, Hao, Krause, Jonathan,<br>Satheesh, Sanjeev, Ma, Sean, Huang, Zhiheng, Karpathy,<br>Andrej, Khosla, Aditya, Bernstein, Michael, Berg,<br>Alexander C., and Fei-Fei, Li. ImageNet Large Scale<br>Visual Recognition Challenge, 2014.<br>Saxe, Andrew M., McClelland, James L., and Ganguli,<br>Surya. Exact solutions to the nonlinear dynamics<br>of learning in deep linear neural networks. CoRR,<br>abs/1312.6120, 2013.<br>Shimodaira, Hidetoshi. Improving predictive inference<br>under covariate shift by weighting the log-likelihood<br>function. Journal of Statistical Planning and Inference,<br>90(2):227–244, October 2000.<br>Srivastava, Nitish, Hinton, Geoffrey, Krizhevsky, Alex,<br>Sutskever, Ilya, and Salakhutdinov, Ruslan. Dropout:<br>A simple way to prevent neural networks from overfitting.<br>J. Mach. Learn. Res., 15(1):1929–1958, January2014.<br>Sutskever, Ilya, Martens, James, Dahl, George E., and<br>Hinton, Geoffrey E. On the importance of initialization<br>and momentum in deep learning. In ICML<br>(3), volume 28 of JMLR Proceedings, pp. 1139–1147.<br>JMLR.org, 2013.<br>Szegedy, Christian, Liu, Wei, Jia, Yangqing, Sermanet,<br>Pierre, Reed, Scott, Anguelov, Dragomir, Erhan, Dumitru,<br>Vanhoucke, Vincent, and Rabinovich, Andrew.<br>Going deeper with convolutions. CoRR,<br>abs/1409.4842, 2014.<br>Wiesler, Simon and Ney, Hermann. A convergence analysis<br>of log-linear training. In Shawe-Taylor, J., Zemel,<br>R.S., Bartlett, P., Pereira, F.C.N., and Weinberger, K.Q.<br>(eds.), Advances in Neural Information Processing Systems<br>24, pp. 657–665, Granada, Spain, December 2011.<br>Wiesler, Simon, Richard, Alexander, Schl¨uter, Ralf, and<br>Ney, Hermann. Mean-normalized stochastic gradient<br>for large-scale deep learning. In IEEE International<br>Conference on Acoustics, Speech, and Signal Processing,<br>pp. 180–184, Florence, Italy, May 2014.<br>Wu, Ren, Yan, Shengen, Shan, Yi, Dang, Qingqing, and<br>Sun, Gang. Deep image: Scaling up image recognition,2015.</p></div><div class="popular-posts-header">相关文章</div><ul class="popular-posts"><li class="popular-posts-item"><div class="popular-posts-title"><a href="/2018/07/22/ResNet/" rel="bookmark">ResNet</a></div></li><li class="popular-posts-item"><div class="popular-posts-title"><a href="/2018/08/29/Person-Re-identification-Past-Present-and-Future/" rel="bookmark">Person Re-identification: Past, Present and Future</a></div></li><li class="popular-posts-item"><div class="popular-posts-title"><a href="/2018/07/21/LeNet/" rel="bookmark">LeNet</a></div></li><li class="popular-posts-item"><div class="popular-posts-title"><a href="/2018/10/16/远距离行人检测：从标注方式出发/" rel="bookmark">远距离行人检测：从标注方式出发</a></div></li><li class="popular-posts-item"><div class="popular-posts-title"><a href="/2018/09/05/GAN-生成式对抗网络/" rel="bookmark">GAN 生成式对抗网络</a></div></li></ul><div><ul class="post-copyright"><li class="post-copyright-author"><strong>本文作者： </strong>慕湮</li><li class="post-copyright-link"><strong>本文链接：</strong> <a href="http://muyaan.com/2018/08/21/Batch-Normalization/" title="Batch Normalization">http://muyaan.com/2018/08/21/Batch-Normalization/</a></li><li class="post-copyright-license"><strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="external nofollow noopener noreferrer" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明出处！</li></ul></div><footer class="post-footer"><div class="post-tags"><a href="/tags/Deep-Learning/" rel="tag"># Deep Learning</a> <a href="/tags/Paper/" rel="tag"># Paper</a> <a href="/tags/BN/" rel="tag"># BN</a></div><div class="post-nav"><div class="post-nav-next post-nav-item"><a href="/2018/08/16/GoogLeNet-v1/" rel="next" title="GoogLeNet v1"><i class="fa fa-chevron-left"></i> GoogLeNet v1</a></div><span class="post-nav-divider"></span><div class="post-nav-prev post-nav-item"><a href="/2018/08/29/Person-Re-identification-Past-Present-and-Future/" rel="prev" title="Person Re-identification: Past, Present and Future">Person Re-identification: Past, Present and Future <i class="fa fa-chevron-right"></i></a></div></div></footer></div></article></div></div></div><div class="sidebar-toggle"><div class="sidebar-toggle-line-wrap"><span class="sidebar-toggle-line sidebar-toggle-line-first"></span> <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span> <span class="sidebar-toggle-line sidebar-toggle-line-last"></span></div></div><aside id="sidebar" class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">文章目录</li><li class="sidebar-nav-overview" data-target="site-overview-wrap">站点概览</li></ul><section class="site-overview-wrap sidebar-panel"><div class="site-overview"><div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" src="https://avatars0.githubusercontent.com/u/3022000?s=460&amp;v=4" alt="慕湮"><p class="site-author-name" itemprop="name">慕湮</p><p class="site-description motion-element" itemprop="description"></p></div><nav class="site-state motion-element"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">26</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/index.html"><span class="site-state-item-count">38</span> <span class="site-state-item-name">标签</span></a></div></nav><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/tycallen" target="_blank" title="GitHub" rel="external nofollow noopener noreferrer"><i class="fa fa-fw fa-github"></i>GitHub</a> </span><span class="links-of-author-item"><a href="mailto:tyc.allen@gmail.com" target="_blank" title="E-Mail" rel="external nofollow noopener noreferrer"><i class="fa fa-fw fa-envelope"></i>E-Mail</a> </span><span class="links-of-author-item"><a href="http://weibo.com/pojunallen" target="_blank" title="微博" rel="external nofollow noopener noreferrer"><i class="fa fa-fw fa-weibo"></i>微博</a> </span><span class="links-of-author-item"><a href="https://tuchong.com/1070837" target="_blank" title="图虫" rel="external nofollow noopener noreferrer"><i class="fa fa-fw fa-globe"></i>图虫</a></span></div><div class="links-of-blogroll motion-element links-of-blogroll-block"><div class="links-of-blogroll-title"><i class="fa fa-fw fa-link"></i> 友情链接</div><ul class="links-of-blogroll-list"><li class="links-of-blogroll-item"><a href="http://dotrabbit.tk" title="dotrabbit" target="_blank" rel="external nofollow noopener noreferrer">dotrabbit</a></li></ul></div></div></section><section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active"><div class="post-toc"><div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#undefined"><span class="nav-text"></span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-Introduction"><span class="nav-text">1. Introduction</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-Towards-Reducing-Internal-Covariate-Shift"><span class="nav-text">2. Towards Reducing Internal Covariate Shift</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-Normalization-via-Mini-Batch-Statistics"><span class="nav-text">3. Normalization via Mini-Batch Statistics</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-Training-and-Inference-with-Batch-Normalized-Networks"><span class="nav-text">3.1 Training and Inference with Batch Normalized Networks</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-Batch-Normalized-Convolutional-Networks"><span class="nav-text">3.2 Batch-Normalized Convolutional Networks</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-3-Batch-Normalization-enables-higher-learning-rates"><span class="nav-text">3.3 Batch Normalization enables higher learning rates</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-4-Batch-Normalization-regularized-the-model"><span class="nav-text">3.4 Batch Normalization regularized the model</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-Experiments"><span class="nav-text">4. Experiments</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#4-1-Activations-over-time"><span class="nav-text">4.1 Activations over time</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-2-ImageNet-classification"><span class="nav-text">4.2 ImageNet classification</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#4-2-1-Accelerating-BN-Networks"><span class="nav-text">4.2.1 Accelerating BN Networks</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-2-2-Single-Network-Classification"><span class="nav-text">4.2.2 Single-Network Classification</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-2-3-Ensemble-Classification"><span class="nav-text">4.2.3 Ensemble Classification</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-Conclusion"><span class="nav-text">5. Conclusion</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#References"><span class="nav-text">References</span></a></li></ol></div></div></section></div></aside></div></main><footer id="footer" class="footer"><div class="footer-inner"><div class="copyright">© 2015 – <span itemprop="copyrightYear">2018</span> <span class="with-love" id="animate"><i class="fa fa-user"></i> </span><span class="author" itemprop="copyrightHolder">慕湮</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-area-chart"></i> </span><span title="站点总字数">329k</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-coffee"></i> </span><span title="站点阅读时长">9:59</span></div><div class="powered-by">由 <a class="theme-link" target="_blank" rel="external nofollow noopener noreferrer" href="https://hexo.io">Hexo</a> 强力驱动</div><span class="post-meta-divider">|</span><div class="theme-info">主题 – <a class="theme-link" target="_blank" rel="external nofollow noopener noreferrer" href="https://theme-next.org">NexT.Muse</a></div></div></footer><div class="back-to-top"><i class="fa fa-arrow-up"></i></div></div><script type="text/javascript">"[object Function]"!==Object.prototype.toString.call(window.Promise)&&(window.Promise=null)</script><script type="text/javascript" src="//cdn.staticfile.org/jquery/2.1.3/jquery.min.js"></script><script type="text/javascript" src="//cdn.staticfile.org/velocity/1.2.1/velocity.min.js"></script><script type="text/javascript" src="//cdn.staticfile.org/velocity/1.2.1/velocity.ui.min.js"></script><script type="text/javascript" src="//cdn.staticfile.org/fancybox/2.1.5/jquery.fancybox.min.js"></script><script type="text/javascript" src="//cdn.jsdelivr.net/npm/mathjax@2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script async="" src="http://muyaan.com/js/src/async.js"></script><script type="text/javascript" src="/bundle.js"></script><script type="text/javascript">function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();

      Counter('get', '/classes/Counter', { where: JSON.stringify({ url }) })
        .done(function ({ results }) {
          if (results.length > 0) {
            var counter = results[0];
            
              var $element = $(document.getElementById(url));
              $element.find('.leancloud-visitors-count').text(counter.time + 1);
            
            Counter('put', `/classes/Counter/${counter.objectId}`, JSON.stringify({ time: { "__op":"Increment", "amount":1 } }))
            
            .fail(function ({ responseJSON }) {
                console.log('Failed to save Visitor num, with error message: ' + responseJSON.error);
            })
          } else {
            
              Counter('post', '/classes/Counter', JSON.stringify({ title: title, url: url, time: 1}))
                .done(function () {
                  var $element = $(document.getElementById(url));
                  $element.find('.leancloud-visitors-count').text(1);
                })
                .fail(function () {
                  console.log('Failed to create');
                });
            
          }
        })
      .fail(function ({ responseJSON }) {
        console.log('LeanCloud Counter Error:' + responseJSON.code + " " + responseJSON.error);
      });
    }
    

    $(function() {
      $.get('https://app-router.leancloud.cn/2/route?appId=' + "UWGXBMGbguCDhSCbC3NrUQtL-gzGzoHsz")
        .done(function ({ api_server }) {
          var Counter = function (method, url, data) {
            return $.ajax({
              method: method,
              url: `https://${api_server}/1.1${url}`,
              headers: {
                'X-LC-Id': "UWGXBMGbguCDhSCbC3NrUQtL-gzGzoHsz",
                'X-LC-Key': "ke1jrA5b6VyR89Kqqqwf2kPP",
                'Content-Type': 'application/json',
              },
              data: data,
            });
          };
          
          addCount(Counter);
          
        })
    });;
!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}();
MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      },
      TeX: {equationNumbers: { autoNumber: "AMS" }}
    });;
MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });</script></body></html>